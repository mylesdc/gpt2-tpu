The time varying diagnosis interval was obtained by numerically simulating a compartmental HIV transmission model previously fitted to HIV and AIDS diagnosis data on MSM in the Netherlands, where it is assumed no transmission occurs when individuals are on treatment [1] .
We considered a simplified version of this model, where we neglect treatment failure since this contributes little to the diagnosis interval. Once infected, individuals go through the primary infection stage, followed by five stages of infection. At any of those 5 stages, individuals can be diagnosed, after which they progress through some of 5 mirroring diagnosed stages, in any of which they can initiate treatment. Transition rates as well as relative infectivity of the different stages were taken from Bezemer et al. [2] . For each year between 1975 and 2014, we simulated the trajectory of 100 cases infected that year, as well as the trajectory of their secondary cases.
For all pairs of index-secondary cases, we recorded the time between diagnosis of the index case and diagnosis of the secondary case, and stratified these according to the date of diagnosis of the index case, leading to a numerical approximation of the diagnosis interval distribution (.) Note that our extension of the Wallinga and Teunis method, which allows for negative diagnoses intervals, may allow "cycles", whereby A infects B and B infects A. However, the aim of the Wallinga and Teunis method, and of the extension we propose here, is not to reconstruct who infected whom per se, but rather to assess how many secondary cases, on average, a case infected or diagnosed at a given time will produce. In that sense, although p ij is described as the relative probability that i infects j, it should in fact be regarded as the relative probability that any case diagnosed the same year as i infects j (or any case infected the same year as j). This view highlights the fact that this method is only applicable to large networks. In that case, the cycle issue A infects B infects A translates into "someone diagnosed the same year as A infects B and someone diagnosed same year as B infects A", which is not an issue.
Another important feature of our analysis is that we have assumed homogeneity across clusters both in terms of the proportion of individuals in each cluster for which a sequence was taken (which was assumed to vary over time but not across clusters), and in terms of timing of HIV transmission (the diagnosis interval derived from Bezemer et al. [2] was assumed to vary over time but to be homogeneous across clusters).
We defined i q as the likelihood that case i has been infected by a case observed up to year T . This is equal to We approximated this quantity by: , which assumes that the product RI is constant over time. Here, we assess how q i is affected by this assumption. We considered 4 scenarios in which this product is exponentially increasing, with doubling times 1, 5, 10 and 20 years, corresponding to growth rates of 0.69, 0.14, 0.069 and 0.035 per year. We compared these to a scenario with constant RI (growth rate 0) and a scenario with exponentially decaying RI , 
To further assess the robustness of our estimates of the reproduction number, we repeated our estimation procedure, but truncating the data after 2000. We then compared the estimates of the reproduction number obtained using the truncated and the full dataset (S4 Fig). Note that the estimates of R t in 2000 based on the full dataset appear to be closer to the threshold value 1 than those based on the truncated dataset. Out of the 15 clusters which could be compared, four (panels A-D) had estimates based on both truncated and non-truncated datasets below 1, five
(panels E-I) had both estimates above 1, and 6 (panels J-O) had estimates above 1 based on the truncated dataset and below 1 based on the full dataset. However, for these 6 clusters, both credible intervals included the threshold value 1. Importantly, for these 6 clusters, the overall trend in transmissibility around 2000 were not dramatically different based on the truncated and the full dataset.
We performed a paired t-test to compare R t in three different time periods of our estimation: 
We investigated if recently introduced clusters have reproductive numbers that differ from the older clusters when they were new, to see if R t might be higher early after founding of a network.
We reran our estimation procedure to derive estimates of R t over the first 5 years for each cluster. 
Only eight (4%) sequences from PWID were in 5 large MSM majority clusters. Overall, 66% 
We wanted to assess whether the observed proportion of singletons, or of small clusters (size 2-9) was consistent with branching process theory. We considered the total "cluster" produced by However, the branching process model with random sampling described above doesn't capture the following feature of our data. As the sampling fraction is not complete, we may be unable to detect that two cases with a sequence belong to the same cluster, as sequences from intermediate cases might have been needed to identify these belonging to the same transmission cluster. We may also be unable to detect that two cases with a sequence belong to the same cluster if one or both of these cases is multiply infected, or had a sample sequenced at an advanced stage of infection. Therefore the observed proportion of singletons may be higher than expected under the model described above, precisely because we may be unable to merge some of the singletons with larger clusters based only on a partial and imperfect sample of sequences.
Another element to note is that the theoretical derivation considers the final size of the outbreak generated by each importation, whereas the data captures the size of each cluster at a point in time where the clusters might still be ongoing. Therefore observed clusters are smaller than expected, because we may not have observed them until they die out.
Overall, we conclude that, although a simple branching model with random sampling is unable to fully capture the complexity of our data, the model with geometric offspring distribution with R = 1 or slightly lower is reasonably well suited to describe our data. Under this model, the expected proportion of singletons and of small clusters is independent on the sampling fraction, so that the true proportion of singletons and small clusters is similar to the observed one despite partial sampling. Our observations show that 64% of clusters are singletons, and 29% are small (size 2-9), whilst the geometric model with mean offspring R = 1 leads to 50% of singletons and 31% of small clusters. This suggests that amongst all imported cases, only a small fraction (7% according to the observations, and 19% according to the model) will go on and establish a large cluster (i.e. 10 cases or more). , which is independent of . In particular the observed proportion of singletons for any value of is the same as the true proportion of singletons if all cases are observed (i.e. for = 1).