Intensive Care Medicine Experimental 2016, 4(Suppl 1):A1
Introduction: Patients meeting the Berlin definition criteria for the acute respiratory distress syndrome (ARDS) might lack exposure to one or more "common" risk factors. Such patients might exhibit different clinical phenotype and outcomes than others and constitute an individualized subgroup of patients. Objectives: To compare the clinical presentation and outcome of patients having ARDS with vs without risk factors, to determine whether the lack of ARDS risk factor is associated with hospital mortality, and Intensive Care Medicine Experimental to identify factors associated with hospital mortality in the subgroup of ARDS patients with no risk factors. Methods: Ancillary study of an international, multicenter, prospective cohort study (LUNG SAFE study [1] ). Patients meeting ARDS criteria (Berlin definition) on day 1 or 2 of acute hypoxemic respiratory failure onset were included in the study and categorized as having "common" risk factors or not. Results: Among the 2813 patients presenting ARDS in the first 48 h, 266 patients (9.4 %) had no ARDS risk factor identified at admission. Table 2 shows the final ARDS risk factor identified in patients with or without initial risk factor identified. The patients with no risk factor were older, had more frequent previously known chronic diseases and presented with less severe SOFA (8.7 ± 3.9 vs 9.5 ± 4.1, p < 0.001) and non-pulmonary (5.4 ± 3.9 vs 6.3 ± 4.1, p < 0.001) SOFA scores. ICU mortality was lower in ARDS patients with no risk factor than in others (28.6 % vs 34.9 %, p = 0.047), but in-hospital mortality was not (35.7 % vs 39.8 %, p = 0.20). The lack of ARDS risk factor was not associated with hospital mortality (adjusted OR = 0.86 [0.65-1.13], p = 0.29). In the subgroup of patients with no ARDS risk factor, age, SOFA, concomitant heart failure, and administration of steroids within 72 hours of ARDS onset were associated with hospital mortality (Table 3) .
Conclusions: Almost ten percent of patients with ARDS had no risk factor identified and exhibit a different clinical phenotype than others. Future research aimed at studying management strategies in this subgroup of patients is warranted. Introduction: Prognostication in patients with ARDS improves when patients are reclassified after 24 hours using PaO2/FiO2 and PEEP cutoffs [1, 2] . It is uncertain if SpO2/FiO2 [3] could serve as a noninvasive and continuous surrogate of PaO2/FiO2 in prognostication of ARDS patients. We hypothesized that SpO2/FiO2, in combination with PEEP, is a reliable alternative for PaO2/FiO2 in prognostication of patients with moderate or severe ARDS. Objectives: To investigate whether classification at onset and reclassification after 24 hours using SpO2/FiO2 and PEEP cutoffs allow Introduction: The differential diagnosis of acute respiratory failure (ARF) in hospitalized patients is extensive and includes congestive heart failure, atelectasis, nosocomial pneumonia, ARDS and sepsis. A novel diagnostic test based on the expression of four RNAs in peripheral blood (SeptiCyte LAB, Immunexpress, Seatle, WA) may facilitate discrimination between infectious and non-infectious causes in this setting [1] .
Objectives: To explore the diagnostic and prognostic value of Septi-Cyte LAB in ARF patients admitted to the ICU from hospital wards. Methods: We enrolled consecutive patients with ARF who had been hospitalized >48 hrs and required prompt intubation in the ICUs of two Dutch university hospitals from 2011 to 2013. All patients fulfilled ≥2 SIRS criteria and/or had an early warning score >5. We excluded patients having an established diagnosis of infection >2 days before ICU admission as well as those with airway obstruction, circulatory arrest, and other pertinent reasons for mechanical ventilation. Blood samples were collected in PAXgene tubes for RNA extraction upon ICU admission and subsequently analyzed on an Applied Bio-systems® 7500 fast Dx Real-Time PCR instrument. Test results were categorized into 4 probability bands according to the manufacturer´s specification. Post-hoc infection likelihood of sepsis events within 2 days after ICU admission were based on physician assessments according to validated definitions [2] . Results: Sample preparation or processing issues resulted in exclusion of 14 patients, leaving 467/481 (97 %) for final analysis. Of these, 359 (77 %) subjects received antibiotics upon ICU admission, whereas therapy was initiated on a later date in an additional 14 (3 %) patients. Test results correlated with the probability of infection (p < 0.001) (Fig. 1) . Among the 415 patients in whom the test classified sepsis as 'likely´, the false positive rate decreased from 17/39 (44 %) to 36/195 (18 %) with higher probability bands. In the 52 patients in whom the test suggested infection to be unlikely we observed 8 cases of confirmed infection (false negative rate 15 %). As 135 patients could not be categorized with certainty ("undetermined") formal calculation of sensitivity and specificity was precluded. SeptiCyte test results were not affected by age, prior ICU stay, or immune deficiency. Higher scores of the test were indicative of increased severity of disease and mortality (Fig. 2) . Conclusions: SeptiCyte LAB is a biomarker assay which may aid clinicians in separating infectious from non-infectious causes of acute respiratory failure in hospitalized patients. In addition, the test may have prognostic utility. Introduction: Recently, the 3rd international consensus definitions for sepsis and septic shock have launched. According to the guideline, quick Sequential Organ Failure Assessment (qSOFA) score 2 or more was recommended as clinical criteria to identify sepsis patients outside the ICU. Emergency department (ED) is the major source of ICU admission for sepsis. Therefore, an early recognition of sepsis is essential for the application of bundle therapy in time.
Objectives: We wanted to investigate the predictive value of qSOFA for 28-day mortality in ED patients with sepsis. Methods: Patients suspected for old definition of severe sepsis and septic shock were retrospectively identified in 3 urban tertiary hospital EDs from May 2014 to April 2015. Demographic findings, initial vital signs, Glasgow coma scale (GCS), site of infection, initial lactate levels, systemic inflammatory response syndrome criteria (SIRS), qSOFA score, SOFA score, and 28-day mortality were abstracted. Area under the receiver operating characteristics (AUROC) of SIRS, qSOFA, and SOFA to predict 28-day mortality were compared and diagnostic performance of qSOFA 2 or more to predict 28-day mortality was calculated.
Results: Total 942 patients were identified during study periods. Among them, 14 patients were excluded because of missing values. Demographic characteristics were described in Table 8 . Patients with qSOFA less than 2 accounted for over half of enrolled patients (493/928, 53.1 %) and over one third of mortality cases (88/ 231, 38.1 %) ( Table 9) . AUROC of SIRS, qSOFA, and SOFA to predict 28-day mortality were 0.540 (0.500-0.580), 0.627 (0.587-0.667), and 0.687 (0.646-0.727), respectively. (SIRS vs qSOFA [p < 0.001], qSOFA vs SOFA [p = 0.009]) (Fig. 3) . Diagnostic performance of qSOFA 2 or more to predict 28-day mortality was as follows: sensitivity, 61.9 % (55.3 %-68.2 %); specificity, 58.1 % (54.3 %-61.8 %); positive predictive value, 32.9 % (28.5 %-37.5 %); negative predictive value, 82.2 % (78.5 %-85.4 %). Diagnostic performance of SOFA score 2 or more to predict 28-day mortality was as follows: sensitivity, 99.1 % (96.9 %-99.9 %); specificity, 4.2 % (2.8 %-5.9 %); positive predictive value, 25.5 % (22.7 %-28.5 %); negative predictive value, 93.5 % (78.6 %-99.2 %).
Conclusions: The current clinical criteria using qSOFA have a better predictive value than SIRS for 28-day mortality in ED patients with sepsis. However, criteria of qSOFA 2 or more can miss one third of mortality cases. Therefore, further assessment of organ failure by SOFA score would be helpful in ED patients with infection. Introduction: Previous studies have linked various cytokine levels and clinical traits to organ failure and mortality, but few have used this data to cluster patients and classify distinct endotypes Objectives: To determine whether clinical biomarkers can define endotypes of sepsis with different rates of 14-day mortality and organ failure Methods: The multicenter, randomized Protocol-Based Care for Early Septic Shock (ProCESS) trial enrolled 1341 patients with septic shock and showed a 16.3 % 14-day mortality. We used hierarchical biclustering as an approach to cluster patients using cytokine levels, their early trends and other baseline clinical variables as features. Cytokine levels measured at 0, 6, and 24 hours were included. Variables with high coefficients of variation and significant univariate logistic regression p-values with organ failure outcomes were included as candidate clustering variables. Patient variables were standardized and differences in cluster mortality were examined using the logrank test. Only patients with complete variable profiles were included in the heat map analysis. After clustering was performed, the association between these clusters, organ failure, defined as a SOFA score of 2 or greater, and 14-day mortality was examined.
Results: Unsupervised clustering yielded several subgroups, or endotypes, of interest. Increasing the potential number of subgroups disclosed the emergence of subgroups with distinct clinical feature. At the highest level, patient with high cytokinemia (HC) are proximally distinguished from those with low cytokinemia (LC). Patient with HC further segregated in those with elevated lactate (HCL) (figure), which often had higher than average platelet count. Although HC was associated with generally higher MOF and mortality, HCL portended a particularly poor prognosis. As the dotted line is moved down the top dendrogram, additional subgroups appear, such as patients with acute kidney injury (high blood urea nitrogen (BUN) with low urine output), hyperglycemia, and patients with high systolic blood pressure, high temperature, and high heart rate. Conclusions: Hierarchical clustering identified endotypes of patients at particularly high (or low) risk of organ failure and 14-day mortality.
Heat map bi-clustering of septic patients including several domains of information (serum markers, clinical features) is a promising method to group patients into distinct endotypes. Classification of these endotypes can act as a basis for personalized therapies. Grant acknowledgement NIH R01-GM-105728. Step 1 (base linerecimbent)
Step 2 (PLR-passive leg raising) P Introduction: Septic patients may require large amount of intravascular fluid in the initial resuscitation. Intravascular volume can be divided into unstressed and stressed volume (V s ). V s represents the volume haemodynamically active. The systemic vascular compliance (C sys ) quantifies the relationship between the change in volume per unit of pressure in the compliance vessels.
Objectives: The aim of this study is to compare the C sys and V s between patients after cardiac surgery and septic patients after a fluid challenge. Methods: Patients admitted to the intensive care unit were monitored with invasive arterial blood pressure, a calibrated LiDCOplus (LiDCO, UK). Mean systemic filling pressure (Pmsf-arm) was measured using the stop-flow arterial-venous equilibrium method [1] . A fluid challenge of 4 -5 mL/kg of Hartmann´s solution was performed over 5 minutes. Csys was calculated as Δvolume/ΔPmsf-arm. V s was calculated multiplying C sys times Pmsf-arm at the end of the fluid challenge. Sepsis was defined by the presence of at least 2 systemic inflammatory response syndrome criteria and strong suspicion or evidence of infection. Data are presented as median and interquartile range, and compared using Mann-Whitney U test. p values less than 0.05 were considered statistically significant. There is no evidence of differences in V s (U = 195, p = .46) between septic and post-cardiac surgical patients. Conclusion: C sys is twice greater in septic patients compared to cardiac surgical patients but V s is similar between these two groups. Introduction: Adequate empiric antimicrobial therapy is crucial in terms of survival in patients with severe infections. However, the use of broad-spectrum antimicrobial treatment is not without its drawbacks.
Objective: The aim of this study was to evaluate factors associated with no de-escalation therapy in a cohort of patients admitted to the ICU with severe sepsis.
Methods: Prospective and observational study of patients admitted to the ICU with severe sepsis or septic shock January 2008 to July 2013. Appropriate cultures were obtained before initiating broad spectrum antimicrobial therapy and supportive measures were performed following Surviving Sepsis Campaign guidelines. Modification of the antimicrobial regimen after culture results was left at the decision of physician in charge of the patient. The following variables were recorded: demographic characteristics, underlying diseases, severity of illness at admission (APACHE II and SOFA scores), adequacy of empirical antimicrobial therapy, SOFA score at the day of culture results, worst SOFA score in the ICU, development of nosocomial infection, leght of stay and mortality. We also analyzed clinical characteristics, sepsis source, presence of bacteremia and type of pathogen. We used Student´s T test, Mann-Whitney U test or Chi square (as appropriate) to compare the variables. A multivariate analysis was also performed to control for confounding variables in order to asses the factors associated with no de-escalation. Results : Eight hundred and fifty two patients were enrolled and de escalation therapy was performed on two hundred and sixty seven (31,3 %). The median APACHE II and SOFA scores at admission were 18 (13-24) 7 (5-10) respectivily. Up to 648 (76,1 %) patient of total cohort had microbiological documentation. The multivariate analysis showed that the variables associated with not de-escalation therapy were SOFA score the day of culture results (OR 0,942 IC 95 %), previous antimicrobial therapy (OR 0,555 IC 95 %), liver SOFA score (OR 0,213 IC 95 %), pulmonar focus (OR 0,491 IC 95 %) and abdominal focus of infection (OR 0,500 IC 95 %). Blood cultures possitives, microbiological documentation and combination of antibiotic therapy were independent factors associated with de-escalation therapy.
Conclusions: De-escalation is a feasible strategy in critically ill patients admitted to the ICU with microbiological documentation, blood cultures positive and those with combination of antibiotic therapy. Methods: A prospective, observational and descriptive study in one ICU. All patients who received intravenous LNZ (60-minutes infusion) at doses of 600 mg every 12 hours, for treatment of a suspected or confirmed CGP-MR infection in which it was possible to obtain a blood sample (5 ml) after the third day (steady state) for the determination of the Cmin, just before administering the next dose, were included. Patients under renal replacement therapy were excluded. Demographic variables, comorbidities, severity on admission and analytical data were evaluated. LNZ quantification was performed using a high performance liquid chromatography technique (HPLC). Differences between groups were assessed using chi-square for categorical variables and Student's t-test or Mann-Whitney test for continuous variables. Significant variables in the univariate analysis were included in a multivariate model (logistic regression) to identify the variables related to sub/supratherapeutic levels. We considered p < 0.05 to be significant. The predictive value of each formula was calculated using a receiver operator characteristic curve (ROC), and the area under the curve (AUC) was also computed.
Results: A total of 103 patients were included. In 58 of them (56.3 %) the C min was < 2 ug / ml and in 30 (29.1 %) the C min was >7. 5 Introduction: Multirresistant bacteria (MRB) development is a growing phenomenon. In 2013, the "Zero Resistance" (RZ) program was launched in Spain, to help prevent the emergence of MRB in critically ill patients. One of its recommendations is to complete a checklist upon patient admission in Intensive Care Unit (ICU) to identify those patients at high risk for colonization or infection by MRB. AIMS. To analyse the effectiveness of the checklist for risk factors (RF) proposed by the RZ project as a way of MRB early detection. Methods: A prospective study from March/2014 to January/2016. All patients admitted to a polyvalent ICU of a general hospital were submitted to the checklist proposed, with the application of contact precaution (CP) strategies for patients with RF for MRB. Bacteriologic swabs (nasal, pharyngeal, axillary and rectal) were routinely performed on all patients admitted, besides diagnostic cultures when necessary. Furthermore, we analysed other pathological variables and comorbidities (diabetes, renal failure, immunosuppression state, neoplasia, cirrhosis, chronic obstructive pulmonary disease -COPD-, organ transplantation, malnutrition or type of admission to ICU -urgent or programmed). Univariate and multivariate analysis of RF for MRB with binary logistic regression were performed. Statistical significance was set at CI 95 %. Results : 1651 patients were admitted. 532 (32,2 %) met some CP criteria. In 136 (8,2 %) were detected one or more MRB, 87 of these (64 %) presented CP criteria according to the checklist. 37 met 1 criteria, 31 met 2 criteria and 19 met 3 or more criteria with accumulation of risk (p < 0,001). In 49 (36 %) MRB carriers it was not identified any of the RF from the checklist. Tables 13 and 14 show risk factors and comorbidities that were significant as added risk for MRB. Conclusion: After comparing to previous analysis, it was seen that, increasing the sample size, almost all RF included in the RZ checklist were predictors of MRB. Despite this, it could not detect 36 % of the patients infected or colonized by MRB. Because of that, we should consider other factors to predict the presence of a MRB on admitted patients to ICU. Patients were randomly assigned to sleep with or without earplugs and a facemask. A polysomnography was performed on the first day and night following inclusion. The primary end point was the proportion of sleep stage 3 + 4. Secondary end points were other descriptors of sleep and major outcome variables. Results: In the intervention group, 33 % of patients did not wear earplugs all night long. The proportion of sleep stage 3 + 4 was 11 % in the control group and 13 [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] [17] [18] [19] [20] [21] [22] [23] % in the protective group (p = 0.72). Other descriptors of sleep were not different between the two groups except the number of long awaking that was lower in the protective group than in the control group (21 [19-26] vs. 31 , p = 0.02). There was no difference among the two groups in terms of sleep quality, occurrence of a delirium, ICU length of stay and mortality, anxiety and depression on ICU discharge and day-90 and the incidence of post-traumatic stress disorder. Conclusion: In ICU patients, earplugs and eye mask are not well accepted by patients, do not increase the proportion of sleep stage 3 + 4 but decrease the number of prolonged awakenings. They had no impact on the outcome. Grant acknowledgement French Ministry of Health (PHRC) Note: This abstract has been previously published and is available at [1] . It is included here as a complete record of the abstracts from the conference.
Introduction: Gravity plays a pivotal role in the pathogenesis of ventilator-associated pneumonia (VAP) (1) . In previous laboratory studies (2) the semi-lateral Trendelenburg position (LTP) hindered gravity-driven pulmonary aspiration and avoided VAP. Objectives: To determine whether the LTP vs. the semi-recumbent position (SRP) would reduce the incidence of microbiologically confirmed VAP and to appraise patient's compliance and safety. Methods: We conducted a randomized, single-blind, controlled study in 17 European centers and 1 in North America. A total of 2019 adult patients were screened between 2010 and 2015. 395 patients were randomized -194 in LTP and 201 in SRP -and analyzed in an intention to treat approach. Patients in LTP were placed in semi-lateral (60°) -Trendelenburg position to achieve an orientation, from the sternal notch toward the mouth, slightly below horizontal, and turned from one side to the other every 6 hours. LTP was encouraged during the first days of mechanical ventilation, but always in compliance with the patient's wish. In the SRP group, the head of the bed was elevated ≥ 30°. Primary outcome was VAP incidence rate, based on quantitative bronchoalveolar lavage fluid culture with ≥ 10 4 colonyforming units/mL. Secondary outcomes were compliance to the randomized position, length of intubation, duration of intensive care unit and hospital stay, mortality, and adverse events.
Results: The trial was stopped after the planned interim analysis for achieving efficacy endpoints and owing to safety concerns. Patients in the LTP and SRP group were kept in the randomized position for 38 % and 90 % of the study time, respectively (p = 0.001). Yet, during the first 48 hours, LTP patients were kept in the randomized position for 50 % of the study time, and SRP patients for 88 % (p = 0.001). In the LTP, the bed was angulated 5.6°in Trendelenburg; while, the head of the bed was elevated 34.1°in the SRP group. Incidence rates of microbiologically confirmed VAP were 0.88 (1/1136 patient-days; 95 % confidence interval [CI], 0.12-6.25) in the LTP group, and 7.19 (8/1113 patient-days; CI 95 %, 3.60-14.37) in the SRP (p = 0.020), relative risk reduction of 0.12 (95 % CI, 0.01-0.91). No statistically significant differences were observed in durations of mechanical ventilation, intensive care unit and hospital stay, and mortality. Vomiting was more common in LTP patients (8.3 % vs. 2.5 % in the SRP, p = 0.013).
Conclusions: Critically ill patients positioned in the LTP had a statistically significant reduction in the incidence of VAP, compared with those positioned in the SRP. A comprehensive evaluation of potential LTP contraindications is warranted to enhance safety.
Introduction: Acute kidney injury (AKI) is a multifactorial syndrome, but knowledge regarding its pathophysiology and possible genetic background is limited. Recently the first hypothesis free genetic association studies have been published to explore the individual susceptibility to AKI. Objectives: We aimed to replicate the previous associations of candidate polymorphisms (N = 5) with development of AKI (1) using a prospectively collected cohort of septic critically ill patients in Finland. Methods: We included all septic patients with genetic samples among the 2968 FINNAKI study patients. After exclusion of 401 patients (due to underlying chronic kidney disease, lack of DNA or genotyping quality) 837 (of the remaining 2567) had sepsis. AKI was defined according to the KDIGO criteria, considering stages 2 and 3 affected and KDIGO 0 unaffected. The genotyping was done using iPLEX™ Assay (Agena Bioscience). The genotyped SNPs were rs8094315 and rs12457893 in the intron of the BCL2 gene, rs2093266 in the SERPINA4 gene, rs1955656 in the Introduction: Acute kidney injury (AKI) is a severe complication of critical illness, often accompanied by vasoconstriction in the renal arteries and microcirculation. Its diagnosis is mainly based on a rise in serum creatinine, which is a late phenomenon. The Renal Resistive Index (RRI), measured with Doppler ultrasound, represents a new non-invasive diagnostic tool assessing flow resistance in the renal circulation, early after admission. (1) Objectives: To determine whether RRI measured on intensive care unit (ICU) admission is an early predictor and discriminator of AKI development and severity, developing within the first week after ICU admission, and if RRI predicts AKI independently of other AKI risk factors.
Methods: Prospective observational cohort study in ICU patients. AKI development and stage were defined by the KDIGO criteria. To increase the likelihood of including patients developing AKI, two cohorts of patients were included within 24 h after ICU admission: Patients with shock and without shock. Patients with eGFR < 30 ml/ min were excluded. Besides routine ICU measurements, including risk factors for developing AKI, three study measurements were performed at inclusion: RRI, sublingual sidestream dark field imaging (SDF) to visualise microcirculation, and Bioelectrical Impedance Analysis (BIA) as a marker of fluid status. Uni-and multivariate and ROC curve analyses were performed to assess predictive and discriminative value of RRI and other variables for the development of AKI. Results: We included 99 patients, mean age 65, mean APACHE III score 73. 49 patients (49 %) developed AKI within the first week (mean 2.2 days after inclusion). Patients who developed AKI had a significantly higher RRI on inclusion than those who did not: 0.708 (0.687-0.730) vs 0.654 (0.631-0.677), p = 0.001. Compared to patients without AKI, RRI was significantly higher in patients with AKI stage 2 and 3, but not in patients with AKI stage 1 (Fig. 12) . We therefore chose AKI stage 2 and 3 as endpoint in further analysis. On univariate analysis, RRI was a significant predictor of AKI (OR 1.012, 95 % CI 1.006-1.019), along with other parameters including: APACHE III, fluid balance and BIA derived reactance, but not sublingual microcirculation. On multivariate analysis, RRI, APACHE III and fluid balance remained significant. The AUC of RRI for AKI stage 2 and 3 was 0.721 (95 % CI 0.612-0.831). The composite AUC of the multivariate predictors was 0.825 (Fig. 13) .
Conclusions: In this observational study, RRI on ICU admission was a significant independent early predictor for development of AKI stage 2 and 3 during the first week, but not for AKI stage 1. Of all evaluated predictors, APACHE III, as a marker of severity of disease, and fluid balance were additional independent predictors of AKI, suggesting that other factors than vasoconstriction contribute to AKI development. Introduction: Remote ischemic preconditioning (RIPC), has been demonstrated beneficial effects on acute kidney injury (AKI) and/or cardiac function, after coronary angiography (CA), in high risk patients. However, the protective effects by RIPC may be attenuated in diabetic patients Objectives: The purpose of this study was to evaluate the effects of RIPC on the myocardial and renal function as measured by plasma Troponin I and proBNP, and creatinine and cystatin C levels (as an early marker of glomerular function), before and after CA in diabetic patients.
Methods: A prospective randomized, single centre pilot trial was conducted at University Hospital Sta. Lucia, Spain. We analyzed 50 diabetic adult patients with acute coronary syndrome admitted to a medical intensive care unit, with a diagnosis of diabetes before admission, undergoing standard CA. We established two groups: standard CA with remote RPIC (RIPC group) trough intermittent upper-arm ischemia before CA, or without RIPC (control group). We recorded demographical, clinical, and analytical data of the patients, before and after 72 hours of procedure. We analyzed qualitative variables with percentages by categories and square Chi; quantitative variable with mean, standard deviation and T Student; or median, interquartile rank and U Mann Whitney; or regression, depending on the statistical distribution.
Results: Patients receiving RIPC showed lower troponin I peak (ng/ml) 3.3 (0.98-13.5) compared to control group 18 (1.76-31.15); p = 0.053; and the NT-proBNP (pg/ml) increasing after 72 hours was -946 (-2977-20); compared to control group 73 (-426-2210); p = 0.005. Regarding to renal function, basal and after 72 hours, creatinine and cystatine-C plasma levels were similar in both groups. The creatinin (mg/dl) increments after 24 hours were (RIPC; 0(-14-10; control -5.5(-16-8) p > 0.05 and cystacin C (mg/L) RIPC, 3 (-7-11) and control -4 (-9-13) p > 0.05. The calculated mean Mehran score for both groups in the present study was8 in RIPC group and 8.5 (control group), thus determining the present study population as a group at medium risk of developing AKI. No adverse effects were related to RIPC maneuver in any patient.
Conclusions: The RIPC maneuver in diabetic patients before CA demonstrated beneficial on cardiac function without affecting renal parameters. The mechanisms underlying these effects merit further investigation Introduction: Quantitative measurement of microcirculatory and of tissue oxygen concentration is of prime importance in experimental research. Non-invasive time resolved quenching of Palladium-porphyrin phosphorescence injected into experimental animals has given much fundamental insight in mechanisms of oxygen transport to tissue in health and models of disease. Until now, most of the phosphorimeters used flash lamps as a light excitation source. However, a major drawback of flash lamps is the plasma glow that persists for tens of microseconds after the primary discharge. When a flash lamp produces a pulse, a tail remains causing unwanted further excitation to the initial pulse of the phosphor in a time dependent manner. This generates a complex excitation pulse pattern, which if not taken into account using deconvolution analysis, can lead to inaccurate PO 2 readings. Objectives: To design and calibrate a new LED-based phosphorimeter (LED-P) that address previous drawbacks of flash-lamp phosphorimeter (FL-P). We validate the LED-P with in vitro and vivo experimental studies Methods: We designed the LED-P using 4 LEDs of different colours (blue, green, yellow, red), each with a narrow-band wavelength (20 nm), providing excitation light pulses within the range of several phosphorescent dyes often use in experimental studies. We calibrated in vitro the device using the Palladium-porphyrin phosphorescent dye at different temperatures ( 19, 25, 28, 32, 34, 37 and 39°C) and adjusted pH (6.8, 7.0, 7.2, 7.4, 7.6) with an enzymatic reaction producing step by step decrease of oxygen content and analysing the decay times of phosphorescence (τ). The oxygen content was measured with a solid-state polymer optical fiber sensor oxygen optode (POF, Oxy-Mini, World Precision Instruments, USA). In vivo calibration was performed in a rat model by exposing the kidney. We ventilated the animal in different hypoxic conditions (15, 7 and 4 % O 2 ) and performed renal ischemia/reperfusion injury by clamping the renal artery.
Results: The LED-P exhibited a block shape light pulse without afterglow eliminating the need for deconvolution of the light emission signal coming from the tissue under analysis. A perfect linear regression was observed after plotting decay times ratio (τ0/τ) and in vitro oxygen concentration (r 2 = 0.99). In vivo, the LED-P showed similar kidney microvascular PO 2 compared to previously published works, in hypoxia or ischemia conditions. Conclusions: This new LED-P provides minimally-invasive, accurate and reliable measurements of microvascular PO 2 in the kidney, without the need of complex mathematical deconvolution of the light emission signal coming from the tissue. LEDs are much cheaper, with a smaller sized and simpler electronics, are more energy efficient, have a longer lifetime. This LED-P provides the ability to choose which LED to enable/disable to excite different phosphorescent dyes within the same measurement. Correspondence: Z. Uz -Academic Medical Centre Amsterdam, Translational Physiology, Amsterdam, Netherlands Introduction: Systemic inflammatory response is a complication that occurs frequently in cardiac surgery patients with extracorporeal circulation (EC). Leucocytosis is a common outcome after cardiac surgery due to surgical trauma, blood contact to nonendothelial surfaces in the EC, endotoxaemia and ischemia reperfusion injury due to aortic cross clamping and release. This induces an activation of complement factors, coagulation pathways and cellular immune response. Leucocyte (Lc) adhesion to the endothelial followed by diapedesis is a key component of the inflammatory response. In the context of cardiac surgery therefore Lc adhesion is expected especially following release of cross clamp. Currently there is no direct method of identifying this behavor of Lc in the microcirculation. This study describes the use of Cytocam IDF imaging (handheld video microscope) as a tool to identify and quantify the behavior of Lc in the sublingual microcirculation of patients during surgery. Objectives: The introduction and application of an algorithm as a method to count non-invasively Lc in the microcirculation. Methods: In this prospective observational study videos of the sublingual microcirculation during, coronary artery bypass surgery with EC, were recorded with the use of the CytoCam (Braedius Medical, Amsterdam, The Netherlands). Two time points were measured, baseline (T0) after induction of anesthesia before CPB, second time point (T1) after release cross clamp.25 patients were recruited, of which 10 were included in this study based on evaluation of the sublingual video images using a quality criteria in order to identify at least one post capillary venule (PCV) where focus of the red blood cells is primarily important. Patients in this group received blood transfusions during surgery.3 clips for each time point with duration of 4 sec (25 frames/sec) in different spots were captured. Identifying a PCV to count the activated Lc: sticking and rolling Lc on the wall of the PCV. Converting these clips into movies with a lower frame rate in order to match the velocity of the leukocytes to that of the frame speed allowed the movement of the rbc's to look unclear. Selecting 2-5 PCV good quality for each clip ( at least one PCV).
Results: The rolling/sticking Lc from T0 (7.3 ± 1.5 Lc/PCV/4 sec) to T1 (14.5 ± 0.7 Lc/PCV/4 sec) increased significantly (P = < 0.0001). The systemic leukocytes before (7.2 ± 0.9 x10^9/L ) and after (10.6 ± 1.5 x10^9/L ) surgery also increased significantly (p = 0.0002).
Conclusions: This study introduces a bedside methodology using CytoCam IDF imaging for quantifying Lc activation of sublingual microcirculation. Application of this methodology to cardiac surgery identified an increase in microcirculatory activated Lc in parallel to an increase in Lc numbers in the systemic circulation. Introduction: We have previously demonstrated that the incidence of infection following major abdominal surgery is 35 % 1 and is associated with the extent of post-operative immune suppression 2 . It remains unclear which clinically available immune stimulant may best suited as an adjunct to prevent post-operative infection.
Objectives: To determine whether Granulocyte macrophage colonystimulating factor (GM-CSF) and interferon gamma (IFNγ) act through different pathways in reversing defects in monocyte antigen presentation following major abdominal surgery. Methods: Serum was collected from 12 patients undergoing elective abdominal surgery (Research ethics approved). The median patient age was 68 years (IQR 48-74), median operation time was 270mins (IQR 207-320) and 50 % (6) developed nosocomial infection.
Pooled healthy peripheral blood mononuclear cells (PMBCs) were incubated with media containing 30 % serum taken either preoperatively or 24 hrs post operatively and then with the addition of GM-CSF (10 ng/ml) and INFg 250 IU/ml). Monocyte human leucocyte antigen-DR (mHLA-DR) membrane density (geometric mean fluorescent intensity) was characterised using flow cytometry following a 20-hour incubation. Cells were then sorted on a BD FACS ARIA IIIu system using CD14 positive selection. Messenger RNA (mRNA) was extracted from the sorted population (>90 % purity post sorting). Genes of interest were quantified using polymerase chain reaction (PCR) using TaqMan® labelled primers and real time PCR (ABI HT7900). Flow cytometry data was analysed using FlowJo. Continuous variables were analysed using a Wilcoxin signed-rank test (JMP (version 11) statistical software).
Results: PMBCs incubated with post-operative serum demonstrated a significant reduction in mHLA-DR membrane density (Fig. 19 , p = 0.001). The reduction in mHLA-DR density was prevented when co-incubated with GM-CSF and IFNγ (Fig. 19 ). Incubation with IFNγ but not GM-CSF increased expression of HLA-DRα chain (p = 0.01), Cathepsin S (CTSS) (p = 0.001), suppressor of cytokine signalling 3 (SOCS3) (p = 0.01) and March 1 (p = 0.002) (Fig. 20) .
Conclusions: These results suggest that these immune stimulants, GM-CSF and IFNγ, exert their effects on monocyte antigen presentation through different signalling pathways. The increased gene expression associated with IFNγ may be indicative of potential therapeutic benefit in reversing post-operative immune suppression. Introduction: Delirium in critically ill patients is associated with increased mortality and long-term cognitive decline. The recent Pain, Agitation and Delirium (PAD) guidelines include recommendations for delirium screening, prevention and management, which may help to improve clinical outcomes and reduce delirium burden. Objectives: We aimed to measure the effectiveness of a multifaceted implementation program for improved adherence to the PAD guidelines and associated changes in delirium incidence and duration, length of ICU stay and hospital mortality. Methods: A prospective multicenter before-after study was conducted in six ICUs in the Netherlands between March 2012 and April 2015. The intervention consisted of a two-phase multifaceted tailored implementation of the PAD guidelines. Multiple implementation strategies were applied to change clinical practice (Table 18) . Data of all adult ICU patients were collected during three four-month periods:
1) before implementation, 2) after implementation of delirium screening, and 3) after implementation of other PAD guidelines.
The difference in adherence and clinical outcomes between the three periods was assessed with random effects Poisson and logistic regression with a random intercept for patients for outcomes on patient-day level and with logistic and linear regression for outcomes on patient level, adjusted for APACHE II, hospital, age and admission type. Differences were expressed as adjusted rate ratios (aRR), odds ratios (aOR) or beta's with the "before"-period as the reference.
Results: A total of 4727 patients were enrolled in the study with a total of 23958 ICU days. Adherence to most PAD guideline recommendations improved significantly whereas early mobilization and reduced benzodiazepine sedation improved only in the last period (Table 19 ). The incidence of delirium increased from 22 % before to 30 % after implementation (aOR = 1.5, p < 0.01) whereas delirium duration decreased from 6.3 before to 3.6 days after implementation (aBeta = -2.6, p < 0.01). There were no statistically significant differences in ICU length of stay (aBeta = 0.001, p = 0.99); ICU mortality (aOR = 1.2, p = 0.17); and hospital mortality (aOR = 1.2, p = 0.21) after vs. before the implementation. Only length of mechanical ventilation increased with half a day (aBeta = 0.55, p = 0.01).
Conclusions: This multifaceted implementation program was effective in improving adherences to multiple key PAD guideline recommendations. Delirium duration decreased significantly in spite of increased incidence probably due to improved screening. We observed differential effects of screening vs. further guideline implementation. However, these improved adherences to guideline recommendations did not translate into measurable improvements of short-term clinical outcomes. To improve clinical outcomes, future investigations on PAD guideline implementation should consider focusing on specific recommendations or targeting long-term outcomes.
Mitochondrial pathogenesis of propofol infusion syndrome in an vitro model of human skeletal muscle A. Krajčová Introduction: Propofol infusion syndrome is a rare, but serious adverse effect of a commonly used drug with a very high mortality rate (˃50 %) [1] . The symptoms can occur in various combinations and include: unexplained metabolic acidosis, arrhythmia, Brugada like pattern on electrocardiograph (elevated ST-segment and coved-T wave), cardiac and/or renal failure, rhabdomyolysis, hyperkalaemia, hepatomegaly and hyperlipidaemia. The mechanism of the syndrome is still unknown: experimental studies performed on animal models and clinical features of the syndrome are suggestive of its mitochondrial origin. Objectives: We hypothesize that propofol decreases respiratory chain capacity, inhibits fatty acid oxidation and induces inner mitochondrial membrane uncoupling in a dose-dependent manner. Our study aims to test this hypothesis in vitro by exposing human skeletal muscle-derived cells to a range of propofol concentrations for 4 days.
Methods: Skeletal muscle cells were isolated from biopsies obtained from patients (n = 16) undergoing hip replacement surgery and subsequently exposed to a range of propofol resembling clinical concentrations in human plasma during propofol infusion (0, 1, 2.5, 5 a 10 μg/ml) and to lipid vehicle (Intralipid® -IL). After 96 hours of exposure, mitochondrial metabolism was assessed by extracellular flux analysis (Seahorse Biosciences). Oxygen consumption rate (OCR) was measured at baseline and after addition of ATPase inhibitor, mitochondrial uncoupler and complex III inhibitor. Injection of these agents enables to calculate baseline OCR, ATP turnover rate, proton leak through inner mitochondrial membrane and respiratory chain capacity (uncoupled respiration). The capacity of fatty acid oxidation was measured as etomoxir-inhibitable OCR after adding of uncoupler and palmitate. Values presented in Table 20 are expressed as % of baseline OCR. Results: In human skeletal muscle cells exposed to propofol, respiratory chain capacity was decreased and uncoupling of inner mitochondrial membrane was increased. The most significant result was propofol-induced inhibition of fatty acid oxidation to 15 %, respectively 11 % of baseline values (see Table 20 ). Data are presented as median (interquartile range). Statistically significant results are signed as * if p-value < 0.05, ** p-value < 0.001. Conclusions: Propofol, in clinically relevant concentrations, is a potent inhibitor of fatty acid oxidation and induces changes in a function of respiratory chain in an in vitro model of human skeletal muscle.
References Introduction: Anaemia affects 60-80 % of patients admitted to critical care (ICU). 1 Allogeneic red blood cell (RBC) transfusions remain the mainstay of treatment for anaemia but are associated with risks 1 and are costly. Some patients may have true iron deficiency and could benefit from iron replacement, reducing the need for transfusions. However, diagnosing iron deficiency in ICU patients is difficult due to the unreliability of serum ferritin in the context of co-existing inflammation. Objectives: To assess the efficacy and safety of iron supplementation, by any route, in anaemic patients in adult ICUs. Methods: We searched multiple databases (CENTRAL, MEDLINE, EMBASE) for RCTs comparing iron by any route with placebo/no iron. Two investigators independently assessed eligibility and extracted data. The primary outcomes were RBC transfusion requirement, mean number of transfused RBCs and mean haemoglobin (Hb) concentration. Secondary outcomes included mortality, infection, length of hospital stay, health-related quality of life (QoL), mean difference in iron biomarkers (e.g. ferritin) and adverse events. Outcomes were assessed at two time points: (i) short-term -up to 10 days and (ii) mid-term -last measured time point in hospital or end of the trial. Risk of study bias was assessed using Cochrane methodology. Metaanalyses were performed in RevMan v5.3 using random effects models. Continuous variables were reported as mean difference (MD) with 95 % confidence interval (CI); dichotomous variables were reported as relative risk (RR) with 95 % CI. Results: Five trials consisting of 613 patients were included for meta-analysis. 2, 3, 4, 5, 6 Four trials were set in surgical ICUs and one in a mixed ICU. Only one trial was rated at low risk of bias in all domains. There was variation in dosage regimes, from 3x/weekly administration of intravenous iron to daily oral iron for up to 30 days post discharge. Results are shown in Table 21 . No trials reported on QoL. Conclusions: Iron supplementation does not reduce RBC transfusion requirements in adult ICU patients. Larger, well-designed trials are needed to investigate the benefits and risks of iron, optimal dosing regimes and strategies to identify patients likely to benefit together with patient-focused outcomes such as QoL after discharge. Introduction: Intensive care is lifesaving, but associated with the development of physical, mental and cognitive problems in survivors.
Intensive care aftercare has emerged to help patient recovery and return to normal life. Guidelines focus on promoting recovery and improving quality of life. More insight is needed into the mechanisms of intensive care recovery.
Objectives: To describe the patient experience of recovery from a longitudinal perspective by analyzing follow-up consultations at three time-points. Methods: The study had a descriptive multicenter longitudinal qualitative design. We selected strategically a sub-sample of 36 consultations with 12 patients from a randomized controlled trial on intensive care recovery from ten Danish intensive care units (ICUs). Data were prospectively collected through the intervention and were audio-recordings of three follow-up consultations (at 3, 5 and 10 months), patient photographs during ICU-stay, and reflection sheets. First consultation focused on patient's narratives of ICU supported by photographs to aid memory. Second and third consultations focused on patient-centred dialogs of what was most important by guided by patients reflection sheets. Thematic analysis and narrative theory were used to explore the mechanisms of recovery after intensive care (1) . Results : The basic narrative of recovery was "toward a trajectory of new orientation". The narrative at 3 months described mortal illness in ICU (Being at Death's door), the narrative at 5 months described ongoing fear of relapse (Still not out of the Woods), and the narrative at 10 months had three potential outcomes: downhill (detour on the road), steady-state (end of the road), or progress (The Road to Recovery). New orientation was obtained in steady-state or progressive recovery, Fig. 21 .
Conclusions: This study provides a contemporary understanding of the process of intensive care recovery. Recovery evolves through narratives of mortal danger, fear of relapse and different types of progress toward a new orientation in life. Nurse-led follow-up consultations help patients to obtain a sense of coherence during the first year after critical illness. These findings enable healthcare professionals to understand what patients experience during stages of recovery by offering dialogue and supporting the construction of a coherent illness narrative with ICU staff and close relatives. This shared understanding is important to improve nursing and healthcare professionals in the assessment of long-term outcome, and management of patients after intensive care. Protective skin products are developed, but it is uncertain whether the use of such products is not associated with a higher rate of dressing disruption, which is also a risk factor for CLABSI [1] . On the other hand, a transparent dressing with a chlorhexidine gluconate (CHG) containing gel pad at the insertion site prevents CLABSI. Objectives: To compare transparent catheter dressings either with or without the application of a protective skin ointment for skin integrity, dressings disruptions and dwell time; in addition, we assessed rates of catheter colonization and CLABSI in transparent dressing either with or without a CHG-pad. Methods: We conducted a monocentric, open-label, randomized, controlled trial (Aug.-Dec./2014) to compare transparent CHG-dressings with use of a skin ointment creating a polymer protective film (Cavi-lon®) (intervention group) with standard transparent dressings without the skin product (control group). Standard catheter care included 0.5 % CHG in 70 % ethanol for skin preparation before CVC insertion and maximal sterile barriers. Dressings were changed /7 days, or in case of full dressing disruption (revealing the insertion site) or if moisture was present under the dressing. Results: Sixty patients with a central venous catheter (CVC) were enrolled accounting for 60 CVCs and a total of 533 CVC days. Study groups did not differ in sex, age, insertion site and the number of CVC lumens, comorbidities, severity of condition, length of hospital stay before enrollment, or concomitant therapy. Dressing dwell time was higher in the intervention group: 6.3 (SD 1.5) vs 2.0 (SD 1.1) days (p < 0.001). The Table describes reasons for dressing changes and skin integrity after dressing removal. CVC dwell time did not differ between the groups: 9.7 (SD 3.5) days in the intervention group and 8 (SD 3.9) days in the control group (p > 0.05). Rates of CVC colonization were not different (37.9/1000 CVC days in the intervention group vs. 37.0/1000 CVC days in the control arm [relative risk 1.22, 95 % confidence interval 0.59-2.5]) as were CLABSI rates (6.9/1000 vs 20.6/1000 CVC days [relative risk 0.4, 95 % confidence interval, 0.08-1.9]). Conclusions: The use of a skin ointment creating a polymer protective film beneath transparent dressings results in longer dressing dwell times and less skin breakdown. The application of the skin product does not alter the risk of infection, at least not when used combined with a CHG-impregnated dressing. Introduction: More ICU programs are emerging to promote psychological recovery after a stay in intensive care unit (ICU) (1) . In the Scandinavian countries, patients' discharge rehabilitation plan usually includes physical training, but seldom psychological rehabilitation. To address this gap, we developed a post-ICU recovery program to improve psychological health after intensive care. We hypothesized that a nurse-led recovery program, that helped to construct a coherent illness narrative including person-centered communication, would improve health-related quality of life (HRQOL), sense of coherence (SOC), reduce symptoms of anxiety, depression, and post-traumatic stress (PTSD) in the first year after ICU discharge. Objectives: To investigate the effectiveness of a post-ICU recovery program compared to standard care in improving quality of life in the first year after ICU. Methods: We randomly assigned 386 patients adult (≥18 years) survivors after receiving mechanical ventilation (≥48 hours) to standard care (SC) plus a recovery program or SC alone after discharge from intensive care. It was a nurse-led intervention consisted of patient photographs, three follow-up consultations and reflection sheets. Results: Primary outcome was HRQOL, and secondary outcomes were SOC, anxiety, depression, PTSD assessed at 3 and 12 months after intensive care discharge using t-tests. We supplemented outcomes with rehabilitation services within the first year. At 12 months after intensive care the HRQOL scores were unchanged by the intervention (mean difference in the Mental Component Summary score, 0.9 [95 % CI, −1.5 to 3.3; P =0.47]; and in the Physical Component Summary score, 1.1 [95 % CI, −1.3 to 3.5; P = 0.37]). No differences were found for the total score on self-reported SOC, anxiety, depression, and PTSD. The intervention showed a potential effectiveness on the rate of anxiety, when a cutoff score ≥11 was applied, in the complete analysis at 3 months. However, all patients received high level of rehabilitation services as SC within the first year after intensive care.
Conclusions: Overall, no beneficial or detrimental effects were found on either primary or secondary outcomes, but the symptoms were generally lower that found in similar studies. Patients maintained good mental health and a strong sense of coherence, but the PTSD score was consistently high. The high quality of standard care in Danish ICUs might help explain the lack of improvement in this study. Introduction: Enabling clinicians to prospectively identify patients who will later become unstable would enable targeting resources to patients most in need as well as potential application of preventive care. Objectives: To determine the incremental contribution of information progressively available within the first 4 hours of (SDU) admission to improve models forecasting later development of cardiorespiratory instability (CRI), including a novel CRI relative risk score. those never displaying CRI (controls, n = 1053) were identified. We computed a minute-by-minute integrated CRI risk score based on the method described in [1] , using features computed from VS data streams during trailing 15 minute rolling windows and a trained random forest machine learning model. We then computed for each patient a mean risk score aggregated from the risk scores during first 4 hours of SDU stay. Next we built a logistic regression model to forecast whether or not there will be a CRI event in the future. To mimic the temporal availability of data following patient admission, we first entered demographics available at patient admission (age, gender, Charlson Comorbidity Index score) into the model, and then the initial VS (5-minute average of continuous VS data accrued from minutes 10 to 15 after admission), and finally the relative risk score derived in the first 4 hours. We assessed the predictive contribution of information from these 3 progressively accrued categories (demographics, initial VS, 4-hr risk score) by the Area Under Receiver Operating Curve (AUC) in a 10-fold cross validation experiment setup.
The risk score derived from admission demographics alone yielded an AUC of 58 ± 0.002 % to forecast future CRI. Adding the initial VS improved the AUC to 64 ± 0.003 %, and with further adding the 4-hr risk score the AUC became 67 ± 0.002 %.
Conclusions: A predictive model which incorporates patient data as it becomes available, including a risk score derived within the first Introduction: Physical activity / rehabilitation forms a pivotal aspect of recovery after critical illness and studies have demonstrated it is safe, feasible and potentially efficacious at improving patient outcomes [1, 2] . However, international data demonstrate low levels of mobilisation occur in the ICU [3, 4] . A current gap exists between the perceived need and actual practice of implementing physical activity across the recovery continuum. Objectives: To identify, evaluate and synthesise studies examining the barriers and enablers for patients with critical illness to participate in physical activity from the perspective of healthcare providers, patients and caregivers. Methods: Systematic review of articles using electronic databases: MEDLINE, CINAHL, EMBASE, Scopus and Cochrane. Quantitative and qualitative studies which assessed the barriers, or enablers to physical activity for patients with critical illness were included. Registered on PROSPERO (number: CRD42016035454).
Results: 79 studies were included. Studies included primarily ICU survivors (69 %, n = 54 studies), healthcare providers (29 %, n = 23 studies) with only one study specifically examining caregivers and patients. Barriers and enablers to physical activity were identified (5 major themes and 28 sub-themes). Patient-level barriers included physical capability (physiological stability, illness severity, sedation, weakness, delirium), psychological influences (fear/motivation) and perceived relevance. Healthcare provider barriers included lack of time/ knowledge and expertise, communication, and concern for line safety.
Environmental barriers included lack of resources (staffing and equipment), lower prioritisation, and lack of an established rehabilitation pathway post ICU. Enablers included: presence of mobility teams/ protocols, designated discipline and overall leaders, teamwork and development of daily care plans.
Conclusions: This systematic review has identified the volume of literature demonstrating that barriers and enablers to physical activity are multi-dimensional and span diverse factors. These factors need to be considered when developing rehabilitation interventions to facilitate cultural change in rehabilitation practices across the recovery continuum.
within the interdisciplinary team, involvement of nurses in EOL, active DM by physicians, and ethical awareness) yielded 4 climates: good, average with and average without involvement of nurses at EOL, and fourth a poor EOL-DM climate. When looking at overall perceptions, there were for all seven factors significant differences (p < 0.001) between nurses and physicians, with physicians consistently perceiving the EOL-DM climate as more positive as nurses. The largest differences were found in regard to physician leadership (median factor scores -0.09 for nurses and 0.61 for physicians, respectively), interdisciplinary reflection (medians -0.03 and 0.51) and not avoiding EOL decisions (medians -0.07 and 0.37). When looking at differences within the 4 types of EOL-DM, the same general pattern was found, and all differences were statistically significant (p < 0.001). The differences were largest in the two lowest types of EOL-DM: average without nurses and poor EOL-DM climate. Head nurses generally had a more positive perception of EOL-DM climate compared to other nurses, and senior physicians had a more positive perception than junior physicians. When comparing nurses (without including head nurses) and junior physicians, the physicians still had a significantly higher perception of EOL-DM, except for "Mutual respect within the interdisciplinary team" (p = 0.26). Physicians having a more positive perception of EOL-DM compared to nurses were found within all 13 participating countries and within the individual ICU's. Introduction: There is increasing recognition of the need for comprehensive expertise in the management of EOLC in the ICU. However there appear to be many controversies between professionals regarding optimal provision. Objectives: As a component of a local, on-going quality improvement process in this area, we performed a survey of nurses' perceptions of aids and obstacles to the optimal provision of EoLC. Methods: We modified a previously validated survey tool 1 and anglicised the language. Nurses were asked to rate both the size and frequency of 20 possible obstacles and 14 possible aids to providing EoLC using a 6 point Likert scale (0-5). The survey was distributed to 120 nursing staff on one adult general critical care unit in March 2015.
Confidentiality was assured. For each obstacle and aid, the median and interquartile ranges were determined for the size and frequency. To determine the effect size of each obstacle and aid, the median of the size was multiplied by the median of the frequency. These were then themed Results: Sixty surveys were returned representing a 50 % return rate.
Conclusions: This study has highlighted the need to proactively identify a family liaison to cascade information to friends and relatives to allow nurses to concentrate on care delivery. Despite having a poor unit design and lack of privacy, nurses feel they can provide a dignified death and feel that multidisciplinary agreement is an important part of this process. Mean length of stay (LOS) was prolonged and level of organ support was high. These results are summarised in Table 25. LOT was instigated in 9 (11.5 %) patients. Age and APACHE II scores were similar in patients with LOT and those with none. Frail patients had a higher LOS and received more organ support compared to non-frail patients. The proportion of patients with LOT remained low despite an increasing LOS. Communication between team members was sub-standard with 33 % of bedside nurses and 44 % of residents being unaware of these decisions. The re-audit after intervention demonstrated an increase in patients receiving LOT, with a higher proportion of frail patients being represented. These patients also received less organ support and LOT was instigated earlier in their stay. Awareness regarding these decisions amongst all staff improved to 100 %. Feedback regarding the communication tools was excellent. Introduction: Previous studies showed that low nurse staffing levels were associated with poor outcomes and increased occurrence of adverse events. However, national data are scarce regarding the relationship between the nurse staffing ratio and pediatric patient outcomes. Objectives: To investigate the association between nurse staffing levels and the outcome of pediatric patients in Korean intensive care units (ICUs).
Methods: This retrospective cohort study used data from National Health Insurance claims. The included patients were under 18 years old and admitted to ICUs (but not neonatal ICUs) between August 2009 and September 2014. The ICU nurse staffing was graded into nine levels according to the total bed to nurse ratio for each hospital (National Health Insurance policy). The lowest and highest bed-to-nurse ratios were 0.5:1 and 2:1, respectively. We inspected the differences between overall patient mortality and the nursing staff grades at discharge. We also analyzed the mortality of patients who underwent mechanical ventilator care for more than 3 hours according to the nursing staff grades.
Results: During the study period, 39,917 medical and surgical pediatric patients were admitted to the ICUs. Mechanical ventilation was administered to 45.9 % of these patients. The median (interquartile range) ICU length of stay was 2 (1-6) days. The overall hospital mortality rate was 5.5 %, and the mortality rate of mechanically ventilated patients was 10.8 %. About half of the patients (18,053; 45.2 %) received the highest grade ICU treatment. The overall mortality rate did not increase with a higher bed-to-nurse ratio (i.e., lower nurse staffing level). However, a trend toward increased mortality was observed in mechanically ventilated patients as the bed-to-nurse ratio increased. The mortality of mechanically ventilated patients was 7.6 % for a bed-to-nurse ratio < 0 Conclusions: EK is common in critically ill patients, and is associated with mechanical ventilation and lagophthalmos. A simple protocol substantially reduced the incidence of EK and was easily achieved in clinical practice.
Introduction: The loss of muscle mass in critical illness is caused by a mismatch between synthesis and degradation, where synthesis is near-normal, while degradation is enhanced, resulting in a negative protein balance. A muscle mass loss of 10 % per week is reported. Studies supporting this mechanism are almost exclusively from patients during the initial two weeks of critical illness.
Objectives: To investigate if this mechanism is valid also in a longer time perspective we studied critical ill patients during days 10-40 of ICU stay. Methods: Critically ill patients on mechanical ventilation (n = 20) were included, multiple times if possible. In total 30 measurements of muscle protein turnover were performed employing a 3-pool model technique with a constant infusion of d5-phenylalanine, leg blood flow measurements, and biopsies to determine tissue enrichments.
Results: Net protein balance of leg mixed muscle showed a pattern of becoming less negative over time with regression analyses. This pattern was totally attributable to an increase in protein synthesis rate, while protein breakdown rate, although higher than in healthy subjects, was completely unaltered over time. Net protein balance during days 10-20 (-21 ± 21 nmol phenylalanine/min/100 g muscle) was lower (p = 0.002; T-test) than during days 30-40 (1 ± 11 nmol phenylalanine/min/100 g muscle).
Conclusions: The temporal pattern of protein turnover in leg muscle showed a pattern of diminished protein losses over time in surviving patients staying in the ICU. How this pattern relates to nutrition, mobilization, and pharmacology remains to be established. Introduction: Critically ill patients exhibit a high degree of vitamin C deficiency at ICU admission and plasma concentrations decrease even more during the following days [1, 2] . High intravenous (iv) doses of vitamin C are required to increase plasma concentrations to normal and supra-normal ranges [2] , but the optimal dosage regime in this population remains unclear. Prolonged vitamin C administration may be associated with oxalate kidney stone formation, but the effect of short-term high-dose supplementation on urinary oxalate excretion is unknown. Study design and objectives: We conducted a prospective randomized controlled trial to determine the pharmacokinetics of four high dose regimes of iv Vitamin C in critically ill patients and to measure oxalate excretion. Patients:. Adult patients admitted to the ICU with sepsis or SIRS, with a non-neurological sequential organ failure assessment (SOFA) score >6 and an expected length of ICU stay >96 hours.
Intervention: Patients were randomized to either 1 g or 5 g vitamin C twice daily as a 30-min bolus infusion, or to 2 g or 10 g daily as a continuous infusion. Vitamin C administration was continued for 48 hours, so that all patients received a total dose of either 4 g or 20 g vitamin C.
Measurements: Concentrations of vitamin C were determined in plasma at t = 0, 1, 2, 4, 8, 12, 24, 36, 48, 72 and 96 hours. Urine vitamin C and oxalate concentrations were determined during the first and last 12 hours of vitamin C administration. NONMEM was used for the pharmacokinetic analysis.
Results: Fourteen patients were included: 5 patients received 1 g vitamin C and 5 patients 5 g vitamin C iv twice daily for two days. Two patients received 2 g/day vitamin C and 2 patients received 10 g/day by continuous infusion for two days (Table 26) . Four patients (28 %) were vitamin C deficient on admission (<20 μmol/L). A two-compartment pharmacokinetic model best described the data (Fig. 23 , model parameters not shown). The urinary excretion of vitamin C and oxalate is shown in Table 27 . Conclusion: Normal vitamin C plasma levels are attained with either 1 g iv twice daily or 2 g as continuous infusion. A bolus infusion is needed for rapid achievement of high-normal plasma concentrations. Both high-dose regimes produce supra-normal plasma concentrations. With continuous infusion, urinary vitamin C loss was lower and a higher proportion remained in the body. The urinary excretion of oxalic acid increased with higher vitamin C doses. However, at the time of cortisol retesting, patients with lower cortisol levels had significantly longer length of ICU stay (p = 0.038). Time interval between two cortisol sampling was (median, IQR) 12 days. Time interval between higher and lower cortisol groups did not reach statistical significance. When glucocorticoid therapy was begun in the lower cortisol group, vasopressors were weaned within 48 hours; vasopressor weaning was longer and varied in higher cortisol group. Conclusions: Adrenal response is a dynamic process. During the course of critical illness, as with other organs, adrenal failure may develop. With these findings, adrenal exhaustion seems to be a complication of prolonged critical illness. We suggest prolonged vasopressor dependency should prompt a search for adrenal exhaustion, even if initial cortisol testing results are within normal limits. Identifying patients that could benefit from corticosteroid therapy may be a life-saving measure.
Introduction: Early and sufficient enteral intake is associated with reduced ICU morbidity and mortality. Limited data suggests that use of nurse-driven feeding protocol with defined targets may facilitate nutrition and improve the outcomes. Objective: To investigate whether implementation of nurse-driven feeding protocol results in increased enteral caloric intake in critically ill patients during their first week in the ICU. Methods: We performed an uncontrolled before-and-after study. Data of consecutive adult patients, readmissions excluded, treated for at least 7 days in General ICU of Tartu University Hospital, were extracted from existing database. In 2013, nurse-driven feeding protocol was instituted in the department [1] . Cumulative proportion of patients who did not receive any enteral feed was significantly smaller in After group (Fig. 24) . Percentage of enterally received calories from caloric needs was significantly higher in After group (Fig. 25) . Prevalence of GI symptoms and intra-abdominal hypertension was not different between the groups. ICU length of stay was significantly shorter in After group (11 vs 13 days, respectively, p < 0.001), but no difference was noted in duration of mechanical ventilation and ICU mortality.
Conclusions: Use of nurse-driven feeding protocol in ICU patients is associated with improved enteral nutrition without an increase of GI complications. that the capillary escape rate of albumin is increased, related to an enhanced capillary leakage, but the return to plasma through the lymphatic system is not characterized. Nevertheless it is necessary to postulate an enhanced degradation rate or increased volume of distribution, to explain this finding. Objectives: We explored 3 different techniques to assess albumin turnover and degradation. Methods: Healthy volunteers (n = 10) were studied over 42 days. The first day, albumin synthesis rate was measured in the postabsorptive state by the in vivo incorporation of d5-phenylalanine, and a dose of 125 I-albumin was given to assess albumin degradation. Degradation rate was measured and calculated by the decay in radioactivity in 2 ways; in urine collected over 24 hours at 3 separate days, and in plasma repeatedly over 42 days. Results: Basal albumin synthesis rate was 118 ± 16 mg/kg/day, equal to degradation rate in steady state. Catabolic rate by urine sampling was 142 ± 31 mg/kg/day (P = 0.022 v. basal), and by plasma 177 ± 29 mg/kg/day (P = 0.001 v. basal). Conclusions: The differences in calculated turnover rates may correspond to effects of feeding or differences in half-lives between exogenous and endogenous albumin. The exact explanation needs to be further investigated. Introduction: A low plasma glutamine concentration at ICU admittance is associated with an unfavorable outcome. A number of studies have shown beneficial effects of exogenous glutamine supplementation to unselected critically ill patients. However, recently harm is reported when pharmacological doses of exogenous glutamine is given to underfed unselected ICU patients with ≥ 2 organ failures. The mechanism behind this finding is not understood and more specifically the reason for the low levels is not known. Objectives: The relation between plasma glutamine concentration and glutamine production rates. Methods: Critically ill patients (n = 17) with normal or low plasma glutamine concentration were studied. Glutamine rate of appearance reflection glutamine production rates was determined employing a bolus dose technique, and the decay curves were fitted into a single pool or a 2-pool model. Results: Glutamine rate of appearance was in the range 5 -15 umol/ kg/min in ICU patients with plasma concentrations in the range300-700 umol/L. There was a statistical significant (P < 0.05) relation, but the coefficient of determination was low R 2 = 0.15. Also the correlation between the 1-pool and 2-pool models was statistically significant (P < 0.01), but the coefficient of determination intermediary R 2 = 0.60. Conclusions: To understand the results of recent glutamine supplementation studies in the critically ill, the relevance of plasma glutamine levels must be under stood. In healthy volunteers there is a high concordance between 1-pool and 2-pool models to calculate the rate of appearance. The lower agreement in ICU patients indicates that a more extensive modeling may be necessary. Introduction: The prevalence of malnutrition in ICU has been estimated at up to 40 % with the majority of critically ill patients requiring nutritional support. Traditional teaching suggests that early enteral feeding in mechanically ventilated septic patients is superior to parenteral feeding due to a lower complication rate but neither form of support is without risk. Objectives: In this study, we compared the outcomes in mechanically ventilated septic ICU patients receiving enteral versus parenteral nutrition.
Methods: A single centre study of patients admitted to a 25 bed University Hospital ICU over a period of three years. Demographics, severity of illness scores (APACHE and SOFA), BMI and MUST were measured upon admission. Daily nutrition requirements were calculated for each patient. Patients were randomized to enteral(EN) or parenteral nutrition(PN) group within 48 hours of intubation and admission to the unit. Duration of mechanical ventilation, ICU and hospital length of stay (LOS), and mortality rates were recorded. Results: A total of 148 patients (76 men) mechanically ventilated septic patients having a mean(±SD) age of 69.6 ± 19.4 years were studied. All patients met the consensus criteria for sepsis. Baseline characteristics were similar in the two groups. APACHE II and SOFA at study entry were 24 ± 5 and 8 ± 3 respectively. The mean(±SD) BMI was ≈ 21.5 ± 3.4 kg/m 2 . Seventy seven (52,02 %) patients received EN, and sixty nine (47,26 %) received PN. There was no difference between the two groups for age, sex, BMI, and scores. ICU and hospital LOS were similar for both groups. ICU mortality rate was 29.4 % for PN group vs. 27.2 % for EN group indicating no significant difference. Hospital mortality was similar for both groups as well. In the PN fed group however, duration of mechanical ventilation was longer (p = .018), but the feeding goal was attained earlier (p = .009). Conclusions: In mechanically ventilated septic ICU patients the ICU LOS and the hospital LOS, as well as the ICU and hospital mortality rates of patients receiving PN are not significantly different than those in patients receiving EN. Furthermore, feeding goals can be attained much easier by PN. Duration of mechanical ventilation however appears to be longer in patients receiving PN.
Association between the route of nutrition and adipokine hormones levels in critically ill patients: a pilot study K. Gundogan 1 , E. Dogan 2 , R. Coskun 1 , S. Muhtaroglu 3 , M. Sungur 1 , T. Ziegler 4 , M. Guven 1 Introduction: Adipokine hormones play an important role in regulation of insulin metabolism, body fat distribution and regulation of appetite and satiety. Some adipokine hormones have effects on inflammation and insulin resistance but the relation between these hormones and critical illness and the route of nutrition is not known. Objectives: The aim of this study to determine association between nutrition route and adipokine hormones levels in critically ill patients Methods: This study was performed prospectively in Medical and Surgical ICU at Erciyes University. Patients expected to stay in ICU at least 72 hours and received either parenteral or enteral nutrition included into the study. Results: Total of 26 patients were included into the study and 17 of them were male (65 %). The mean age was 62.8 ± 18.2 years. Total of 14 patients (54 %) were fed via enteral route and 12 patients (46 %) were received parenteral nutrition. The mean APACHE II score was 22.7 ± 7.1. Resistin levels were lower in enteral nutrition group at 24th (p = 0.015) and 72nd hours (p = 0.014) compared to parenteral nutrition group. Baseline, 24.th hours and 72.th hours GLP-1 levels were found to be higher in enteral nutrition group than parenteral nutrition group (p = 0.031, p = 0.006 and p = 0.001 respectively). Adiponectin levels were significantly higher in enteral nutrition group compared to parenteral nutrition group at 72th hour (p = 0.014). Conclusions: Our study showed that enteral nutrition helped to reverse abnormal process in critically ill patients with increasing adiponectin and GLP-1 levels and decreasing resistin levels. Introduction: A switch from carbohydrate to fat utilization is a hallmark of systemic inflammation. While this adaptive response occurs quickly and allows animals to survive under restricted food supply conditions, it will markedly affect cell metabolism. Objectives: To elucidate molecular mechanisms underlying the substrate switch from carbohydrate to fat in different organs, we studied early alterations in (i) phosphorylation of enzymes involved in energy metabolism: AMP kinase (AMPK, thr172), acetylCoA carboxylase (ACC ser179), pyruvate dehydrogenase (PDK ser293), hormone sensitive lipase (HSL ser563); and (ii) expression of mitochondrial uncoupling proteins 2 and 3 in soleus and gastrocnemius skeletal muscle, liver, kidney and heart in sham-operated and septic rats at 6 h in our wellcharacterized 72 h fluid-resuscitated rat model of faecal peritonitis Methods: Awake, instrumented yet fully mobile male Wistar rats (325 ± 15 g) received an i.p. injection of 4 μl/g faecal slurry. Fluid resuscitation (50:50 mix of 5 % glucose/Hartmann´s; 10 ml/kg/h) was commenced at 2 h. Control animals were treated identically except for slurry injection. At 6 h, an echo-measured heart rate cut-off of 460 bpm was used to classify animals into predicted survivors SR or non-survivors NSR.(1) Animals were killed and organs were immediately collected into liquid nitrogen. Alterations in protein phosphorylation and expression were studied by Western blot. Normalization was performed to loading control: actin or PFK. Results were presented as mean +/-SE, analyzed using Student's t-test and considered statistically significant when p < 0.05. Results: At 6 h post-sepsis no differences were seen in renal and hepatic phosphorylation of AMPK, ACC, PDH and HSL between sham and septic animals. While cardiac ACC phosphorylation was strongly increased in septic rats, AMPK phosphorylation did not differ, suggesting that ACC phosphorylation was mediated not by AMPK but rather via the glucagon-PKA pathway. The biggest changes were observed in skeletal muscle. AMPK phosphorylation was increased in gastrocnemius and even more so in soleus in septic rats but this was not accompanied by a corresponding increase in ACC phosphorylation. In both muscles PDH phosphorylation markedly increased while PDH fell, suggesting a fall in pyruvate oxidative decarboxylation and glucose usage as a fuel. HSL phosphorylation was strongly increased in soleus in non-survivors. UCP2 and UCP3 levels were not altered in any organ. Table 31 . Conclusions: 1) Each organ has its own program for the switch from carbohydrate to fat metabolism. 2) The consequences of these changes on the development of organ dysfunction merit further investigation, as this may lead to novel directed therapeutics.
Introduction: Albeit practical implementation remains a concern, indirect calorimetry (IC) is the first choice technique for estimating energy requirements in critically ill patients. Methods: In our adult mainly surgical intensive care unit (ICU) we retrospectively assessed in 25 patients the utility and practical aspects of estimating the daily energy requirements. We determined energy requirements by IC (Quark, COSMED) and compared the estimates with those calculated by measuring VCO 2 alone using a ventilator (Evita XL; Draeger) or using formulas based on body mass of body mass index. Results: Our study population was found to have an average body mass of 69.7 kg and according to IC and energy requirement of 1987 kcal/day on average. No correlation (R 2 = 6E-05) was found when estimates of IC were compared to estimates based on body mass alone. However using an adjusted mass (based on hight and an assumed body mass index of 23) correlation improved (R 2 = 0.3358). VCO 2 based estimation of energy requirement only weakly correlated with IC (R 2 = 0.414). Weak correlation is explained by assuming a fixed respiratory coefficient for ventilator based energy estimates as well as by imperfect correlation of VCO 2 estimates reported by calorimeter and ventilator (R 2 = 0.6189) Conclusions: Body parameters such as hight or mass aren't suited to predict the patient's energy needs. Albeit promising and simple, estimation of energy requirement based on ventilator derived VCO 2 also fails precision. Whether technical improvements on how ventilators calculate VCO2 can render them more suited in daily praxis will have to be determined in future studies. Introduction: Extracorporeal membrane oxygenation (ECMO) is an advanced treatment to support the critically ill patients with cardiac and/or with severe respiratory failure. It is suggested that ECMO patients are at risk of splanchnic ischemia and thus, enteral feeding is poorly tolerated needing nasojejunal feeding and is potentially unsafe. This study aims to investigate the nutritional adequacy of this patient group. criteria were: patients with H1N1 confirmed by reverse transcriptase polymerase chain reaction who were ≥18 years of age. Exclusion criteria were: unconfirmed cases, patients not seen in the hospital and with missing case notes. Differences in clinical parameters between patients discharged within 24 hours of medical assessment and those admitted to hospital were analysed. A chest X-ray scoring system was also employed to assess the ability of radiographic findings to predict likelihood of discharge. Results: Eighty-six patients were eligible for the study. 17 patients were discharged early and 69 patients were admitted to hospital. P/F ratio and CRP predicted discharge with area under receiver operating characteristic (ROC) curves of 0.788 (CI 0.681-0.894) and 0.763 (CI 0.6377-0.889) respectively, which was higher than triage and bedside tools. The chest radiograph scoring tool did not predict patient discharge (p = 0.191-0.999), but demonstrated very good inter-rater reliability (Cohen's kappa statistic >0.8).
Conclusions: P/F ratio and CRP predicted discharge better other clinical parameters. Both were superior to H1N1 specific triage tools described in the literature. P/F ratio is a simple and effective method to determine oxygen exchange. We recommend this tool in the assessment of patients during influenza pandemic to guide management decisions and future work would involve validation in prospective cohorts.
Introduction: Ventilator-associated pneumonia (VAP) is the most common ICU-acquired infection. Recently, the incidence of extended-spectrum beta-lactamase producing Enterobacteriaceae (ESBLE) has substantially increased in critically ill patients. Identifying patients at risk for VAP related to ESBLE could be helpful to improve the rate of appropriate initial antibiotic treatment, and reduce unnecessary exposure to carbapenems. Gram-negative bacteria were the most common agents in our ICU. Conclusions: To know and close monitoring of the incidence of VAP, microbiological agents associated and its antimicrobial resistance pattern is the key to the adoption of more specific standards ICU rules.
Introduction: Ventilator Associated Pneumonia (VAP) is the most common hospital acquired infection in those requiring mechanical ventilation. It is associated with prolonged length of stay on the ICU, poorer outcomes and increased cost 1 .There is currently no 'gold standard' definition but a high clinical suspicion is often enough to begin treatment. Diagnosis can be complicated as the signs that are seen with VAP are not uncommon in those who are critically ill in ITU, potentially delaying treatment 1,2 .
Objectives: The aim of this project was to establish if there are significant differences between the Triggers which predicted VAPs (VAP We looked at acknowledgment time, differences in values and order of the index parameters between VAP triggers and Non VAP triggers to look for differences suggesting early predictors for positive microbiology and radiology. Microsoft Excel ® was used to manipulate data for analysis and SPSS Statistics 17.0 ® was used to calculate summary statistics, generate tables, perform the student's t-test analysis and produce graphs. Student's t-test was used to analyse statistical significance between groups.
Results: Of the quantitative variables measured, there was no statistically significant difference between the confirmed VAP cases and the non-VAP cases apart from in temperature with non-VAP cases having a higher average temperature, 38.2°C, compared with 37.89°C in confirmed VAP. This notwithstanding we noted a lower mean C-rective protein (CRP), a higher oxygen requirement and a lower White Cell Count (WCC) in confirmed VAP cases.
As would be expected those in the VAP group had secretions most commonly described as creamy with moderate to copious amount.
In terms of trigger order in the confirmed VAP cases, secretion amount was the most common first and second trigger in the VAP alert followed by nonspecific inflammatory markers such as WBC, CRP and temperature.
In the non VAP group, temperature, oxygen requirement (PaO2/FiO2) and WBC were the most common first trigger factors.
Conclusions: In conclusion early Secretion quantity and description predict positive microbiology and radiology compared with other parameters such as temperature, WBC, CRP which do not. Conclusions: Anticoagulation used in our study appears lower than recommendations without increasing thromboembolic complications, with persistence of a high rate of bleeding complications with or without a direct connection with ECMO. Does these results reinforce the idea of lowering the anticoagulation ratio on patients under VV-ECMO? Introduction: Low flow extracorporeal veno-venous CO2 removal therapy (ECCO2RT) in addition to mechanical ventilation is used to remove CO2 while allowing protective ventilation (PV) during ARDS. However, this technique requires anticoagulation that may induce severe bleeding in critically ill patients (1) . An alternative method consists in using citrate anticoagulation.
Objectives: The aim of this study was to assess the effect of citrate anticoagulation on CO2 extraction during ECCO2RT.
Methods: This study was conducted on an experimental model of severe hypercapnic acidosis performed in 2 groups of 3 pigs. In the first group (heparin group), pigs were anticoagulated with a standard protocol of unfractionated heparin while citrate was used for ECCO2RT device anticoagulation in the second group (citrate group). After sedation, analgesia and endotracheal intubation via a cervical tracheostomy, pigs were connected to a volume-cycled ventilator (tidal volume 10 mL/Kg, respiratory rate 20/min, FiO2 1.0, PEEP 5 cmH2O). Severe hypercapnic acidosis was obtained by reducing tidal volume by half. ECCO2RT was started in both groups when arterial pH was lower than 7.2. Pump Assisted Lung Protection (PALP, Maquet, Germany) system was used with two small cannulas to remove CO2. Blood flow in the PALP was successively set at 200, 400, 600 and 0 mL/min, each setting lasting 60 minutes. Sweep gas flow was set at 10 L/ min. CO2 extraction, arterial pH, PaCO2 as well as systemic and pulmonary pressures were continuously followed.
Results: CO2 extraction is depicted in graph 1. Mean arterial pH was normalized to 7.37 ± 1.4 at an extracorporeal blood flow of 400 mL/ min, coming from 7.11 ± 1.3. Arterial pH did not significantly changed in the citrate group as compared to the heparin group.
Conclusions: Using citrate anticoagulation during ECCO2RT is feasible. A trend toward better CO2 extraction was observed in the citrate group but not statistically significant as compared to the heparin group.
(1) Kluge (Fig. 33) . The POC tests evaluating the intrinsic and extrinsic coagulation pathways, as well as the thrombin receptor activating peptide-6 test (TRAP-AUC) assessing platelet aggregometry, were different between groups, even though not statistically significant (Fig. 34 ). There was no difference in PT, aPTT, anti-Xa activity, fibrinogen and ACT between groups. . Currently only low tidal volume ventilation has been proven to reduce mortality in all patients with ARDS [2] . This is frequently difficult to achieve in the presence of hypercapnia. Decreases in ventilatory driving pressure have been strongly associated with ICU survival [3] . It has been hypothesised that ventilation combining reduced tidal volumes with extracorporeal carbon dioxide removal (ECCOR) may result in further improvements in mortality [4] , and prospective randomised trials are planned [5] . Objectives: To assess in patients with severe ARDS and acidosis secondary to hypercapnia if by using veno-veno ECCOR there can be a normalisation of pH and reduction of peak airway pressures. Secondary outcomes -survival to hospital discharge and complications of therapy.
Methods: Data on ventilatory and arterial blood gas parameters before and during therapy was prospectively collected and entered into the Extracorporeal Life Support Organisation (ELSO) registry in line with national guidance [6] . The Hemolung RAS (A Lung technologies) was used to provide ECCOR. Results: 4 patients received ECCOR using the Hemolung. All patients had an improvement in the degree of acidosis with mean hydrogen ion concentration falling from 72.65 nM (pH 7.14) to 46.59 nM (pH 7.33) over the first 24 hours, with a mean PaCO2 fall from 13.5 kPa to 8.7 kPa. Peak airway pressures dropped from 31.5 cmH2O to 29.1 cmH2O over the same time period. There were no direct complications of therapy. 3 patients survived to hospital discharge. Discussion: Using ECCOR locally in patients with severe ARDS it is possible to lower the hydrogen ion concentration improving the degree of acidosis. This corresponds to a trend in lower peak airway pressures, which in this small case series does not reach statistical significance. There were no complications of the therapy and mortality was shown to be lower then quoted in other ARDS trials [1] .
Our experience with A-V ECCO2r device (Novalung iLA) in the district general hospital setting P. Remeta 1 , P. Introduction: Fluid overload is associated with worse outcomes in critically ill patients.
Objectives: The aim of this study was to investigate the impact of fluid overload (FO) at initiation of renal replacement therapy (RRT) in critically ill patients with acute kidney injury (AKI). Methods: We performed a retrospective analysis of all patients who were treated with RRT for AKI in the multi-disciplinary Intensive Care Unit (ICU) at a university hospital in London (UK) between 2012 -2015.Total cumulative fluid balance on day of initiation of RRT was used to describe fluid accumulation and estimated in % of baseline body weight (BW). FO was defined as fluid accumulation greater than 10 % of BW. We collected data related to patient demographics, anthropometrics and SOFA score. Outcomes were hospital mortality and length of stay in ICU.
Results: 1129 patients received RRT for AKI of whom 42 % died in hospital. There was a significant difference in cumulative fluid balance at initiation of RRT between hospital survivors and nonsurvivors. (Fig. 35 ) 108 patients (9.6 %) had FO >10 %. They had a significantly higher hospital mortality (X 2 = 5,89; p = 0,015) and longer stay in ICU (19.6 days versus 12.8; p < 0,001) but also higher SOFA score compared to patients with FO ≤10 %. (Table 36 ) Conclusions: In critically ill patients with AKI, fluid overload at initiation of RRT was associated with a significantly higher mortality and longer stay in ICU. respectively.For NMNP cases (57 %) both actual and expected mortality rates decreased with increased fluid volume (8.3 % at 1 L, 6.6 % at 9 + L). Patients receiving pressors and MV (17 %) exhibited minimal variation in expected mortality but presented with a decrease in mortality from low to middle ranges (23.2 % at 1 L to 15.7 % at 5 L) and an increase in mortality from middle to high ranges (15.7 % at 5 L to 25.4 % at 8 L). The highest severity group exhibited no change in actual or expected mortality with fluid administration. Septic shock requiring MV (13 % of cases) had no variation in mortality across the lower groups of day 1 fluid use (1 L to 5 L). However, higher ranges of 6 + L (38 % of the group) had increased actual mortality rates (40 % at 6 L to 45 % at 9 + L), higher than predicted.
Conclusions: A potential for both under resuscitation and over resuscitation is observed in patients with AKI who received treatment with vasopressors in those requiring pressor and MV support a clear association existed between volume excess and outcomes emphasizing the need for a better understanding of individual fluid needs in this important population.
Introduction: Laparoscopic abdominal surgery has been widely used to reduce length of stay and complications from open abdominal surgery. During the operation, pneumoperitoneum needs to be created for better visualization of operating fields. This is followed by decreased urine output and resulted in acute kidney injury. However, we do not know the effect of pneumoperitoneum and factors inducing acute kidney injury (AKI). Objectives: We aimed to 1) show the incidence of AKI in patients undergone laparoscopic abdominal surgery and 2) propose a set of risk factors associated with the development of AKI following laparoscopic abdominal surgery Methods: All patients underwent laparoscopic abdominal surgery at King Chulalongkorn Memorial hospital, Bangkok, Thailand were prospectively enrolled between 2012 and 2013 (n = 64). Two were excluded due to preexisting chronic kidney disease and NSAIDs use in previous 1 week. Baseline characteristics, laboratory results, and introperative data were prospectively recorded in case record forms. Urine neutrophil gelatinaseassociated lipokalin (NGAL) was measured as the surrogate marker. AKI was identified by KDIGO criteria. Characteristics were analyzed by student´s t-test and nonparametric test. Factors associated with AKI were identified using the logistic regression and the area under the receiver operating characteristics curve (AUC). Results: Of the 62 patients receiving laparoscopic abdominal surgery, 12(19 %) developed postoperative AKI. The mean age, initial blood pressure, and initial glomerular filtration rate were not different between AKI and non-AKI groups. The peak serum creatinine was seen at 24 hours postoperatively. AKI patients had significantly increased urine NGAL level at 24 hours postoperatively compared to non-AKI (p = 0.01). Mean operative time, inflation time, and exposure index, defined by the product of inflation time and intra-abdominal pressure were significantly higher in AKI compared with non-AKI patients (p < 0.05 for all). Duration of intraoperative hypotension, amount of blood loss and intravenous fluid were not different between groups. By multivariate analysis, exposure index was significantly associated with postoperative AKI, with adjusted odds ratio (95 % CI) of 1.59 (1.02-2.38). AUCs of inflation time, operation time, and exposure index were 0.68, 0.67, and 0.67, respectively (p < 0.05).
Conclusions: Postoperative AKI can occur in patients undergone laparoscopic abdominal surgery. A larger cohort is required to confirm these findings.
None.
The incidence and outcome of fluid overload in intensive care unit patients with acute kidney injury R. 7.18 [1] . Patients with AKI often have impaired excretion of salt and water [2] . On the other hand, intravenous fluids are part of the management of AKI, which increases the risk of fluid overload in these patients.
Objective: We examined the association between fluid overload and outcome in ICU patients with AKI. Method: Retrospective cohort study of adult ICU-patients from two university hospitals in Denmark admitted between Jan 1st 2012 and Dec 31st 2013. All cases of AKI were identified according to the creatinine criteria of the KDIGO definition. Fluid data was missing in 13 patients (1.5 %), and these were excluded from the analysis. The association between cumulative fluid balance and the risk of death/renal recovery at day 28 was estimated with joint modeling techniques [3] . The cumulative fluid balance was dichotomized with cutoffs at 5 % and 10 % of admission body weight at any day during the first five days of admission. The longitudinal submodel was fitted using mixed effects logistic regression, and the survival submodel was a Cox model adjusted for age, gender, severity of disease (SAPS II, KDIGO grade) and use of life support (norepinephrine, mechanical ventilation and dialysis). The study was approved by the national board of health, who waived the need for consent. Results: We screened 4087 patients and identified 864 with AKI ( Fig. 37 ) of whom 461 and 255 developed fluid overload above respectively 5 % and 10 % of bodywieght (BW) during their first 5 days in ICU (Fig. 38) . At day 28, 514 of the AKI patients had renal recovery and 282 had died (Table 37) . Fluid overload >10 % BW at any day during the first 5 days in ICU was associated with a hazard ratio (HR) for death of 1.08 (p < 0.001); for > 5 % BW fluid overload the HR for death was 1.07 (p < 0.001). In contrast, there was no association between fluid accumulation and renal recovery. Conclusion: In our cohort of 864 patients with AKI, 255 developed fluid overload (10 % BW) during the first 5 days in ICU. Fluid overload, even at 5 % BW, was associated with increased mortality after adjusting for risk factors, but fluid overload was not associated with renal recovery.
This study was funded by the Department of Anaesthesiology, Nordsjaellands Hospital.
Staging of cardiorenal syndrome for outcome prediction in pediatric acute decompensated heart failure D. Introduction: Subtle worsening of renal function is associated with adverse outcomes in pediatric patients (pts) with heart failure. Cardiorenal syndrome (CRS) is a recently coined term underscoring the co-existence of cardiac and renal dysfunction and stresses the bidirectional nature of the heart-kidney interactions. While well defined in adult populations, available pediatric data is scarce. Acute kidney injury (AKI) consensus definitions could Introduction: Microcirculatory dysfunction is an important triggering event of organ dysfunction in sepsis, and the fluid therapy is essential for improvement of the hemodynamic, but the ideal fluid strategy in sepsis has not been developed yet. Aggressive-fluid therapy is controversial and the consequences for the kidney dysfunction are little known. This study investigated the effect of an early phase aggressive-fluid therapy at the kidney microcirculation and tubular structures.
Methods: Adult Wistar rats (200 g) were submitted to sepsis {iv. 2 mL E. coli 10 8 CFU/mL (S8), DL60 in 26 hours}, or sepsis and Ringer Lactate infusion (30 mL/kg/20 min), 30 minutes after the sepsis challenge. Under general anesthesia, the microcirculation of the renal cortical area was monitored by Sidestream Dark Field Imaging (SDF) video-microscopy, at 6 hours (T6h -n = 3/group) and 30 days (T30dn = 3/group) after sepsis. The tissue samples were evaluated by histology (T6h,T30d) by HE and PAS staining. Results and conclusions: SDF at T6h showed broadly distributed microcirculation and tissue dysfunction at both groups (Fig. 39 ). The outlining of tubules became blurred by their enlargement, with compression of tubular lumen and of the peritubular microvessels, suggesting an obstructive phenomenon by cellular edema. Histology. After 6 hours of sepsis, animals treated with aggressive fluid infusionshowed less peritubular congestion, preserved mesangial space and lower areas with hyaline degenerations and better preservation of the tubular lumen compared to sepsis without aggressive overhydrating. PAS staining showed a very slight hyaline degeneration, better preservation of tissue architecture, lower occurrence of cellular death, suggesting that the aggressive fluid therapy in the early stage of sepsis minimizes the severity of vascular and tissue injury in the kidney. The live animals treated with the aggressive fluid showed less peritubularmicrovesselscongestion compared to S8, better preservation of the mesangial space, minor hyaline degeneration, and less cell death in deeper regions of the cortexafter a month of recovery. However, the general appearance showing a kidney limitation for venous blood drainage. Clearly, the aggressive-fluid therapy attenuates renal damage compared to S8. The results suggest that animals treated with aggressive fluid therapy, at the early stage of sepsis, have better conditions to respond against new harmful challenges to the kidney. Besides, the recover process after sepsis seems to be partial, justifying the occurrence of the post-sepsis syndrome. Results: Out of studied patients males represented 46.7%n = 14with mean age 48 ± 16 years.There was positive correlation between UFvolume and TFC (r = 0.410, P = 0.025). Out of the 30pts studied 18pts60%were hemodynamically stable vs 12pts40% had hypotension represented non responders group and had lower TFC compared to hemodunamically stable group (26.45kohm-1 vs 37.8kohm-1) P value 0.004 indicating that they were hypovolemic. Out of the 30pts studied 18pts60%weren´t congested vs 12pts40%were remained persistently congested after accomplishing HD session with significantly higher TFC when compared to those get red off congestion (43.14 ± 9.9kohm-1 vs 25.44 ± 5.5kohm-1) P value 0.0001 indicating that they were still hypervolemic. Using analysis of ROC curve TFC at 25.34kohm-1 was significantly predictor of hypotension with P value0.002, AUC83.4 %, sensitivity67%, specificity100%. Also TFC cutoff value predicting persistent congestion was 37.02kohm-1 with P value0.0001, AUC95.8 %, sensitivity83%, specificity100%.
Conclusions: Electrical Cardiometry is evolving noninvasive tool for adjusting fluid status of critically ill patient on RRT using thoracic fluid content as indicator of fluid status that could be used to avoid hemodynamic instability and persistent volume overload and congestion during and after HD session. Introduction: Acute Kidney Injury (AKI) is believed to carry a good prognosis but recent reports have raised concern about long-term outcome. Assessment of renal functional reserve after AKI can be of aid for ascertaining recovery of kidney function.
Objective: To develop a method for the estimation of renal reserve in the critical care setting. Methods: Exploratory study. We selected 8 patients (4 men/women) between 20 to 50 years, without known previous renal disease who did not develop AKI during ICU stay. Patients were not receiving drugs that could interfere with renal function, were stable and already recovered from their initial problem, but still with a bladder catheter, a IV line and a nasogastric tube for enteral feeding. After administration of a load of 20 gr of proteins by enteral route, a creatinine clearance (CrCl) was calculated for each of the next 6 hours, with a timely collection of urine and a sample of serum creatinine at the end of every period. For the analysis we performed u-Mann-Whitney and Kruskal-Wallis non-parametric test. Data as mean (mean error standard) or median (percentiles 25-75).
Results: Age 41.13 (3.2) years, 50 % men and base CrCl 163 (19.51) mL/min. Median percentage of change between base and maximum CrCl was 123.5 % (78.2-143.2) and because a pick was detected between 3 and four hours after protein load we analysed these two hours together, finding a median change of 80.7 % (69.95-144). Changes between the first and third hours were significant either for absolute values (p 0.023) or % (p 0.031). Hourly changes in CrCl are presented in Fig. 40 Conclusions: A protein load by enteral route is followed by an early rise in creatinine clearance. The profile of this response lets us propose a creatinine clearance 3-4 hours after a load of 20 gr of proteins as a quick and easy way to estimate renal reserve. Our next goal should be to define the profile of response for different kind of patients and degrees of renal dysfunction. Introduction: Evidence has established that there is strong link with Acute Kidney Injury (AKI) and progression to chronic kidney disease (CKD) and end stage renal failure (ESRF) [1] . After AKI, 9 % have permenant loss of kidney function and 9-13 % are dialysis dependent post hospital discharge [2] . Renal followup is recommended for patients who have had AKI whilst critically ill [3] . Objectives: To assess whether patients that received renal replacement therapy (RRT) in ICU had a nephrology follow up, and determine if there was a need for the service.To assess if there were any difference in mortality between the groups. Methods: We performed a retrospective longitudinal cohort study analysis of all patients that received RRT after an AKI in the Greater Glasgow and Clyde Hospitals over one year. Renal function at 3-6 months pre-admission and post discharge were examined by comparing urea, creatinine and eGFR values. Nephrology follow up status was also investigated. We excluded patients that had renal baselines out with the 3-6 month period.Paired t-test analysis was used to analyze preadmission vs post discharge renal baselines in normal eGFR patients Introduction The risk of chronic kidney disease increases with the time of evolution of type 2 diabetes and chronic metabolic control. In people over 40 years occur a progressive loss of glomerular filtration rate corresponding to 1 mL per year. This is associated with progressive deterioration of renal tissue replacement by fibrous tissue, which involves progressive glomeruroesclerosis, tubulointerstitial fibrosis and nephrosclerosis.
Objectives To determine the evolution time of diabetes and prevalence for stages on chronic kidney disease. Material and method: A cross-sectional and descriptive study was done on 150 patients diabetic type 2. There were included all of them that have more than 5 years of evolution on the diabetes type 2, the sample was calculated with the averages formula for finite population and the selection was simple random. Sociodemographic variables and health variables were studied, the stage of chronic kidney disease were estimated by the Cockcroft-Gault equation. The statistic analysis included averages, percentages and confidence intervals.
Methods A cross-sectional, descriptive, observational, retrospective study was conducted which included adult patients that were 50 years and older, and had 10 year diabetes mellitus type 2 diagnosis, without complications mentioned in the Nephrology Unit in Hospital General de Mexico, Mexico City.
Results Regarding the study population, 57 % are female, the average age was 62.12 years and mean glucose was 165.23 mg / dL. The time evolution of diabetes 2 patients in stage 5 was 20.05 years and in patients with stage 1 was 11.05 years. The average creatinine clearance in stage 2 was 75.10 mL / min and in stage 5 10.33 mL / min. 13 % of the population was in stage 4 and a similar percentage (15 %) in stage 5. The time evolution of stage 1 to stage 5 was 10.10 years and stage 3 to 4, 1.5 years.
Conclusions Chronic kidney disease is a public health problem that affects health systems around the world. Today his studio is preferably focused on the population undergoing dialysis treatment in its various forms which lies in stage 5; However, a comprehensive approach to chronic kidney disease in all its stages is necessary to have information about the condition; hence the importance of this study, in which the time evolution of diabetes and population analyzed by stage of chronic kidney disease. The diabetic patient with chronic kidney disease is not flattering; it is distinguished by short evolution times between the stages and high population percentage on stages 4 and 5.
Reference(s) Wild S, Roglic G, Green A, Sicree R, King Objectives The aim of the study was to compare demographic and physiological characteristics of patients requiring RRT in ICU with those who did not require it, and to investigate the impact of receiving RRT on length of unit stay and mortality on ultimate hospital discharge.
Methods The study is a multi-centre retrospective observational cohort study. It uses data from January 1st 2005 to December 31st 2014 from three teaching hospital intensive care units with 18 combined beds and an associated tertiary referral renal service in Glasgow. The data used was collected prospectively from the Wardwatcher service. Demographic details, severity scores, physiological parameters and information on length of unit stay and in-hospital mortality was gathered. Standardised Mortality Ratios (SMRs) were calculated using the APACHE II predicted mortality scores as the denominator.
Results Data for a total of 10549 patients was collected, of whom 13.9% (1471) received RRT during their admission. The mean duration of RRT was 5.0 +/-0.2days. Standardised mortality ratios between the two groups is comparable at 1.04 for the RRT group, and 10.6 for the non RRT group. The results for the two groups are shown below. Conclusions Patients receiving RRT had a mortality rate on ultimate hospital discharge of 52.6 %, roughly in line with previous studies, and nearly twice the rate in those not requiring RRT. (1) . These patient also stayed in ICU for over twice as many days as those not requiring RRT. It is interesting to note, however that the SMR is actually marginally lower for those receiving RRT than not. Patients who require RRT at some point during their ICU stay also have significantly more deranged physiology during their first 24hours of admission, as evidenced by the urine output, potassium, urea and creatinine values for the two groups. Objectives The aim of the study was to compare demographic and physiological characteristics of patients requiring RRT in ICU with those who did not require it, and to investigate the impact of receiving RRT on length of unit stay and mortality on ultimate hospital discharge.
Methods The study is a multi-centre retrospective observational cohort study. It uses data from January 1, 2005 to December 31, 2014 for three intensive care units (ICUs) based in teaching hospitals, with 18 beds combined, and an associated tertiary renal service. The data used was collected prospectively for the Wardwatcher™ service. Demographic details, severity scores, physiological parameters and information on length of unit stay and in-hospital mortality were gathered. Standardised Mortality Ratios (SMRs) were calculated using the APACHE II predicted mortality scores as the denominator.
Results Data for a total of 10549 patients was collected, of whom 13.9 % (1471) received RRT during their admission. The mean duration of RRT was 5.0 ± 0.2 days. The results for the two groups are shown below: Conclusions Patients receiving RRT had a mortality rate on ultimate hospital discharge of 52.6 %, roughly in line with previous studies, and nearly twice the rate in those not requiring RRT (1). These patients also stayed in ICU for over twice as many days as those not requiring RRT. It is interesting to note, however, that the SMR is actually lower for those receiving RRT than not. Patients who require RRT at some point during their ICU stay also have significantly more deranged physiology during their first 24 hours of admission, as evidenced by the urine output, potassium, urea and creatinine values for the two groups.
Introduction Acute Kidney Injury (AKI) is a severe complication of shock. Pathophysiological pathways include renal vasoconstriction and endothelial damage to microvessels, thereby impairing microand macrovascular flow. Microvascular flow can be measured by sublingual Sidestream Dark Field imaging. Renal macrocirculation can be assessed with Renal Resistive Index (RRI), (peak systolic flow velocityend diastolic flow velocity)/ peak systolic velocity, using Doppler ultrasound, obtained from the intrarenal arcuate or interlobar arteries. High RRI is a predictor of persistent AKI (1). Whether RRI reflects the systemic circulation or renal microcirculation is not well known.
Objectives To determine whether RRI is elevated in patients with shock and to relate RRI to concomitant markers of the systemic circulation, the sublingual microcirculation, hydration state and renal function.
Methods We performed a prospective observational cohort study in critically ill patients admitted to the ICU between August 2015 and February 2016. Patients with shock and patients without shock were included < 24-h after ICU admission. Shock was defined as persistent hypotension or low cardiac index (<2 L/min) despite adequate fluid resuscitation and the need of vasopressors. Deferred consent was obtained. At inclusion, three study measurements were performed: RRI, SDF and Bioelectral Impedance Analysis (BIA) to assess fluid status (resistance) and membrane integrity (reactance). Uni-and multivariate analyses were computed to determine the relation between potential determinants and the RRI.
Results Forty patients with shock and 52 without shock were included. Patients with eGFR < 30 mL/min were excluded. Mean age was 69 (60-76) vs. 67 (59-76) yrs. and APACHE III score was 81 (63-107) vs. 57 (45-70) (p < 0.001). Shock patients had a higher RRI than patients without shock (median, 0.751 (0.692-0.788) vs. 0.654 (0.610-0.686); p < 0.001), (Fig. 41) . On univariate analysis, high age, APACHE III score, vasopressor support, pulse pressure index (PPI: (systolic-diastolic)/systolic blood pressure), central venous pressure and positive fluid balance, and low mean arterial pressure (MAP), reactance/m and creatinine clearance were the markers most significantly associated with high RRI (p < 0.01). Markers of the microcirculation were not. On multivariate analysis, vasopressor support, higher PPI, lower MAP and lower Xc/m remained as independent determinants of RRI (n = 89, Adj. R 2 = 0.472).
Conclusions Critically ill patients with shock have a higher RRI than patients without shock. High RRI was associated with renal dysfunction on the one hand and a disturbed systemic circulation (vasopressor support, high PPI and low MAP) and poor cellular membrane resistance on the other, but not with markers of microcirculation. These findings support the concept that shock-induced AKI is associated with renal vasoconstriction and cellular damage. Introduction Severe sepsis state constitute a worlwide public health problem. (1, 2) .Thus SSC has edicted recommendations to improve the management of this pathology.(3)But some authors have expressed reserves on the implementation of these recommendations in low income countries. (4) Objectives To evaluate the faisability and the impact of the recommendations of SSC on adults in septic shock in University Hospital of Kinshasa.
Methods We conducted a quasi-experimental prospective study of twelve months from 1 st February 2014 to 28 february 2015 .This study was divided into 2 phases of 6 months each, before the protocol or the preprotocol phase and after the protocol or the post-protocol phase. Adults (over 16 years old) with septic shock within this period were included. Preprotocol group were treated as usual. After establishing a local protocol based on the SSC recommendations, post-protocol group received during the earlier 6 hours intravenous fluids,vasopressors, blood transfusion and large broad spectrum antibiotics. The next 24 hours, was devoted to or-gans´failure management. Our 2 endpoints were the compliance according to the SSC recommendations and the mortality between both groups.
Results 72 patients were included. 33 during the first phase and 39 in the second phase. Patients' characteristics were similar in both group. The infection site responsible of septic shock was mainly pulmonary (24 %) , cutaneous (21 %), urinary (19 %) and abdominal (13 %). Post-protocol group received more intravenously fluids (+1229 ml); catecholamines (+20 %) as well as blood transfusion (X3) than those of the pre-protocol group. They were also more likely to achieve the target mean arterial pressure (36.6 versus 82.1 %) and to receive appropriate antibiotics (0 versus 12.8 %). The compliance to SSC bundles was significantly improved, passing from 0 % before protocol to 50 % after protocol. We also observed a significant decrease of the mortality, of 17 % in 6 months.
Conclusions SSC recommendations can be apply in a country of subsaharan Africa with a significant reduction of mortality. Results Ninety-nine patients underwent one hundred and three VV-ECMO, representing 1472 ECMO-days. The ECMO device infection rate was 6.8 per 1000 ECMO-days (10 events, 9.7 % of ECMO support) including 7 ECMO device-related bloodstream infections (4.7 per 1000 ECMO-days). The ECMO device colonization rate was 22.4 per 1000 ECMO-days (33 events, 32 % of ECMO support). Coagulase negative staphylococcus was the most frequently organism responsible for ECMO device infections (8/10, 80 %) and ECMO device colonization (20/33, 60.6 %). No difference was observed between the three groups, regarding days of mechanical ventilation, both ICU length of stay and mortality, and in hospital mortality. We observed a longer ECMO duration in the ECMO-device colonization group as compared with the Uninfected/Uncolonized ECMO-device group [12 days (9-20 days) versus 5 days (5-16 days); respectively, p < 0.05].
Conclusions At the time of ECMO device removal, we reported a low incidence of infection related to the devices. Further studies are needed to evaluate the benefits of systematic strategies using chlorhexidineimpregnated dressing to reduce the rate of colonization. Objectives The objective was to explore the lived experience of the family during the acute stage of NSTI using diaries written by close family members.
Methods The study had a multicenter, binational, qualitative explorative design using diaries written by close family members (n = 17) during the acute stage of the trajectory starting in the intensive care unit (ICU) at the hospitals where NSTI is centralized in Denmark and Sweden. Family was defined in its broadest terms as spouse, partner, blood-relation, neighbor or friend. Qualitative content analysis and investigator triangulation were used. The study was part of the P-INFECT-study investigating the patient and family experience of NSTI from different perspectives. Patient and family involvement was applied in constructing the study. Conclusions NSTI is generally unknown to patient and family and comes as a shock. Patients in our sample received rapid treatment in the ICU and the worst consequences were avoided. Nevertheless, close family, including spouses were faced with the sudden risk of disfigurement or death in the patient as they coped with ambivalence of being several places at once, lack of sleep and lack of certainty. We recommend the provision of systematic information during the acute stage, including knowledge on what to expect. Conclusions Infections are one of the leading causes of morbidity and mortality in SICUs due to high incidence, drug resistance and rate of associated complications. Ventilator-associated pneumonia was the leading cause of ICU infections in our study and Acinetobacter baumannii was the most frequently found organism in our patients.
Benchmarking severe sepsis incidence in Germany: accuracy of different ICD-10 coding strategies in administrative data C. Introduction Various ICD code abstraction strategies are used to identify severe sepsis cases in administrative data, but reliable data on their validity is scarce.
Objectives To assess the accuracy of severe sepsis coding by validation trough clinical chart review and to identify reasons for wrongor non-coding.
Methods A random sample of 1120 patients stratified by hospital length of stay and ICU admission status admitted to an academic medical center in Germany between 2007 and 2013 was selected. Severe sepsis patients were identified by the following ICD-10 abstraction strategies applied to patients' primary and secondary discharge diagnoses:
(1) clinical sepsis codes (R codes),
Gold standard was the diagnosis of sepsis according to ACCP/ SCCM consensus criteria based on the review of full patient charts by four independent physicians. Predictive accuracies of abstraction strategies were compared correcting for stratified sampling by using sampling weights. Following the analysis, false negatives and false positives were reviewed to determine reasons for misclassification. Results From 937 charts from adult patients that were accessible in full, 81 patients with severe sepsis/septic shock. Sensitivity, specificity, positive and negative predictive values are shown in Tab. 1. Overall, explicit coding strategies are limited in their sensitivity, but have a better positive prediction than implicit coding strategies. Identification strategies based on clinical and/ or microbiological sepsis codes risk underestimating true sepsis incidences by 1.4-2.2-fold, whereas indirect coding strategies carry the risk of overestimation. In explicitly identified cases which were coded false positive (n = 13), 23 % organ dysfunction was not caused by infection (23 %), infection or organ dysfunction were not documented in the chart (54 %) or patients did not meet two or more SIRS criteria (23 %). For the implicit approach, false-positives (n = 90) resulted from concurrence of infection and organ dysfunction without causality (51 %) or that infection or organ dysfunctions were not identifiable retrospectively by chart review (40 %). 9 % did not meet the SIRS criteria. In implicitly false-negatives (n = 21), organ dysfunction, infection or both were not coded in 67 %, 14 % and 17 % of cases, respectively. Conclusions Existing ICD coding strategies differ in their accuracy in identifying septic patients in hospital discharge databases and thus may over-or underestimate true sepsis incidences. Standardized and valid coding strategies for severe sepsis are needed to ensure comparability between epidemiological and intervention studies based on administrative data.
The CSCC is funded by the German Federal Ministry of Education and Research, Germany, FKZ: 01EO1502. Introduction The level of healthcare workers knowledge on Hospital Acquired Infection (HAI) international recommendations strongly influences its increase. Objectives To describe the level of knowledge of ICU doctors, nurses and physiotherapists at Sagrada Esperança Clinic on HAI international recommendations. Methods It was applied to ICU doctors, nurses and physiotherapists the questionnaire used in the EVIDENCE study, which includes 50 comprehensive questions concerning bloodstream infection, catheter-associated infection, ventilator-associated pneumonia, urinary catheter-associated infection, surgical site infection, hands washing and general knowledge on HAI. We validated the number of correct answers and rated the staff as GOOD (50-40); MEDIUM (39 to 30); ENOUGH (29-25) and POOR (<25). Results Out of 50 healthcare workers invited to participate, we received and analyzed a total of 28 completed questionnaires, with a Mean of correct answers: 13.1 ± 7.0 and wrong answers: 14.9 ± 7.0; (P = 0,22). No healthcare worker was rated as GOOD; three were rated as MEDIUM (all doctors); eight as ENOUGH (three doctors and five nurses); seventeen as POOR (two doctors, ten nurses and four physiotherapists). Comparing the results, we found a significant difference between doctors and nurses (P = 0.022) and between doctors and physiotherapists (P = 0.005). There was no difference between nurses and physiotherapists (P = 0.071).
Conclusions Healthcare workers did not show, in this study, good knowledge on Hospital Acquired Infection international recommendations. Introduction Sepsis is one of the leading causes of mortality amongst ICU patients [1] . However there is a paucity of information on the variables that could advise the physician to predict mortality.
Objectives To identify risk factors associated with poor prognosis in patients with sepsis on the critical care unit.
Methods A retrospective, observational study performed in a tertiary referral University Hospital over 12 months (September 2014 to September 2015). Inclusion: All patients admitted to the ICU with a diagnosis of sepsis and coded by the audit team. Exclusion: Age less than18 years and patients admitted with end of life care plan. Data collection: Case notes were reviewed and the following details were recorded in a predesigned data collection sheet: demographic profile, admission diagnosis, APACHE II score, antibiotics, co-morbidities, survival and length of stay. Ethical approval was not sought as study considered a service evaluation.
Results We included 236 patients (n = 236). The mortality rate was 38.1 %. The demographic details of the patients can be seen in the table.
It was noted that age and APACHE II score at admission significantly are associated with high mortality. Mortality increased proportionately with time to administration of antibiotics although not significantly. It was noted that the most common source of infection was the respiratory system (64 %) as demonstrated in the graph below. The most common antibiotic used was piperacillin-tazobactam. Mortality was higher in patients with a respiratory or soft tissue/bone source of infection, the lowest mortality was seen in infections of the nervous system. Conclusions Our study demonstrates that increased age, high APACHE II score and delay in administration of antibiotics are associated with higher mortality in sepsis related admissions to ICU. We aim to develop a scoring system identifying different variables which will contribute to informed decision making in sepsis related admissions. Introduction Sepsis is the leading cause of ICU admissions, associated with high mortality. Very few Indian data is available to identify the incidence of severe sepsis/ septic shock and their outcomes.
Objectives To identify the incidence, risk factors and outcomes of patients with severe sepsis/septic shock Methods Prospective observational study, done in a multidisciplinary ICU over a period of 18 months. We included all adult patients admitted to ICU with features of severe sepsis/septic shock as per SCCM/ACCP guidelines. Data collection was done on demography, co-existing illness, parameters to assess Acute Physiology and Chronic Health Evaluation (APACHE) II and Sequential Organ Failure Assessment (SOFA) scores and other relevant lab data including vital parameters. Data concerning the source of infection was obtained. Organ failures and other supportive measures taken were captured. Primary outcome data on mortality was collected and secondary outcome data on ventilator days, ICU length of stay (ALOS) and ventilator free days were captured.
Results 1162 patients were screened and 356 patients had severe sepsis; incidence of severe sepsis was 30.6 %, mortality rate was 51.6 %. Admission APACHE II (23.37 ± 9.47) and SOFA (7.58 ± 4.05) scores were high. Most common source of infection was from respiratory tract (37.2 %) followed by urinary tract (10.3 %) and intraabdominal (9.5 %) infections. 62.9 % of patients required ventilator support, 25.5 % of patients required vasopressor support despite adequate fluid resuscitation, more than one third of patients required renal replacement therapies (35.7 %). Hematocrit, total leucocyte count, serum bilirubin and SOFA scores were significantly higher among non-survivors. Conclusions Incidence of severe sepsis was high and was associated with poor patient outcomes. Introduction Inadequate ICU bed concurrent cleaning is associated with increased risk of nosocomial infections in critically ill patients. Healthcare provider training and continuous education have been associated with better outcomes in several settings.
Objectives To evaluate the microbiological impact of training a critical care staff in concurrent cleaning of ICU beds. Methods design Before-and-after study. Intervention: Training program in concurrent cleaning for critical care healthcare providers. Period and setting: From January 2014 to October 2014 in a mixed private ICU. A pretest questionnaire was applied to all participating nurses to assess initial knowledge of concurrent cleaning. After training a new test was applied and the participating nurse was deemed approved if answers correctly at least 80 % of the questions. Microbiological burden was evaluated before training and 30 days by a quantitative ATP essay. The ICU bed was considered clean if quantitative assay resulted was less or equal to 150 URL. If quantitative essay result was higher than 150 URL the ICU bed was considered contaminated and a new cleaning process initiated. Each microbiological burden evaluation included three different moments, as follows: (1) before patient admission, (2) six hours after admission, and (3) 24 hours after admission.
Results A total of 60 ICU beds were included, being 30 before training and 30 after training. We included in training 269 critical care healthcare providers. The pre and post-test was answered by all participating providers, which answered correctly to 73 % and 93 % of the questions, respectively. The microbiological quantitative results before training were 259 (±101) URL, 209 (±103) URL and 261(±101) URL for before admission, six hours after admission and 24 hours after admission, respectively. Thirty days after training, the results were 169 (±110) URL, 61 (±21) URL and 52 (±20) URL for before admission, six hours after admission and 24 hours after admission, respectively. The microbiological burden significantly reduced after training before admission (p = 0.001), six hours after admission (p < 0.001) and 24 hours after admission (p < 0.001).
Conclusions A training program in concurrent cleaning for critical care healthcare providers was effective in reducing the burden of microbiological specimens in ICU beds. Objectives This study sought to assess the effect of a multidimensional approach developed by our team on the reduction of catheter related hospital acquired infection (CR-HAI) rates in the patients hospitalized in an adult intensive care unit (AICU) in an INICC member hospital in Shiraz, Iran.
The study was divided into two periods: During the baseline period, we conducted active prospective surveillance of VAP, VAE, CLABSI and CAUTI using the CDC and NHSN definition and INICC methods. During the intervention period, we implemented a multidimensional approach for VAP, VAE, CLABSI and CAUTI in addition to performing active surveillance. This multidimensional approach included a bundle of infection control interventions including hand hygiene, active screening, contact precaution and environmental cleaning. The baseline rates of CR-HAI were compared to the rates obtained after intervention, and we analyzed the impact of our interventions by Z score.
Results The two years of study period were divided to 4 epochs with six-month duration. 621 patients were admitted in the ICU with 6190 bed days. Central line utilization ratio was 65 percent.The rate of CLABSI was reduced from 21 to 7 per thousand catheter days (p < 0.007). The incidence of VAP plus VAE decreased from 26 to 11 per thousand mechanical ventilation days (p < 0.0128) while ventilator utilization ratio was 51 percent. The rate of CAUTI also decreased from 23 to 9 per thousand catheter days (p < 0.0126).
Conclusions The implementation of this multidimensional approach for CR-HAI was associated with a significant reduction in the CLABSI, VAP plus VAE and CAUTI rates in the participating AICU.
The The sharing of outcomes of such investigations is an essential part of the process; unless the results are disseminated lessons cannot be learnt by staff involved. The NHS national patient safety agency describes a seven stage process to patient safety, which outlines this process clearly. 1 Objectives To how assess how effectively the results of investigations into infection with MRSA and C.diff are disseminated to staff working in the CCU at SRFT. Methods On 22.11.2015, all CCU staff on duty were asked to complete a questionnaire, and to do so without reference to additional sources of information (eg noticeboards, colleagues and websites). The survey asked participants the following questions: · How long ago was the last C.diff/MRSA infection on CCU? · Do you know what the RCA into this infection showed? Participants were then asked for additional comments, including how they had heard about the results of the investigations, and for ideas for on how such information could be more effectively shared.
Results 33 members of staff participated in our study and all groups from the MDT were represented.
Most of the staff were not aware of the time since the most recent infections, as can be seen in Table 42 . Perhaps even more worryingly, fewer than one third of the participants were aware what the investigation into either of these HCAIs had shown.
Conclusions On the day of the survey, the most recent cases of MRSA and C.diff had been fully investigated and the results of the RCAs into the events had been published. Despite the completion of these investigations, our survey shows the learning points raised had only been shared with a small percentage of the critical care team, limiting the impact of the investigative work.
As a result of this work, we intend to involve more members of the MDT in RCAs, and change the way results of such investigations are communicated with the critical care team to ensure any lessons can be learnt by a wider group of individuals. Introduction Plasmapheresis (therapeutic plasma exchange -TPE) is an established treatment option in the therapy of Guillain-Barré syndrome (GBS). 3 randomized controlled trials established its efficiency between 1985 and 1995. So far the recommended number of TPE sessions is four, but the optimum TPE protocol (number of exchanges and volumes exchanged) remains to be established (1) . Also the role of TPE in patients with GBS who fail to respond to therapy and who relapse after therapy remains to be determined (1). TPE is expected to be a logical therapeutic option in diseases in which pathogenesis is linked with a biological substance with a relatively high molecular weight, a slow rate of formation and a distribution in the vascular space. TPE is used in the treatment of diseases in which the pathogenesis is associated with abnormal circulating pathogenic autoantibodies (2) . The role of antibodies against gangliosides in GBS is established only in Miller Fisher variant, in other types of GBS the role of antibodies still remains to be determined. But as the optimum TPE protocol (especially in patients who fail to respond to therapy and in patiens who relapse after standard TPE protocol) has not been determined, it is a question, whether in these patients the role of antibodies should not be considered and the number of TPE sessions should not be individualized and adapted to these results.
Objectives We wanted to determine the relationship of antibodies to gangliosides in patients with GBS and TPE and its influence on TPE protocol.
Methods We prospectively screened patients with GBS treated by TPE for antibodies to gangliosides before, during and after TPE series and adapted the number of TPE to the neurological status and results of antibodies. Results In 2014 we had and unexpected number of GBS patients at our ICU. 4 patients were admitted to our ICU during the period of 3 months.In all 4 patients we chose TPE as an initial therapy. We tested the patients for antibodies against gangliosides before, during and after the TPE protocol and adapted the number of TPE to the clinical course of the disease and to the results of antibodies against gangliosides. In patients with positive antibodies and a remaining neurological defficiency or a relapse we repeated a series of TPE.
Conclusions The studies on TPE protocols and GBS are 20 years old. The optimal TPE protocol remains to be established. The question is whether the efficacy of TPE should not at least in patients with severe neurological symptoms and in patients who fail to respond to standard TPE protocol be individualised according to the results of antibodies to gangliosides. Introduction Traumatic brain injury (TBI) is a common cause of morbidity in Europe. Managing raised intracranial pressure (ICP) with barbiturate coma is a final option in medical management 1 . Interactions between thiopentone and potassium have been reported 2 and have been attributed to mortality in our ICU.
Objectives To review the frequency, complications and contributing factors in the loss of potassium homeostasis during and after a thiopentone infusion.
Methods Patients who were prescribed thiopentone by infusion from March 2011-May 2015 were selected. Serum potassium was recorded at baseline and 6 hourly until 72 hours or infusion stopped. Following cessation, potassium levels were recorded 6 hourly for 60 hours unless death occurred. Potassium replacement during the 72 hours and the use of insulin were noted. Complications following infusion were reviewed. Results In total 50 patients were prescribed thiopentone. Eight received a bolus and three had other indications. A further 3 patients had a duration under 6 hours and were excluded. Thirty-six patients were reviewed with 1 patient dying during infusion. Patient characteristics are shown in Table 44 . Hypokalaemia (potassium < 3.5) developed in 25 patients (69.4 %) during infusion with the mean lowest at 12 hours (Fig. 49 ). Subsequently 11 (31.4 %) patients developed hyperkalaemia (potassium > 5.5), mean peak 12 hours after. Three patients died due to cardiac arrest with hyperkalaemia following infusion and 2 patients required filtration to control potassium. Insulin use, duration of infusion, weight, potassium replacement or presence of hypokalaemia had no statistical significance relating to loss of regulation (Tables 45 and 46) . Conclusions After fatalities attributed to hyperkalaemia post barbiturate coma, we aimed to assess the occurrence and any contributing factor. A case series 2 highlighted the potassium replacement as a significant variable. This was not shown here, possibly due to restrictive replacement in patients during infusion. We did find an earlier fall in potassium following the start of infusion and an earlier peak after cessation. That no variable showed significance suggests a lack of understanding of the cause of dysregulation.
This study was limited by sample size, likely due to limiting barbiturate coma to a final attempt at ICP control. Further large trials may be required to identify variables predicting hyperkalaemia. Overall, with little to indicate which patients will develop hyperkalaemia, ICU staff should beware this potentially fatal complication. Introduction Inflammation is a key player in brain damage and increased production of pro-inflammatory and lower levels of the antiinflammatory cytokines in periphery blood and cerebrospinal fluid (CSF) are associated with poorer clinical outcome after primary intraventricular hemorrhage (IVH).
Objectives The aim of this study was to investigate changes in concentration of interleukin (IL)-1β and Transforming Growth Factor β (TGF β) in CSS of patients with IVH and external ventricular drainage treated with catheter-based clot lysis with low-dose tissue plasminogen activator (tPA).
Methods Thirty adult patients with IVH were enrolled in the prospective study. The patients were divided in two groups: group A was treated with 3x1 mg/12 h tPA (15 pts; age 69 (60-74); male 7) and control group B with placebo (15 pts; age 62 (59-68); male 8). Intracerebral hemorrhage score on admission was equal in both groups (ICH = 3 (2-3)). Concentration of IL-1 β and TGF β in CSF were determined 24 hours (day 1), 3 and 7 days after the start of clot lysis. Introduction Bone marrow suppression, leucopenia and infectious complications have been reported during the use of barbiturate coma therapy (BCT) for refractory intracranial hypertension. However, these studies have mainly involved small sample sizes. Thus, although effective in lowering intracranial pressure, barbiturate-mediated infections may severely limit the potential life saving utility of BCT.
Objectives /Methods We conducted a retrospective cohort study of all patients (n = 72) receiving thiopentone BCT for the control of refractory intracranial hypertension in a neurosurgical intensive care unit over 4 years. We collected data including changes in cell count, procalcitonin levels and incidence of clinically diagnosed infections. The microbiological profile of the organisms isolated and antibiotics prescribed were also analysed.
The mean pre-induction WBC count was 15.1 ± 12.2 x 109 L; 91.7 % of patients experienced a decrease in WBC count after induction with a mean maximal decrease in white cell count of 9.15 x 109 L. The incidence of leucopenia and neutropenia were 34.7 % and 2.8 %, respectively. Procalcitonin levels were generally raised as early as first day of BCT. The incidence of clinical infections was 46.2 %. Pneumonia (n = 15) and blood stream infections (n = 9) accounted for majority of the infections. The main causative organisms causing pneumonia were Klebsiella pneumonia (n = 4), Staphyloccus aureus (n = 2) and Pseudomonas aeruginosa (n = 2). The main cultured organisms from blood stream infections were Pseudomonas aeruginosia (n = 3), Klebsiella pneumonia (n = 1), Enterococcus cloacae (n = 1) and Acinetobacter baumannii with Staphyloccus aureus (n = 1). Out of 40 positive cultures, Klebsiella pneumonia (n = 14, 1 was multiresistant) and Staphyloccus Aureus (n = 9, 4 were methicillin-resistant) constituted the commonest bacteria isolated.
Conclusions Leucopenia and infections (predominantly pneumonia) are common complications in patients on BCT for refractory intracranial hypertension. Introduction Stroke is a disease with high morbidity and mortality, it constitutes a main medical cause of permanent disability in adulthood, and in Spain it is one of the leading causes of death. The intravenous thrombolysis is an approved treatment in selected patients that with the new recomendations this group could be bigger. Advances in imaging studies for acute ischemic stroke are largely due to the development of new efficacious treatments carried out in the acute phase. The computed tomography (CT) perfusion studies and CT angiography facilitates the selections of patients who are likely to benefit from appropriate early treatment.
Objectives To analyze the impact of new recomendations for acute ischemic stroke treatment in the selection of patients for treatment and the outcomes in patients atended in a polyvalent ICU during the last year (2015) and the first trimester of this year.
Methods Consecutive registry of patients seen in the last year (2015) and the first trimester of this year whom were suffering acute stroke in the ICU of a university hospital. Descriptive analyze of the registry during this period.
Results During 2015 were approached as suffering an acute stroke 28 patients, 13 women (46 %) and 15 men (54 %) with a medium age of 62.3 y.o.; in whom were treated with thrombolysis 9 (32 %) patients being this treatment considerate as efective in 1 (11 %) patient, reporting up to 3 cases (33 %) of bleeding in CT control. In 19 patients thrombolysis was not applied and the causes were: thrombolysis contraindicated (4 cases), with out indication of thrombolysis (4 cases) and improvement of disability (11 cases). During the first trimester of this year we had 18 patients, 6 women (33 %) and 12 men (67 %) with a medium age of 63.6 y.o.; thrombolysis was appplied in 10 patients (55 %), being efective the treatment in 3 (30 %) cases with no one case of bleeding in CT control. And in the 8 patients in whom thrombolysis was not applied the causes were: thrombolysis contraindicated and with out indication of thrombolysis with 4 cases for every group. Improvement of disability is not considerated as cause of no thrombolysis.
Conclusions The new recomendations in acute ischemic stroke and the advances in neuroradiology allow a better approach of patients, is increasing the patients whom benefits of this treatment, and the effectiveness seems to increase, in the same way the adverse results seem to remain in low cases.
Conduction of passive verticalization in patients with ischemic stroke who are on mechanical ventilation A. Gritsan 1 , A. Gazenkampf 1 , E. Korchagin 2 , N. Dovbish 3
Introduction Acute ischemic stroke is a leader in terms of mortality and disability. Early rehabilitation significantly improves the outcome of treatment. One of the most effective methods of early rehabilitation is passive verticalization, aimed at prevention and elimination of complications associated with long-stay patient in the supine position.
One of the relative contraindications for verticalization is to carry out mechanical ventilation (AV).
Objectives To assess the effectiveness of early passive verticalization conducted against the background of mechanical ventilation in patients with ischemic stroke.
Methods The analysis of 55 and medical history of patients with a diagnosis -ischemic stroke. It formed two groups -the addition of verticalization (Group 1 -32 persons) and without a verticalization (Group 2 -23 people). All patients were treated according to the Recommendations AHA / ASA 2013. All patients underwent mechanical ventilation respirators "Hamilton C2 " (Switzerland). In verticalization carried out by verticalization table «Beka Hospital» (Germany). All patients conducted severity rating scales for SOFA, NIHHS, CGS at admission and on the first, 3rd, 5th, 7th, 10th. At these stages were assessed respiratory status.
Results In both groups assessed results are presented in Table 48 . Starting ventilator patients in both groups were required at different times substantially on average, and the eighth day in both groups were diagnosed with pneumonia.The frequency of hemodynamic disturbances and duration of inotropic support were comparable in both groups. The mortality rate in group 1 was significantly lower than in group 2, which explains the increase in the period of mechanical ventilation and stay of patients in the ICU and in the hospital. Analysis on GOS the surviving patients showed no significant differences. Introduction Post-craniotomy pain has been reported to be moderate to severe. Management of post-craniotomy pain is inadequate in many cases, yet is limited by the side effects of opioids. Codeine has been the mainstay of treatment of post-craniotomy pain in our institution, due to its safer side effect profile when compared to more potent opioids. However, its effectiveness may be limited due to the need to be de-methylated before it has any analgesic effect and this process is subject to inter-individual variability.
Objectives Our primary objective was to determine if there is a difference in the mean pain VAS scores in the oxycodone and codeine groups at 24 hours. Secondary objectives were to compare pain VAS scores at 48 and 72 hours and to compare the incidence of excessive sedation, depression of respiratory rate and GCS.
Methods A randomized, double blinded controlled trial was used to evaluate the efficacy of oral oxycodone versus oral codeine. 40 patients were randomized to the control group of codeine (n = 20) or the experimental group receiving oxycodone (n = 20), in addition to regular oral paracetamol for both groups of patients. Analgesia was to be administered according to a strict protocol. Patients were reviewed by blinded assessors closely in the 1 st day and then subsequently once a day at the 48 th and 72 nd hour post-operatively. Results A total of 36 patients were analysed (4 patients dropped out due to post-surgical complications). The mean pain score at 24 hours was 1.85 ± 1.60 and 2.78 ± 1.92 (p = 0.110) in the codeine and oxycodone group respectively. There were also no statistically significant difference in the sedation scores, respiratory rate and GCS scores.
Conclusions Oral oxycodone is as effective as oral codeine in the management of post-craniotomy pain.
Our local population also seemingly has very mild pain after a craniotomy (mean pain VAS scores 1-3), as compared to what was reported in the literature. One deduction is that compared to the Western population, our population probably has minimal genetic variability in the ability to metabolise codeine. Our population may all be efficient metabolisers, thus allowing codeine to be as effective as oxycodone. Also, as our patients generally had mild pain, codeine may be adequate analgesia for them.
As there is no difference in adverse effects, oxycodone may also be as safe as codeine, in bioequivalent doses. Hence, oxycodone can be considered as an effective alternative to codeine.
Early and 60-days mortality and its causes in patients undergoing intravenous thrombolysis for ischemic stroke R. Assis 1 , F. Filipe 2 , N. Lopes 3 , L. Pessoa 3 , T. Pereira 3 , N. Catorze 3
Introduction Ischemic Stroke still constitutes the major cause of death in Portugal. With the widespread investment in information to the population and creation of a net of reference hospitals with established protocols of Intravenous Fibrinolysis and endovascular treatment, mortality and morbidity have declined.
Objectives The objective of this study is characterize the population undergoing Intravenous Fibrinolysis with alteplase at the Intensive Care Unit of the researchers' hospital, verify the early (48 hours) and 60-days mortality after admission,and identify the causes of death.
Methods Observational retrospective study based on information acquired from the clinical records of patients admitted in the Intensive Care Unit for Intravenous Thrombolysis between the 1 st of January 2010 and 31 st December 2015, and its statistical analysis.
Results Among the total of patients included (n = 102), 63 % were male with an average of 70 years old.The average admission National Institutes of Health Stroke Scale (NIHSS) score was 14 and the average Symptoms-to-Needle time was 156 minutes. There was a total of 4 deaths in the first 48 h after admission and 19 deaths between 48 hours and 60 days post admission. Of the early deaths, 2 were due to intracerebral hemorrhage and the other 2 accounted for progression of ischemic disease, unresponsive to thrombolysis. The highest cause of death at 60 days was Aspiration Pneumonia (10), followed by progression of ischemic disease (5), Intracerebral Hemorrhage (2), Septic Shock (1) and 1 prehospital death, with no reference to cause of death on clinical records. The average NIHSS score at twelve hours of patients who died between 48 hours and 60 days was 20.
Conclusions With the application of adequate guidelines and evaluation of the patients proposed to Fibrinolysis, early deaths accounted for 17 % of total deaths and were attributed to non effectiveness of fibrinolytic therapy or its hemorrhagic complications. Deaths occurring at 60 days post admission occurred in patients with higher NIHSS scores, revealing important neurological dysfunction. The most frequent cause of death was Aspiration Pneumonia. Being so, it is important to apply prevention measures to patients during ICU and hospital stay, in order to reduce Aspiration Pneumonia's incidence and allow the patient to start physiotherapy as soon as possible to regain lost functionality. Patients suffering stroke should be evaluated by a multidisciplinary team involving Neurology, Internal Medicine and Physiotherapy at regular periods to adequately assist them to resume their lives.
Introduction Propofol and midazolam are known to be excellent drugs for sedation for intensive care units.
Objectives This study aimed to compare the sedative and analgesic effects and the recovery profiles of propofol and midazolam in a rat model by conducting motor coordination tests (rotarod-accelerod test) and by evaluating the analgesic response times by conducting hot plate and tail flick tests. Methods Rats were randomly divided into the following 4 groups on the basis of the treatment received. The first group received 600 μg/kg/min propofol, the second, 83 μg/kg / min midazolam; and the third, 83 μg/kg / min morphine; the fourth was a control group. The rats were placed on a rotating rod and tested first at the slowest speed (5 rpm), followed by a speed of 10 rpm, and then with 10-rpm speed increments at speeds up to 40 rpm. The speed was set to increase from 1 to 79 rpm within 4 and 10 min in the accelerod test. Pain reflexes in response to a thermal stimulus were measured at 0, 10, 20, and 60 min after the drug injection by using the hot plate and tail flick tests. The neurobehavioral status, including sensory and motor function, was assessed every 30 min until normal functioning resumed by an investigator who was blinded to the groups.
Results At all the tested speeds, the midazolam-injected rats remained on the rotarod longer than did the propofol-injected rats. Furthermore, in the 10 min accelerod test, the midazolaminjected rats remained for a longer duration than did the propofol-injected rats. The latency time for the hot plate test was significantly higher at 10 min in the propofol group than in the midazolam group. At 10 and 20 min, the latency time was greater in the propofol group than in the midazolam group. Further, the latency time at 10 min for the tail flick test was greater in the propofol group than in the midazolam group. Propofol enhanced sensory blockade to a greater extent at 90 and 120 min than midazolam did at the corresponding time points. Further, the duration of complete motor blockade was significantly greater in the propofol group than in the midazolam group. Introduction Ranolazine (Rn), a drug used for the treatment of chronic angina pectoris (1), has been proposed for the management of epileptic disorders for its ability to decrease neuronal excitability by blocking late inward sodium current (late INa) in the central nervous system (2, 3) . We recently demonstrated in primary cultures that Rn could act as a neuroprotective drug by promoting astrocyte viability, preventing necrosis and apoptosis, inhibiting inflammatory phenomena and inducing antiinflammatory and antioxidant agents (4). Amyloid-β peptide 1-42 (Aβ 1-42 ), a protein involved in the pathogenesis of Alzheimer´s disease, produce glial activation, inflammatory response and oxidative stress that can lead to neuronal death (5) .
Objectives Under the hypothesis that ranolazine acts as a neuroprotective drug, the present study focuses on the effects ranolazine on astrocytes exposed to Aβ 1-42 toxic peptide.
Methods We incubated rat astrocytes in primary cultures for 24 hours with Rn (10 −7 , 10 −6 and 10 −5 M), Aβ 1-42 (15 μM) or Rn (10 −6 M) + Aβ 1-42 (15 μM). Cell viability and proliferation were measured using MTT conversion assay and LDH release assay. Apoptosis was determined by Caspase 3 activity assay.
Results In cultured astrocytes, Rn significantly increased cell viability and proliferation at any concentration tested, and decreased LDH leakage and Caspase 3 activity indicating less cell death. Aβ 1-42 significantly decreased cell viability compared to control astrocytes. Incubation with Rn (10 −6 M) prevented the decrease in cell viability induced by Aβ 1-42 . Rn decreased LDH release to the medium (15 % with Rn 10 -6 M and 20 % with Rn 10 -5 ). Toxic peptide increased LDH release in about 75 % and incubation with Rn (10 -6 ) lowered by 60 % LDH levels, indicating a protective effect against Aβ .
Conclusions Ranolazine increases cell viability and prevents necrosis and apoptosis induced by Aβ 1-42 , suggesting that Rn could act as a neuroprotective drug in situations associated with oxidative stress or inflammation. (2).
Objectives The aim of our study was first to estimate the occurrence of DCI in a proinflammatory state using an high omega 6 polyunsaturated fatty acid (w6) diet and secondly to evaluate the efficiency of terutroban (TER) a TP receptor inhibitor.
Methods Ninety wistar rats (400 g) were randomly assigned to one of 5 groups: a double 250 μL intracisternal injection of autologous arterial blood (SAH groups) (3) or artificial CSF (CSF group) was performed. To induce a proinflammatory state animals were fat with w6 during 6 weeks before SAH procedure (SAH_w6/SAH_w6 + TER). TER was administered (30 mg/kg/day) during 5 days following SAH (SAH + TER/SAH_w6 + TER groups). Evaluation of uptakes of 3 [99mTc]radiolabeled agents was achieved using microSPECT/CT imaging: HMPAO at D5 for cerebral perfusion quantification; DTPA at D3 for blood brain barrier (BBB) integrity study; and AnnexinV at D4 for apoptotic activity study. ANOVA followed by Student́s t test.
Results HMPAO uptake analysis showed a significant decrease in the SAH group (figure). DTPA and AnnexinV uptake were also significantly increased in the SAH group compare to the CSF group. Proinflammatory state before SAH dramatically decreased HMPAO uptake (figure); increased DTPA (0.37 ± 0.04 vs. 0.43 ± 0.01 Mbeq/mm3; P < 0.05) and AnnexinV (0.39 ± 0.03 vs. 0.48 ± 0.03 Mbeq/mm3; P < 0.05). TER significantly counteracted the decrease in HMPAO uptake (figure) and the increase in DTPA uptake (P < 0.05) and in AnnexinV uptake (P < 0.001) induced by SAH.
Conclusions For the first time, a proinflammatory SAH rat model of DCI has been described. microSPECT study shows that a proinflammatory diet dramatically increases apoptosis and DCI. TER improved hypoperfusion, BBB disruption and apoptosis. TP receptor antagonists could be promising treatments after SAH.
Introduction Brain injured critically ill patients have often impaired airways reflexes and require long-term mechanical ventilation and tracheostomy, which is a standard of care. Many issues still remain unclear, for example the optimal timing (early versus late), the better technique and the effect on ICP in brain injured patients.
Objectives To describe the approach and the systemic/intracranial effects of tracheostomy in severe brain injured patients in a neurocritical intensive care unit (San Gerardo Hospital, Monza, Italy). Methods All consecutive adult patients undergone tracheostomies from 2010 to 2015 were included. A retrospective analysis of prospectively-collected data retrieved from a digital PDM system was performed (demographics, procedures characteristics, and blood gas analyses, intracranial pressure (ICP), mean arterial pressure (MAP), cerebral perfusion pressure (CPP)). Data are reported as median (interquartile range) prior to/during/after tracheostomy. A repeated measures analysis of variance was utilized to assess the effects of tracheostomy.
Results Preliminary data are based on 170 patients (58 % male and 42 % female, 67 (56-73) years old, GCS at admission 7 (6-9)) admitted for intracranial hemorrhage (29 %), subarachnoid hemorrhage (22 %), trauma (21 %), stroke (12 %). Tracheostomy was performed at 10 (7-13) days from admission for compromised neurological status (89 %, GCS at tracheostomy 7 (6-8)). Direct laryngoscopy Fantoni´s translaryngeal technique (TLT), Percutwist, surgical, standard TLT and Dolphin were used in 63 %, 18 %, 11 %, 6 % and 2 % of the cases. ENT specialists and intenstivists performed 46 % and 54 % of the tracheostomy, respectively. No deleterious effect on recorded parameters was detected (see Table 48 ). Four lesions of the tracheal rings were documented.
Conclusions In a large cohort of brain-injured patients tracheostomy performed one week after the initial insult is safe. Introduction The systemic inflammatory response syndrome (SIRS) can lead to pronounced tissue damage and is a frequent cause of multi-organ failure and mortality in Intensive Care units 1 . SIRS can be elicited by a variety of insults, such as sepsis, trauma, and major surgery, and no specific therapy is currently in routine use. EA-230 is a newly developed synthetic linear tetrapeptide derived from the βhuman chorionic gonadotropin hormone (β-hCG), which has shown promising anti-inflammatory and tissue-protective effects in animal studies 2,3 . Objectives To investigate the tolerability, safety and immunomodulatory effects of EA-230 in humans. Methods We conducted a double blind, placebo controlled, doseescalating randomized clinical trial in 60 healthy volunteers. The study was carried out in two phases. In the first phase (n = 24), safety and tolerability was established for escalating doses of EA-230 (30, 90, and 180 mg/kg). In the second phase (n = 36), the same doses were used to assess the effects of EA-230 on systemic inflammation during experimental human endotoxemia. At t = 0 hours, 2 ng/kg E. Coli endotoxin was administered i.v. followed by a 2-hour continuous i.v. infusion of EA-230 or placebo. Levels of circulating cytokines and adhesion molecules as well as body temperature and flu-like symptoms were assessed. Furthermore, effects on renal function were investigated using plasma clearance of iohexol. Results EA-230 was well tolerated and showed an excellent safety profile. Treatment with the highest dose of EA-230, but not with lower doses, resulted in a significant attenuation of the endotoxininduced increase in plasma levels of IL-6, IL-8, IL-1RA, MCP-1, MIP-1α, and MIP-1β (IL-6, IL-8, and MCP-1 shown in Fig. 50a, b, and c) , and the adhesion molecule VCAM-1 (Fig. 50d) . Furthermore, the highest dose of EA-230 reduced fever and flu-like symptoms (Fig. 51) . Endotoxemia resulted in a marked increase in GFR, but no differences between groups were observed. Conclusion Administration of EA-230 is safe and results in attenuation of the systemic inflammatory response in humans. These promising results pave the way for a phase IIb clinical trial to assess the anti-inflammatory and tissue-protective effects of EA-230 in patients.
Introduction Mortality from sepsis and septic shock remains high. Results of trials on intravenous immunoglobulins (IVIG) as adjunctive therapy for sepsis have showed controversies. Objectives The aim of this study was to identify factors for predicting prognosis in patients with severe sepsis (SS) or septic shock (SSh) according to quartiles of immunoglobulin G (IgG) concentrations Methods It is a cohort study of 133 critically ill adults admitted in a polivalent Intensive Care Unit of a University Hospital. Demographic data, clinical parameters and IgG levels were determinated within 24 hours from SS or SSh onset, defined according to Surviving Sepsis Campaign (SSC) criteria. The patients were divided into four groups (quartiles) based on the 25th, 50th and 75th percentiles of their initial level of IgG. We tested for differences in baseline characteristics by IgG interval using a Kruskal-Wallis test for continuous data or a Chi Square test for categorical data and reported the median and interquartile ranges. A logistic regression model was adjusted for potential confounders as age, APACHE II score, SOFA score, number of organ failure (NOF) and presence of shock on admission. Statistical analysis was performed using SPSS 15.0 for Windows (SPSS Inc. Chicago, IL, USA) Results We analyzed 133 consecutive episodes of SS (16.5 %) or ShS (83.5 %) admitted in the ICU. The median age of the study sample was 62 (inter-quartile range: 48.5-70.5) years old; male: 62.4 %. The main sources of infection were: respiratory tract 36.8 % and intraabdomen 28.6 % and 69.9 % had medical pathology. 28-day mortality was 21.8 %. Quartiles of serum IgG concentration were: quartile 1 (Q1: 607 mg/dL or less), quartile 2 (Q2: 607-792 mg/dL), quartile 3 (Q3: 792.1-976 mg/dL) and quartile 4 (Q4: 976.1 mg/dL or greater). The median IgG concentrations of each quartile were 525 mg/dL in Q1, 695 mg/dL in Q2, 881 mg/dL in Q3 and 1340 mg/dL in Q4, (p < 0.001). The differences between these quartiles shown no significant difference in APACHE II, SOFA score, number of organ failure (NOF) neither 28 day-mortality. Surprisingly the patients in Q4 had the higher 28-day mortality (30.3 %) compared with the other quartiles (OR 0.998, CI 0.996 to 1, P = 0.072), following by patients in Q1 (21.1 %). Conclusions Our studied did not show prognostic value with low levels of serum IgG within 24 hours from SS or SSh onset. High levels of IgG within 24 hours from SS or SSh may be a risk factor for increase 28 day-mortality in septic patients; should be further investigated in this field. Introduction T lymphocytes play fundamental roles in the immunological response to sepsis. γδ T cells are a new subset of T lymphocytes that represent a small population of immune cells, exhibit features of both innate and adaptive immunity, and play an indispensable role in host defense, immune surveillance and homeostasis. Recent studies found massive loss of gamma delta T (γδT) cells in patients with sepsis. However, little did we know about their function changes and role in such a pathological status. Objectives This study was designed to evaluate the phenotype and function of peripheral γδ T cells in patients with severe sepsis and septic shock, and its association with prognosis. Methods This prospective observational study was conducted in three ICUs of a university hospital. A total of 107 patients, consecutively admitted and diagnosed with severe sepsis or septic shock (excluding previous immunosuppression) and 30 healthy controls, were enrolled. Surface markers (CD69, NKG2D, PD-1) and intracellular cytokines (IFN-γ, IL-17, IL-10, TGF-β) of γδT cells isolated from peripheral blood were analyzed by flow cytometry. Results were also correlated with clinical outcome. Results Septic patients displayed decreased percentage of γδT cells and NKG2D expression, and increased CD69, pro-(IFN-γ, IL-17) and antiinflammatory (IL-10, TGF-β) intracellular cytokines as compared to healthy controls. After stimulation of γδ T cells in vitro by pamidronate (PAM) or phorbol-myristate acetate (PMA) plus ionomycin, both CD69 expression and IFN-γ secretion significantly reduced in septic patients as compared to healthy controls, 19.041 ± 11.74 % vs. 52.47 ± 19.84 % and 23.66 ± 17.37 % vs. 70.47 ± 16.41 %, respectively, p < 0.001. Importantly, these decreased expressions were more pronounced in nonsurvivors as compared to survivors. Using multi-regression logistic method to adjust factors that impacted patient outcome, IFN-γ secretion after stimulation and SOFA score were independent risk factors associated with patient death, OR: 0.937 (95 % CI: 0.893-0.982) and 1.248 (95 % CI: 1.056-1.474), respectively, p < 0.05. Conclusions Our results showed pronounced changes in γδT cell phenotype and function in septic patients. This finding provides novel insights into the role of γδT cells in sepsis. Introduction Hallmarks for sepsis severity include loss of vascular and immunological homeostasis. NO is an important vasodilatator and loss of NO may contribute to impaired microcirculation. Moreover, NO is involved in protein modification, regulation of transcription factors and production of superoxide anions. L-Arginine (L-Arg) is substrate of NO producing synthase (NOS) and its homolog, Lhomoarginine (h-Arg), is the competitive substrate. Asymmetric dimethylarginine (ADMA) is an endogenous NOS inhibitor (see reference).
Objectives Therefore we sought to investigate whether L-Arg, h-Arg or ADMA are altered in septic patients. In addition we analyzed mRNA expression levels of dimethlyarginin-dimethylamino-hydrolase 2 (DDAH2), the ADMA degrading enzyme in peripheral blood monocytes (PBMC) of sepsis patients. Methods Blood from 129 sepsis patients and 25 healthy controls was drawn and analyzed. L-Arg, h-Arg and ADMA concentrations were measured by mass spectrometry. In peripheral blood monocytes DDAH2 mRNA expression was measured by quantitative PCR (qPCR). All parameters were correlated with Sequential Organ Failure Assessment Score (SOFA) score for sepsis severity.
Results We did not observe any difference of NOS substrate Larg between controls and patients. In contrast the concentration of h-Arg in blood was significant decreased in patients (P < 0.01), whereas ADMA concentration was increased in patients (P < 0.01). Both h-Arg and ADMA concentrations were associated with diseases severity. Spearman-rank analysis revealed a positive association between SOFA score and blood levels of ADMA with rho of 0.25 (P < 0.01). A negative association of h-Arg with the SOFA score was determined, however this was not significant. In ROC analysis ADMA emerged as the most powerful indicator of organ dysfunction, followed by the SOFA score, whereby both parameters yielded almost identical AUCs. Furthermore, in PBMCs DDAH2 expression was decreased in patients and significant lower in patients with sepsis related organ dysfunction (P < 0.05).
Conclusions In blood of septic patients we found increased concentrations of the endogenous NOS inhibitor ADMA together with decreased mRNA expression for DDAH2 in PBMCs. These measurements may influence systemic and intracellular NO levels in patients with sepsis and may contribute to the septic phenotype of microcirculatory and immunological collapse during sepsis. Decreased concentration of h-Arg the competitive substrate of NOS may be a reaction to restore NO equilibrium during sepsis. Further prospective studies are needed to confirm the results in a larger cohort of non-septic patients and controls.
Introduction Antimicrobial resistance threatens to undermine treatment for severe infection; new therapeutic strategies are urgently needed. Augmented passive immunotherapy with P4 peptide is a novel therapeutic strategy that increases phagocytic activity in vitro and rescues moribund septic mice. Objectives Our aim was to determine ex vivo P4 activity in a target population of patients admitted to critical care with severe infection.
Methods We prospectively recruited UK critical care unit patients with severe sepsis and observed clinical course (≥3 months post discharge). Blood samples were taken in early (≤48 hrs postdiagnosis, n = 54), latent (seven days post-diagnosis, n = 39) and convalescent (3-6 months post-diagnosis, n = 18) phases of disease. The primary outcome measure was killing of opsonised S.pneumoniae by neutrophils with and without P4 peptide stimulation. We also used a flow cytometric whole blood phagocytosis assay to determine phagocyte association and oxidation of intraphagosomal reporter beads. Introduction It is well-known that bacterial sepsis induces an immunosuppressed state, impairing the host's ability to clear the primary infection and increasing vulnerability for secondary bacterial or fungal infections [1] . However, whether bacterial sepsis affects the subsequent response to influenza infection is unknown, as is the safety of administration of live attenuated influenza vaccines (LAIVs) in immunosuppressed patients. Experimental human endotoxemia induces systemic inflammation that mimics bacterial sepsis and subsequent development of immune suppresion [2] .
Objectives To investigate the effects of human endotoxemia on the immune response elicited by a subsequent challenge with the LAIV Fluenz (surrogate for influenza infection [3] ).
Methods In a randomized, placebo-controlled study 30 healthy male subjects received intravenous placebo (NaCl, n = 15) or endotoxin (E. coli LPS 2 ng/kg, n = 15), followed by administration of quadrivalent Fluenz on day 7 in all subjects. Nasal wash samples were obtained to measure viral shedding and inflammatory mediators. Symptoms were recorded daily using an online symptom diary.
Results LPS administration resulted in a typical increase in plasma levels of cytokines, which was absent in the placebo group (Fig. 52) . Following Fluenz challenge, viral shedding for at least one of the four influenza strains present in the vaccine was 12/15 (80 %) in the LPS-Fluenz group compared with 13/15 (87 %) in the placebo-Fluenz group. The increase in viral shedding of the influenza A and B strains was similar between groups (Fig. 53, upper panels) . Likewise, the Fluenz-induced increase in levels of the chemokine IP-10 in nasal wash, as well as local symptoms, were not different between the LPS-Fluenz and placebo-Fluenz group (Fig. 53, lower panels) .
Conclusions While human endotoxemia attenuates the inflammatory response of a second challenge with endotoxin with approximately 70 % [2] , it does not influence the Fluenz-induced local immune response and viral shedding. These data suggest that the immune response to a bacterial compound does not alter the response to a subsequent viral infection.
Introduction Sepsis is a severe infection with a hyperinflammatory response mediated by cytokines that can induce acute lung injury and multi-organ dysfunction. It is the most common cause of death in intensive care units and currently, there is no specific drug treatment for this disease. That is why new therapeutic alternatives are essential to be found 1 . Methotrexate (MTX) is an immunosuppressant currently used in autoimmune disease; it acts by decreasing lymphocyte proliferation and cytokines production 2 .
Objectives The aim of this study is to evaluate the effect of MTX in inflammation caused by sepsis, focusing on systemic and lung injury.
Our main hypothesis is that treatment with MTX reduces damage and control the inflammatory response in both the lung and systemic level. Methods Sepsis was induced by a cecal ligation and puncture (CLP) in Sprague-Dawley rats (300-325 g). 6 hours later we did a surgical source control and administered antibiotics, fluids and analgesics. In addition, we administered to one group MTX i.p. (2.5 mg/kg). 48 h later the animals were sacrificed and samples of lung tissue, bronchoalveolar lavage and blood were collected. Groups:
Survival, Body weight and lung weight were mesured. Neutrophils, macrophages, lymphocytes and protein concentration in bronchoalveolar lavage were quantified. Different T cells subsets in blood were analysed. Molecular markers related with inflammation, infiltration and damage were evaluated by qRT-PCR in lung tissue. Results Results show a decrease in circulating lymphocytes, Treg lymphocytes and lung weight in groups treated with MTX compared to the septic group (Fig. 54a-c) . The cellular content in alveolus in the CLP MTX group shows a decrease in cell infiltration of polimorfonuclear cells and lymphocytes compared to CLP group, while the number of alveolar macrophages is not altered in the different groups ( Fig. 54d-f ). Expression of the inflammatory cells recruitment, matrix remodelling and proinflmatory markers show an increase in septic rats, while with MTX treatment exhibit a reduction. Finally, MTX cause an increase of the expression of the anti-inflammatory cytokine IL4 (Fig. 55) .
Conclusions MTX administration in an animal model of sepsis reduces systemic and lung injury causes by sepsis. This drug inhibits cytokine cascade and recruitment of pro-inflammatory cells in the lung. Introduction Neutrophils are key effectors in the host´s immune response to sepsis. Excessive stimulation or dysregulated functions of neutrophils are considered responsible for the pathogenesis of sepsis.
Objectives We report that neutrophil autophagy primes neutrophils for increased neutrophil extracellular trap (NET) formation, which is responsible for host survival during sepsis.
Method We studied patients with community-acquired pneumonia who have been admitted to the intensive care unit. To investigate this hypothesis, we isolated neutrophils from community-acquired pneumonia patients on day 1 (PD1) and day 3 (PD3). Then we determined the ROS generation, NETs Formation, surface expression of granule markers (CD63, CD66b, CD35. Results Neutrophils isolated from septic patients expressed high levels of the autophagy-specific protein LC3 and primed neutrophils for NET formation in response to subsequent phorbol 12-myristate 13-acetate (PMA) stimulation. These neutrophils showed decreased mean lobe counts and distinct changes in surface marker expression (CD62L dim /CD64 brt ). In contrast, neutrophils isolated from nonsurviving septic patients showed dysregulated autophagy and decreased responses to PMA stimulation. In a mouse model of sepsis, autophagy augmentation improved survival via a NET-dependent mechanism. Our study provides important insights into the role of autophagy in neutrophils during sepsis.
Conclusion Neutrophil autophagy could be an attractive therapeutic target for the treatment of sepsis. Introduction Septic shock with Acute kidney injury are common in critically ill patients. The apelinergic system improves cardiac functions, decreases vascular tones and exhibits diuretic properties. These effects are held by two distinct endogenous peptides: Apelin-13 (APL-13) a dominant bioactive fragment of the apelin family mainly expressed in the cardiovascular system, and ELABELA (ELA) a recently discovered ligand of APJ-R described to regulate cardiovascular development and mainly expressed in kidney tissues.
Objectives ELABELA vs. APL-13 during sepsis-induced cardio-renal syndrome.
Methods Sepsis induced by cecal ligature and puncture (CLP) in adult rats. Myocardial impact of ELA vs. APL-13 on healthy and septic isolated-heart assessed by Langendorff apparatus ex vivo.
Peptides and fluid resuscitation intra-venous infusions through osmotic and/or syringe pumps in healthy vs. CLP rats in vivo. Monitoring of myocardial functions by echocardiography, and in vivo left ventricular (LV) hemodynamics through pressure-volume probing 24 h after CLP induction. Water intake and urine output recording, heart; kidney and blood collection for subsequent biological assays.
Results ELA as well as APL-13 stimulated left ventricular ino-and lusitropy of healthy and septic hearts ex vivo (sepsis, dP/dtmax from baseline 10pM; APL-13: 92 %; ELA: 83 %). Both APL-13 and ELA also Introduction The major sources of body heat production are muscular activity, oxidation of food, and uncoupled mitochondrial respiration due to proton leak. The cause of fever in sepsis is unknown, particularly in sedated, ventilated patients who neither perform much voluntary skeletal muscle activity nor shiver, and are often not fed in the acute early phase. Furthermore, the usual vasodilated state implies increased heat loss, so this must be exceeded by heat generation to generate a pyrexia.
Objectives To determine the association between fever and uncoupled mitochondrial respiration, by comparing the effects of exogenous uncoupling with dinitrophenol in sham and septic rats. Methods Awake, male Wistar rats (approx. 300 g body weight), previously instrumented with tunnelled carotid and jugular lines, were placed in metabolic cages to continuously monitor whole body oxygen consumption (VO 2 ). Core temperature was measured intermittently with a rectal probe. Sepsis was induced by i.p. injection of faecal slurry. Sham animals received i.p. saline. Intravenous fluid resuscitation (10 ml/kg/h crystalloid) was started at 2 h. At 6 and 24 h, animals received the mitochondrial uncoupler, dinitrophenol (DNP) (30 mg/kg), given over 1 h. Statistical differences comparing pre-and post-DNP were assessed using a paired T-test. P values < 0.05 were considered statistically significant.
Results Sham animals were euthermic at 6 and 24 h, and their VO 2 was similar to baseline values. DNP produced significant rises in VO 2 (20 % and 22 %, respectively) and temperature (>1°C) at both timepoints (p < 0.05). By contrast, septic animals were febrile pre-DNP at 6 h (p < 0.05) but not 24 h, and DNP only induced small, nonsignificant rises in temperature. No change in VO 2 was seen at either timepoint.
Conclusions Whereas sham animals generated an appropriate rise in temperature and VO 2 in response to mitochondrial uncoupling with DNP, septic rats could only generate a small rise in temperature and a minimal VO 2 response. This implies that mitochondrial uncoupling was already increased in septic rats (thus explaining the pyrexia) and could not be increased further by exogenous uncoupling. It is also possible that upstream inhibition of the electron transport chain may have prevented the response to DNP seen in septic animals. This possibility is under further investigation.
Introduction Critical illness acquired myopathy in rats is characterized by homogeneous muscle atrophy (1). Conversely, histological abnormalities are heterogeneous among muscle types: oxidative muscles show patchy alterations (myofascitis, necrosis), while glycolytic types demonstrate normal patterns. Activation of the ubiquitinproteasome system (UPS) is responsible for 80-100 % of myofibrillar protein breakdown in skeletal muscle. Whether UPS activation is dependent on the oxidative and glycolytic muscle type during critical illness is unknown.
Objectives To characterize UPS activation by skeletal muscle type in a long-term peritonitis model Methods Male Wistar rats were followed for up to 2 weeks after intraperitoneal injection of the yeast cell wall constituent, zymosan or n-saline. Soleus (oxidative, slow twitch muscle), and gastrocnemius (mixed glycolytic-oxidative, fast twitch muscle) were harvested from both the zymosan and control group 2, 7 and 14 days after the insult. Caspase-, trypsin-, and chemotrypsin-like activities of the 26S proteasome were measured by enzymatic assay. Protein expression of activated caspase-3, muscle-specific ubiquitin ligases (MuRF1 and MAFbx), and polyubiquitinated proteins were assessed by Western blots at all time points. Protein expression of caspase-3 specific fragments of myofibrillar actin was assessed at day 7. Results Weight loss was not statistically different for soleus versus gastrocnemius in the zymosan group (-26 ± 11 % versus -16 ± 9 %, p = 0.17) at day 2. Catalytic activity of the 26S proteasome was increased at day 2 in soleus, and days 2 and 7 in gastrocnemius. Soleus displayed upregulation of MuRF1 at days 2 and 14.
Gastrocnemius displayed both activation of MuRF1 and MAFbx at day 2 and 7. Activated caspase-3 and polyubiquitinated proteins were increased at days 2, 7 and 14 in soleus but not in gastrocnemius. Caspase-3 specific fragments of myofibrillar actin were increased in soleus, but not in gastrocnemius. Results are summarized in the Table. Conclusions In a rodent model of long-term peritonitis, oxidative and glycolytic muscles show some similarities (e.g. up-regulation of ubiquitin ligases, early proteasome activation) but also marked differences in caspase activation, polyubiquitination and duration of proteasome activation. Introduction Increasing evidence is being presented which suggests that modulation of mitochondrial bioenergetics may play a key role in the apparent paradox between the clinical and biochemical presentation of acute kidney injury (AKI) observed in sepsis, and the lack of cell death, maintenance of tissue oxygenation, and eventual recovery. 1 Furthermore, evidence from in vitro studies have indicated that humoral mediators carried in the circulation may play a role in the mitochondrial dysfunction observed in sepsis that result in organ dysfunction unrelated to haemodynamic changes. 2 Objectives Determine if exposure to septic serum modulates mitochondrial function in a live naïve kidney slice. The mitochondrial functions probed were: mitochondrial membrane potential (MMP), redox state, and reactive oxygen species (ROS) generation.
Methods Live naïve kidney slices (200 μm thick) were exposed to serum from 24 hour sham operated or septic rats for 90 minutes and imaged with a confocal microscope using fluorescent dyes to detect dynamic changes in mitochondrial function (Fig. 60 ). Tetramethylrhodamine methyl ester (TMRM) is an indicator of MMP whose signal decreases with MMP depolarisation. Dihydroethidium (HEt) is an indicator of ROS whose signal increases with increasing ROS. NADH is constitutively fluorescent and can be used as a marker of the redox state.
Results Septic serum caused a decrease in MMP, an increase in ROS, but no change in NADH at 90 minutes exposure compared to baseline (Fig. 61 ). Sham serum did not cause any change from baseline and was comparable to slices exposed only to a physiological saline solution.
Conclusions The decrease in MMP seen during exposure to septic serum could be indicative of either increased uncoupling or decreased electron transport chain activity. In the first case one would expect a parallel decrease in NADH signal while in the second one would expect an increase in NADH. In this study, NADH did not change in the septic exposed slices and so it is not clear which of the two proposed scenarios is more likely.
Mitochondria are an established source of cellular ROS and in this ex-vivo model, ROS increased significantly following exposure to septic serum. ROS may be a both a mediator and a consequence of mitochondrial dysfunction and the relationship between the two should be explored further. This study has suggested that humoral factors within septic serum are capable of causing mitochondrial dysfunction in an ex-vivo kidney slice model. Mean tetremethylrhodamine methyl ester RFI at 90 min (relative to baseline) for kidney slices exposed to PSS, sham serum or septic serum. b) Reactive oxygen species generation. Mean dihydroethidium RFI at 90 min (relative to baseline) for kidney slices exposed to PSS, sham serum or septic serum. c) Redox state. Mean NADH RFI at 90 min (relative to baseline) for kidney slices exposed to PSS, sham serum or septic serum. * = p < 0.05, n = 9, RFI = relative fluorescence intensity, PSS = physiological saline solution Introduction The incidence of ICU-acquired infection following major trauma is greater than 60 % (1). A hyperacute increase in IL-10 (2) as well as a reduction in monocyte HLA-DR (mHLA-DR) expression (3) has been documented following injury and these are associated with the development of late nosocomial infection.
Objectives To evaluate the role of IL-10 mediated pathways in posttraumatic immune suppression and to assess the reversibility of this phenomenon.
Methods Serum was collected from consecutive patients suffering severe blunt polytrauma at admission and again at 24 hours (24HR). Age and sex matched healthy volunteers served as controls.
Pooled peripheral blood mononuclear cells (PMBCs) from healthy volunteers were incubated for 20 hrs with media containing 30 % serum from either trauma patients or healthy volunteers. These were cultured in the presence or absence of granulocytemacrophage Colony-stimulating factor (GM-CSF, 200 ng/mL), Interferon Gamma (IFN-γ, 250 International Units) or an IL-10 neutralising antibody (10 ng/mL). Monocyte HLA-DR (mHLA-DR) membrane density (geometric mean florescent intensity (gMFI)) was characterised on a BD FACS ARIA IIIu flow cytometer. Data are displayed as median and interquartile range (IQR) and analysed with non-parametric statistics. Results Ten polytrauma patients with a median Injury Severity Score (ISS) of 38 (IQR 29-50) were recruited. This cohort was 80 % male with a median age of 27 (IQR 23-50). There was a decrease in antigen density of mHLA-DR on healthy donor PBMCs when incubated with admission (P < 0.01) or 24HR (P < 0.05) polytrauma serum, compared to incubation with serum from age and sex matched controls (Fig. 62a) . Culturing in the presence of IFN-γ (P < 0.01) or GM-CSF (P < 0.05) prevented this decrease in antigen density (Fig. 62b ). Pre-incubation with an IL-10 neutralising antibody partially reversed the detrimental effects of the incubation with polytrauma trauma serum (P < 0.001; Fig. 62c ). Conclusions Serum obtained from polytrauma patients induces an immunosuppressive response through an IL-10 dependent pathway, which is reversible with IFN-γ or GM-CSF treatment.
Introduction Prolonged use of intravenous (IV) drugs for intensive care unit (ICU) sedation is associated with accumulation and difficulty of control. After a new volatile anesthetic conserving device (ACD) was introduced, the use of volatile anesthetic agents for sedation in ICU has emerged. Though many trials have shown the effectiveness of sedation using volatile agents in several aspects, these studies have been too small to identify significant effects. Objectives To access the overall efficacy for volatile sedation compared with IV sedation in the ICU patients. Methods We reviewed for all publications from PubMed, Embase, and the Cochrane database on ICU sedation comparing volatile anesthetics (sevoflurane or isoflurane) using ACD with IV agents (propofol or midazolam ± remifentanil). And we performed meta-analysis on eligible studies. Two reviewers independently assessed studies for inclusion and extracted data. The Cochrane Collaboration methodology was used. Standardized mean differences (SMD) with 95 % confidence intervals (CIs) were estimated. Results Sixteen trials and 942 patients were included in our metaanalysis. Extubation time from termination of sedation comparing volatile with intravenous sedatives was significantly shorter in the volatile sedation group than IV sedation group (SMD -1.062, 95 % CIs -1.311 --0.813; p < 0.001). In addition, the ICU length of stay (LOS) was significantly shorter in the volatile sedation group than IV sedation group (SMD -0.183, 95 % CIs -0.350 --0.016, p = 0.032).
Conclusions We found evidence that ICU sedation with volatile ACD provides the shorter extubation time from termination of sedation and the ICU LOS Introduction The clinical practice guideline for the management of agitation of the American College of Critical Care Medicine suggests that either propofol or dexmedetomidine may be preferred over sedation with benzodiazepine to improve clinical outcomes in critically ill intubated patients.
(1) Recent study have revealed that dexmedetomidine reduces incidence and shortens duration of postoperative delirium. (2) It remains unknown that whether the side effects of bradycardia and hypotension of dexmedetomidine may affect cardiac output or stroke volume in critically ill patients.
Objectives The aim of this study is to compare the hemodynamic effects between dexmedetomidine and propofol for postoperative sedation in patients with abdominal surgery. Methods This is a randomized controlled clinical trial (Clinical-Trials.gov ID: NCT02393066). 60 patients undergoing abdominal tumor surgery were enrolled in the study and randomly allocated to Propofol group or Dexmedetomidine group. Cardiac index and stroke volume index were measured by a continuous non-invasive cardiac output monitoring using bioreactancebased technique. Opioid requirement, urine output, length of ICU stay and hospital stay were compared between the two groups.
Results The baseline heart rate and mean arterial pressure were not significantly different between the two groups. During the treatment period, heart rate and mean arterial pressure were significantly lower in the Dexmedetomidine group than in the Propofol group.
No severe bradycardia no hypotension was noted in both groups. The cardiac index and stroke volume index were not significantly different between the two groups. The mean length of hospital stay was shorter in the Dexmedetomidine group than in the Propofol group (20.3(10.1) vs 20.6(12.6) days, p = 0.037).
Conclusions Our results support that the cardiac output and stoke volume were not significantly different between sedation with dexmedetomidine or propofol. We found that postoperative sedation with dexmedetomidine shortens the length of hospital stay in patients with abdominal surgery. Introduction Delirium is common in the critically ill and is an important independent predictor of mortality. To be able to accurately manage delirium, screening for its presence with the Confusion Assessment Method for the Intensive Care Unit (CAM-ICU) or the Intensive Care Delirium Screening Checklist (ICDSC) is essential.
Objective To assess the impact of delirium screening with a validated screening tool and the tool used (CAM-ICU versus ICDSC) on the prognostic value of delirium for hospital mortality.
Methods A prospective multicenter before-after implementation intervention study was conducted in six ICUs between March 2012 and April 2015 in the Netherlands. The intervention consisted of a multifaceted implementation of the Pain, Agitation and Delirium guidelines. For this sub-analysis, all consecutive adult patients who were admitted to ICU, excluding those with primary neurological diagnoses, were included during three 4month periods. We discerned a before-period (no routine daily delirium screening with CAM-ICU or ICDSC; delirium was considered present when noted in medical or nursing charts or when antipsychotics were given) and after-period (after multifaceted implementation of daily delirium screening; three hospital using CAM-ICU and three ICDSC). The primary outcome was the association of delirium, assessed with or without screening and with ICDSC or CAM-ICU, with hospital mortality. Multivariable logistic regression analysis was used with adjustment for covariables age, APACHE II, admission type (medical, or elective/emergency surgery) and hospital (only for before-vs. after-period analysis).
Interactions between covariables were tested. We further assessed the primary outcome in the before-vs. after-period (screening -/+), and in the after-period (screening+) when assessed with CAM-ICU versus ICDSC, by entering these as covariates in the regression model. Results 4033 patients were included (before-and after-period: 1385 and 2632 patients, 15 patients had missing data on covariables). Delirium was independently associated with hospital mortality in crude analysis (OR 1.95, p < 0.001, Table 55 ). There was significant interaction between APACHE II and delirium (p < 0.001). After adjustment the OR for delirium was 8.61, but the effect was much stronger in the patients with a higher APACHE II score above the median value (≤15; OR 1.68, p = 0.07 versus >15; OR 19.0, p < 0.001). Mortality risk of delirium in the afterperiod compared with the before-period and with CAM-ICU versus ICDSC (after-period) did not differ (before versus afterperiod, OR 0.82, p = 0.079 and ICDSC versus CAM-ICU, OR 1.03, p = 0.831).
Conclusions In this large multicentre prospective study, we confirmed the independent association of ICU delirium with hospital mortality but found significant interaction with APACHE II. The screening instrument used (CAM-ICU versus ICDSC) did not influence the delirium-associated risk of in-hospital death.
Pain assessment in the unconscious patient-a comparison of three different analgesia-indices with clinical signs in a prospective observational clinical study S. Introduction Levels of analgesia under sedation are traditionally evaluated by clinical signs such as an increase in heart rate (HR), blood pressure, lacrimation and defensive movements. However, the patients' analgesic level under sedation is hard to determine in the intensive care setting, as these clinical signs are not specific. Recently, the assessment of the anti-/ nociception balance by different monitoring devices was described. The Analgesia Nociception Index (ANI) (MetroDoloris, Lille, France) is derived from HR variability and provides an index between 0 (nociception) and 100 (analgesia). The Surgical Pleth Index (SPI) (GE Healthcare, Helsinki, Finland) derived from HR and pulse wave amplitude measured with photoplethysmography displays the parasympathetic tone as index between 0 and 100. Pupillary reflex dilatation (PRD) following a noxious event is measured with video recording (AlgiScan, IDMed, Marseille, France).
Objectives This prospective observational clinical study was designed to evaluate the diagnostic accuracy of the analgesic indices in assessing the level of analgesia under sedation compared to clinical signs. Methods After obtaining ethics approval and informed consent, 37 surgical patients were anaesthetized pre-operative with propofol to a bispectral index (BIS) 30-60. A laryngeal mask was inserted and remifentanil was increased step-wise to a dose of 0.05, 0.10, 0.15 and 0.2 μg/kg/min. After ensuring a steady-state period, two different standardized painful stimuli were applied. Tetanic stimulation (80 mA, 30 sec., 50Hz), the most common used noxious event in clinical studies, was compared to Bromm's pain model, a direct intracutaneous stimulation (80 mA, 30 sec., 2Hz) of Aδ-and C-fibres [1] . All stimulations were accompanied by recordings of SPI, ANI, PRD, HR, mean arterial pressure (MAP) and BIS. Sensitivity and specificity in Introduction The use of sevoflurane in ICU is possible with the Ana-conda® system. Its properties could be interesting during a procedural sedation for repetitive dressings of burn patients in ICU.
Objectives To evaluate the pharmacokinetics of sevoflurane administration during a procedural sedation in a population of burn patients compared to a standard population of critically ill patients Methods Burn patients (body surface area burned (BSAB) with 3rd degree between 20 and 50 %) requiring procedural sedation and control patients were enrolled. Sevoflurane was administered with an expired fraction target of 2 %. Plasma concentrations of sevoflurane, the hexafluoroisopropanolol (HFIP) and free fluoride ions were recorded at different times. The Kinetic Pro (Wgroupe, France) was used for pharmacokinetic analysis. Introduction Sleep and wakefulness are strong interconnected stages regulated by complex mechanism in the basal brain. Disturbed sleep impairs function of nervous and immune systems and metabolism. There has been much focus on sleep in ICU during the recent years: disturbed sleep causes prolonged stay in ICU, increased morbidity, including delirium, and mortality. Several studies reveal pathological sleep patterns in critically ill patients. Critically ill patients in the busy environment of an ICU are exposed to a range of different disturbances such as the high level of noise and light, procedures, mechanical ventilation, medication, and the critical illness itself.Polysomnography (PSG) has never been used in studies on critically ill patients in an ICU to test whether environmental changes improve sleep in this patient group.
Objectives We hypothesised that improvement of the intensive care environment would lead to better sleep quality in critically ill mechanically ventilated patients.
Methods This study was conducted in a general 8-bed ICU, Vejle Hospital, Denmark. The night-intervention´Quiet routine' protocol was planned as a bundle of procedures, directed towards improvement of ICU environment between 10 pm and 6 am. Noise levels during control and intervention nights were recorded to control for the intervention. Adult patients with relevant contact on mechanical ventilation were randomized after informed consent to the It is not possible to blind whether a patient is sedated or not. However, the ICU-nurses who performed the clinical assessments and registrations were unaware that we were investigating the incidence of pressure ulcers. All clinical data were extracted and interpreted by the principal investigator before the patient's randomization status was revealed.
If we encountered difficulties ascertaining whether an ulcer was acquired in the ICU or already present at admission, we assumed that the ulcer was ICU-acquired to avoid risk of underestimation. Primary outcome: total number of pressure ulcers acquired in the ICU, described by grade (I-IV) and localization.
Results 65 ICU-acquired or assumed ICU-acquired pressure ulcers were identified. There were no significant differences between groups regarding sex, age, BMI, APACHE II or SAPS II. There were 34 grade 1 pressure ulcers (sedated: 18, non-sedated: 16), 29 grade 2 ulcers (sedated: 17, non-sedated: 12) and 2 grade 3 ulcers (sedated: 1, non-sedated: 1), with no significant difference between groups. Concerning localization, results were grouped into three: sacrum, heels and caused by equipment (for example at nostril from oxygen catheter or at wrist from arterial line). The localization of the ulcers were significantly different (p = 0.04): sacrum (sedated: 36 %, non-sedated: 21 %), heels (sedated: 33 %, non-sedated: 17 %), from equipment (sedated: 31 %, nonsedated: 62 %).
Conclusions There were no significant difference in the incidence of pressure ulcers in the two groups. An interesting difference in the localization of the pressure ulcers was found. The sedated patients mainly had ulcers in the classical localizations, namely sacrum and heels, whereas the non-sedated mainly had ulcers related to equipment, in diverse localizations such as the face, limbs and genitalia. Considering the long-term prognosis, ulcers deriving from equipment are easier to relieve and must be expected to heel faster. . In multivariable analysis, the duration of ICU stay more than 5 days was independently associated with delirium incidence (P = 0.042). We also found that patients who stayed more than 5 days in ICU showed significant reduction in night sleep time compared to patients who stayed less than 5 days (00:42 ± 0:46 vs 2:04 ± 1:25, P = 0.012), despite of similar total sleep time.
Conclusions The quantity and quality of sleep in critically ill patients were poor. The long duration of ICU stay disrupted circadian rhythm which might contribute to the development of delirium in critically ill patients.
Evaluation of a sedation protocol in mechanically ventilated patients in a medical intensive care unit: a pilot study Y.J. Lim 1 , A. Chan 1 , S. Tang 2 Introduction Mechanically ventilated patients frequently receive analgesia and sedation to manage pain and agitation in the intensive care unit (ICU). Current clinical practice guidelines advocate the maintenance of light target levels of sedation along with the use of structured sedation protocols and daily sedation interruption. A sedation protocol was therefore developed and implemented in a medical intensive care unit (MICU) at a tertiary hospital to standardize the management of analgesia and sedation in mechanically ventilated patients.
Objectives To evaluate the impact of a sedation protocol on patient outcomes in mechanically ventilated patients.
Methods This observational before-after study was conducted in the MICU at the National University Hospital (NUH), Singapore between September 2014 and March 2015. The sedation protocol incorporated daily sedation interruption and routine objective assessments of pain, agitation and delirium by nurses and advocated titration of analgesia and sedation to maintain a target Richmond Agitation Sedation Scale (RASS) range of -2 to 0. Data were collected retrospectively from electronic patient records. The primary outcome was the duration of mechanical ventilation, and the main secondary outcomes included the number of ventilator-free days at day 28, ICU length of stay, ICU mortality and 28-day mortality.
Results The study included 53 and 41 patients before and after protocol implementation respectively. There was significant improvement in the percentage of ICU days with daily sedation interruption in the post-implementation period (23.6 % vs 35.9 %, p = 0.0087). There was a trend for decreased duration of mechanical ventilation after implementation ( 
This study did not receive any grants.
Effect of dexmedetomidine on weaning from mechanical ventilation in intensive care patients S.L. Nunes 1 , S. Introduction Mechanically ventilated intensive care patients are traditionally sedated to assure analgesia, anxiolysis and comfort. This might have negative effects such as prolonged mechanical ventilation (MV) and longer length of stay (LOS). Dexmedetomidine has been shown to shorten time to extubation, but its role in the weaning process is not fully elucidated.
Objectives To determine whether sedation regimes affect the weaning process.
Methods This was a non-interventional, multicenter, retrospective study. Lightly to moderately sedated intubated adult patients mechanically ventilated for ≥ 24 h were included. SAPS III scores were measured at admission. After admission to the intensive care unit (ICU) and until fit for weaning all patients were sedated with standard of care according to their respective clinics protocol. During weaning period patients sedated with only dexmedetomidine (DEX) were compared to those sedated with midazolam and/or propofolstandard of care (SOC) or SOC + dexmedetomidine (SOCDEX) concerning weaning time. Weaning time, was defined as time from "fit for weaning" to extubation. Total time on MV and LOS in the ICU were measured. Amount of sedatives and analgesics used as well as anxiety and ICU delirium were recorded using NuDESC/CAM-ICU. Introduction Opioid drug dependency is not uncommon worldwide and withdrawal syndrome is a major clinical concern when these patients are admitted in intensive care unit (ICU) with low levels of consciousness.
Objectives We hypothesized if a software could be designed to estimate daily need of these patients to opioids and if a protocol could be designed and implemented to concomitantly control pain, agitation and delirium (PAD) and prevent withdrawal signs in this population during ICU admission.
Methods A multidisciplinary team designed the software and protocol. Methadone was used to prevent withdrawal syndrome and pain was assessed hourly, by Behavioral Pain Scale and controlled by morphine or fentanyl. Level of sedation was also assessed hourly, by Richmond Agitation-Sedation Scale and controlled by midazolam or propofol, according to the protocol. Delirium was checked by Confusion Assessment Method for ICU, once in every working shift.
Results Thirty patients with history of opium dependency were recruited during an 8-month period in 2 mixed medical-surgical ICU's. The protocol was effective to completely prevent the withdrawal syndrome in 24 patients (80 %). The average need to methadone was 14.5 ± 22.2 mg in the patients.The pain, sedation and delirium were evaluated and documented by the staff in 97, 98 % and 56 % of situations, respectively. Pain and sedation scores were within acceptable limits in 93 and 98 % of occasions, respectively. Delirium occurred in 2 patients during the ICU stay.
Conclusions Implementation of a PAD protocol and using a software, especially designed for the opium dependent patients is feasible. Management of PAD could be effectively done with a multidisciplinary approach, along with prevention of withdrawal syndrome. Introduction The numeric rating scale (NRS) and skin conductance responses per second (NSCR) are both used as methods to assess pain in the perioperative setting (1). An experimental study was conducted to investigate the relationship between NRS and NSCR, and how these measures are related to anxiety and degree of pain stimulation.
Methods Eighteen volunteers were exposed to conditions simulating ICU circumstances using pictorial emotional stimuli (neutral, positive, negative), authentic ICU sound (noise, no noise) and electrocutaneous stimulation (pain, no pain). The electrical stimulation was individually titrated prior to the experiment to induce moderate pain (40 mm > VAS < 60 mm) and NSCR was measured throughout the experiment. Conclusions Both NRS and NSCR are reliable indicators of pain, and the correspondence between NSCR and actual pain stimulation moreover validates the use of NSCR as a measure of pain in patients. However, NRS is also sensitive to the contextual setting and anxiety, which NSCR is not. A discussion, whether to administer analgesic or ataractic drugs during the perioperative stage when NRS is moderate or higher, is warranted. Introduction According to the recent guideline (2013), nonbenzodiazepine drugs, like propofol, are preferred to benzodiazepines in sedation of ICU patients undergoing mechanical ventilation due to decreased duration of mechanical ventilation, shortened ICU stay, lower risk of patients death and decreased costs of treatment. Propofol is a relatively well known drug, nevertheless the influence of various factors connected with patients, like demographics, health status or co-administered drugs on the propofol pharmacokinetics has not been fully understood.
Objectives The aim of our study was to examine the pharmacokinetics of propofol in a heterogeneous group of patients sedated in an ICU. The specific objective was to investigate the influence of different variables monitored and patients' health status descriptors, like SOFA or presence of sepsis, on the PK of propofol.
Methods The propofol concentration-time profiles were obtained from 29 patients. All the subjects were evaluated according to APA-CHE II score and SOFA score, whereas the level of sedation was applied according to modified Ramsay Sedation score to achieve a sedation score of 3-4. Non-linear mixed-effects modelling in NON-MEM (Version 7.3.0, Icon Development Solutions, Ellicott City, MD, USA) was used to analyse the observed data. Blood samples for propofol assay were collected from the patients' arteries on every day of the infusion, at the selected time points after its termination. The propofol concentration in the plasma was measured within eight weeks by HPLC method with a fluorescence detector. Nonparametric bootstrap and visual predictive check were conducted to evaluate the adequacy of the induced model to describe the observations. Results Propofol pharmacokinetics was best described with a threecompartment disposition model. A typical value of propofol clearance (1.46 L/min) approximated liver blood flow. The volume of distribution at steady state was high 955.1 L, but consistent with other studies on ICU patients. We were unable to identify any statistically significant covariate relationships between PK parameters and opioid type, SOFA score at admission, APACHE II, predicted death rate, reason for admission to the ICU (sepsis, trauma or surgery), gender, body weight, age, infusion duration and C-reactive protein.
Conclusions The population PK model was successfully developed to describe the time course of propofol concentration in ICU patients undergoing prolonged sedation. Despite a very heterogeneous group of patients, consistent PK profiles were observed.
Introduction Fluid challenge (FC) is commonly used to increase cardiac index and oxygen delivery. A Tidal volume (Vt) > 8 ml/kg, which is required to guarantee the efficacy of dynamic index of fluid responsiveness in predicting fluid responsiveness, is nowadays not recommended in operating room (1). The identification of early variation of hemodynamic variables may act as a clinical target or a safety limit to stop infusion. This approach has been successfully used to assess fluid responsiveness in critically ill patients ventilated with low tidal volume (2) . We evaluated the early variations after a FC in operating room of cardiac cycle efficacy (CCE) and dicrotic pressure (P dic ) to improve baseline pulse pressure variation (PPV) reliability and predict fluid responsiveness. In responders, the reduction of PPV during fluid challenge was statistically significant between baseline and minute 3 (p < 0.01), baseline and minute 4, 5 and 10 (p < 0.001). The increase of CCE during fluid challenge was statistically significant between baseline and minute 4 (p < 0.05). The increase of dicrotic pressure during fluid challenge was statistically significant between baseline minute 4 and 10 (p < 0.01), baseline and minute 5 (p < 0.001).
In non responders, PPV and dicrotic pressure did not change significantly during the FC while CCE was significantly reduced from baseline to minute 10 (p < 0.05) (Figs. 69, 70, 71 ). Discussion In this pilot study the baseline values of CCE and P dic significantly increased reliability of PPV. During the FC nor the PPV, neither P dic significantly changed in non responders, while the CCE was reduced at the end of the FC. In responders, the reduction of PPV and the increase of CCE and P dic were significant and the first time point of significance was minute 3 for PPV and P dic and minute 4 for CCE, potentially acting as an early safety-limit for the FC. Introduction A positive fluid balance is associated with worse outcomes in the critically ill [1, 2] , and it has been suggested that conservative fluid administration or deresuscitation (active removal of fluid using diuretics or renal replacement therapy (RRT)) may be beneficial following haemodynamic stabilisation [3] .
Objectives We performed a systematic review and meta-analysis to evaluate the efficacy and safety of conservative or deresuscitative fluid strategies in adults and children with acute respiratory distress syndrome (ARDS), sepsis, or systemic inflammatory response syndrome (SIRS) following initial resuscitation [4] .
Methods We searched Medline, Embase, and the Cochrane central register of controlled trials without restrictions, and manually searched conference proceedings for the last 5 years. Two reviewers independently assessed publications. We included randomised controlled trials comparing two or more fluid regimens in which fluid balance differed, and observational studies investigating the relationship between fluid volume administered or fluid balance achieved and patient outcomes. We excluded studies published before 1980, studies of neonatal, post-cardiac surgical, or heart failure patients, and observational studies with fewer than 50 participants.
Results In a meta-analysis of the 7 included randomised trials (n = 1390), we found a non-significant reduction in mortality with a conservative or deresuscitative fluid strategy (pooled odds ratio 0.86, 95 % confidence interval (CI) 0.68-1.09) compared to a liberal strategy or usual care (Fig. 72) . We found a non-significant reduction in RRT use with a conservative or deresuscitative fluid strategy (2 studies, pooled odds ratio 0.73, 95 % CI 0.51-1.05). Four trials reported shorter length of ICU stay or increased number of ICU-free days, and 2 studies reported shorter duration of mechanical ventilation or increased ventilator-free days with a conservative or deresuscitative fluid strategy compared to a liberal strategy or usual care. Marked clinical heterogeneity was present.
Conclusions A conservative or deresuscitative approach to fluid management may improve patient outcomes, and does not appear to increase the incidence of acute kidney injury or RRT use. Large randomised trials comparing alternative fluid regimens are needed to determine the optimal approach to fluid management in critically ill patients.
Correlation between the distensibility index of inferior vena cava collapsability and pulse pressure variation in shock patients J.A. Introduction Fluid administration is one of the principal therapy adopted in order to achieve early haemodynamic stabilization in septic patients. Despite international guidelines promote rapid volume expansion in the early stages of shock [1] , several studies have recently shown that excessive fluid balance in septic patients is correlated with increased mortality [1] Objectives This study aims to investigate the impact of fluid balance on mortality in septic patients along with any associated electrolytes (strong ion difference-SID) and pH imbalance Methods This pilot retrospective study enrolled approximately 10 % of the adult patients admitted to the intensive care unit (ICU) of the Gemelli University Hospital with a diagnosis of severe sepsis/septic shock. We excluded pregnant women and those who survived less than 48 hours. We collected all the data concerning daily fluid balance, arterial blood gases (ABG), the hemodynamics and daily SOFA, until day 28 of ICU stay or discharge. Conclusions In our population positive fluid balance was independently associated with increased mortality at 90 days, but without any significant differences in terms of SID and pH.
Reference(s) Introduction Fluid management is one of the most difficult tasks in critical care medicine. A recent study shows that in current practice, fluid administration is not evidence based despite a lot of tools available for physician (1) . However many of them are invasive or not always applicable depending on clinical context. Carotid doppler, a non invasive and easy-to-use method, has shown excellent predictive values to monitor fluid responsiveness after passive leg raising (2) . Otherwise, mini fluid challenge is described as a reliable alternative to classical fluid challenge to prevent fluid overload.
Objectives To assess if variation of carotid doppler flow can predict fluid responsiveness after a mini fluid challenge. Methods This prospective observational study was performed from September to December 2015. Patients requiring volume expansion were eligible for enrollment. Patients less than 18 years old, with carotid stenosis or poor insonation were excluded. We recorded the variation of carotid doppler flow after 100 cc of cristalloids (ΔDc100) over 1 min and the variation of velocity time integral (VTI) after an additional infusion of 400 cc over 14 min assessed by transthoracic echocardiography. The cardiac output (CO) was calculated as CO = VTI x Heart Rate x Aortic Surface . A patient whose CO increased by 15 % following 500 cc (ΔCO500) was consider as a fluid responder. If mechanical ventilation was required, a lung protective strategy was applied. Statistics: Spearman's correlation test was used. The receiver operating curve (ROC) and grey zone were defined for ΔDc100.
In total, 30 patients were included. Diagnosis admission were severe sepsis/septic shock (22), brain injury (4) and post operative (4). Sixty five percent of patients were ventilated and 45 % required vasopressor support. There was no difference between responders and non responders. Fourteen patients (45 %) were volume responders. Dc100 increased by 32 % +/-24 % in the responders compared with 10 % +/-8 % in the non responders (p < 0.001). ΔDc100 was strongly correlated with ΔCO500 (r 0,78 ; p < 0,001). The best threshold of ΔDc100 was 14 % with a sensitivity and specificity of 93 % and 82 % respectively.
The areas under the ROC curve of ΔDc100 was 0,91 +/-0,01. After bootstrapping (1000 resamples) a grey zone ranging between 11 and 20 % was observed in up to 29 % of patients. Background Sepsis-related acute circulatory dysfunction is a life threatening condition. Peripheral perfusion as a marker of hypoperfusion could be used to trigger initial fluid resuscitation (FR). The response of peripheral perfusion to FR in patients with abnormal perfusion could potentially identify high-risk patients.
Objective Our aim was to study the effects of the first protocolized FR on capillary refill time (CRT) and other perfusion parameters, and the relationship of the response with outcome. Methods Prospective observational study including patients with sepsis and acute circulatory dysfunction just admitted to the Emergency department (ED) and in whom an initial FR was indicated according to standard care. Peripheral perfusion and laboratory assessments were performed before and after protocolized FR. Follow-up of patients until hospital discharge. CRT responders were defined as patients who were able to maintain normal CRT or to normalize abnormal CRT values after FR.
Results One hundred consecutive patients were included. Of 30 patients with an abnormal CRT at admission, 23 (77 %) normalized CRT after initial FR. CRT responders showed a significant decrease in heart rate and lactate, presented less organ dysfunction and requirement of mechanical ventilation. Hospital mortality was significantly lower in CRT responders when compared to non-responders (9.6 % vs. 55.6 %; p < 0.001). In logistic regression analysis only CRT was significantly related to hospital mortality. This association was maintained after adjusting for baseline severity.
Conclusions Patients with sepsis-related acute circulatory dysfunction that exhibit normal CRT after early FR have low mortality rates. In contrast, failure to improve peripheral perfusion in response to initial FR is a strong predictor of mortality. This finding could be very important for the ED or limited-resource settings since it could help to decide on additional diagnostic and treatment options.
Prediction of fluid responsiveness in patients with assisted mechanical ventilation: a comparison of the "fluid responsiveness index" FRI to CVP, global end-diastolic volume index gedvi and stroke volume variation SVV This later has shown to be a useful predictor of fluid responsiveness in cardiac surgery patients [1] .
Objective The aim of the study was to evaluate if dVR is a reliable variable to predict fluid responsiveness.
Methods Twenty-nine critically ill patients requiring FE were included in this prospective observational study. In each patient, Parm was measured three times before FE from the arterial pressure curve obtained from a radial artery catheter 30 sec after occluding the arterial flow by a cuff inflated up to 50 mmHg above systolic blood pressure. The average value of triplicate measurements was calculated. Stroke volume was estimated either by Swan-Ganz catheter or transthoracic echocardiography. A positive response to the fluid expansion was defined as a SV increased by at least 10 %. The optimal cut offs were chosen using a receiver operating characteristic curve (ROC) analysis and identifying the maximal Youden's index. Sensitivity, specificity, and their approximate 95 % confidence intervals were computed. Results In the group of patients who responded to the fluid expansion (n = 19), the mean CVP/RAP was 8 mmHg ±3, the mean Parm was 21 mmHg ±7 and the mean dVR was 13 mmHg ±7. In nonresponders patients (n = 10), the mean CVP/RAP was 8 mmHg ±3, the mean Parm was 26 mmHg ±6 and the mean dVR was 18 mmHg ±6. The best parameter in order to predict fluid responsiveness was dVR, with an area under the curve of 0,77 (95 % confidence interval 0,57-0,97); a dVR cut-off of < 15 mmHg predicting a successful FE with a sensitivity of 74 % and a specificity of 90 %. In comparison, for Parm, the area under the curve was 0,73 (95 % confidence interval 0,54-0,92); a Parm cut-off of < 24 mmHg predicting a successful FE with a sensitivity of 74 % and a specificity of 70 %.
Conclusion Venous return gradient estimated by arm occlusion pressure is at least as good as Parm for the prediction of fluid responsiveness in critically ill patients.
Reference(s) Introduction The ability of echocardiography and analysis of mitral profile to predict fluid responsiveness in a septic shock with left systolic heart failure is difficult to manage.
Objective The objective of the study was to evaluate the ability of mitral profile and its evolution with a test of passive leg raising to discriminate fluid responsiveness in septic shock with left systolic heart failure.
Methods 60 patients in septic shock and left systolic failure, monitored by transthoracic echocardiography (TTE) and continuous measurement of cardiac output (CO) (catheter pulmonary artery catheter (PAC) or transpulmonary thermodilution (TPTD)) were included. Mitral profile (E, A, E/A, E´lateral, E´septal, E´average, E/E´), CO, pulmonary artery occlusion pressure (PAOP) and extravascular lung water (EVLW)) were collected before volume expansion (VE), after passive leg raising (PLR) and after VE with 500 ml of crystalloid solution. Variation of each hemodynamic values after VE (Δ(VE)) and after PLR (Δ(PLR)) was performed. The left systolic heart failure was defined with left ventricle ejection fraction (LVEF) ≤ 40 %. Patients were classified into two groups according to their response after VE measured by thermodilution: responders (R) defined by an increase ≥ 15 % of CO, and non-responders (NR). Background Patients in critical care settings are often at risk of developing hypotension, which can lead to poor outcomes. To address this need for early detection of hypotensive events, we have developed a hypotension probability indicator (HPI™). A hypotensive event was defined by any time period where MAP < 65 mmHg. After training the HPI™ model on 3,000 ICU and surgical patients, we tested it on an independent data set and demonstrated sensitivity and specificity > 80 % for detection of an event respectively at 5, 10, and 15 minutes prior to its start. To give further clinical value to the HPI™ as a decision support index, there is a need for understanding the underlying reasons for a patient trending towards hypotension. In this study, we evaluate the use of stroke volume (SV), cardiac output (CO), stroke volume variation (SVV), dynamic elastance (Ea dyn), systemic vascular resistances (SVR), and dp/dt to classify patients into 4 prescriptive hypotensive groups: 1) Decreased preload, 2) Decreased afterload, 3) Decreased contractility, and 4) Uncertain.
Methods Data used in this study came from the MIMIC II MIT database (n = 326). Arterial pressure waveforms from these patients were processed through FloTrac (Edwards Lifesciences) for calculation of mean arterial pressure (MAP), CO, SV, SVV, Ea dyn, dp/dt, and SVR. All data was annotated for events as defined previously. Events were then classified into 4 groups based on % change from 15 to 0 minutes prior to event: 1) Decreased preload (decrease in SV, CO, and increase in SVV); 2) Decreased afterload (decrease in Ea and SVR); 3) Decreased contractility (decrease in dP/dt); and 4) Uncertain (did not meet any criteria). Any events that met more than 1 group criteria were not used in the analysis to avoid any overlap. After classification of events, % changes of SV, CO, SVV, Ea dyn, SVR, and dP/dt from 15 to 10 minutes prior to event and 15 to 5 were evaluated to assess if an event's underlying cause could be identified early on. A t-test was used to assess significant difference (p < 0.05) in mean % changes by group.
Results / conclusions There were 25,419 total hypotensive events. Group 1 contained 1,200 events, 2 had 2,066, 3 had 7,290, and 4 had 5,283. 9,560 events were not used in analysis due to data outliers or meeting more than 1 group criteria. Overall, each group's 5 minute % change profile was different at 5 and 10 minutes (Fig. 75) . % change in CO, SVV, and SV were significantly different when comparing Group 1 to 2, 3, and 4 at 10 minutes. % change in Ea dyn and SVR were significantly different when comparing Group 2 to 1, 3, and 4 at 10 minutes prior to event. % change in dP/dt were all significantly different when comparing Group 3 to 1, 2, and 4 at 10 and 5 minutes prior to event. In conclusion, the underlying cause of a hypotensive event can potentially be classified into 1 of 4 prescriptive groups up to 10 minutes prior to the start of an event.
Introduction The dynamic arterial elastance (EaDyn) is used to predict the rising of mean arterial pressure (MAP) from fluid challenge in fluid responders. However, according to ventricular-arterial coupling, arterial resistance (Rart), not arterial elastance should be a predictor for MAP responsiveness Objectives Our study aimed to understand the relationship between arterial resistance variables and arterial elastance variables, and analyzed their performances to predict MAP responders in septic shock patients received fluid challenge (FC). Methods The Rart was MAP divided by cardiac output. The EaStat was pulse pressure (PP) divided by stroke volume (SV) and the EaDyn was pulse pressure variation (PPV) divided by stroke volume variation (SVV). We obtained these parameters at baseline and at the end of fluid challenge (FC Introduction In high-risk surgical patients arterial catheterization is needed to monitoring blood pressure and perform blood gas analysis, both in the operating room and ICU. The Seldinger technique is considered the gold standard, but many catheters are recently proposed to be as effective and safe.
Objectives Evaluate effectiveness and safety of BBraun Introcan Safety 3 for arterial catheterization in adult high-risk surgical patients scheduled to postoperative ICU stay, compared to Seldinger devices. Methods BBraun Introcan Safety 3, Vygon Leader-Cath and Arrow Arterial Catheterization Set were analysed for arterial cannulation in adult high-risk surgical patients scheduled to postoperative ICU stay, for the follow parameters: adequate size, easy recognition of the vascular space, easy Introduction, traumaticity, cannula fixation, efficacy in blood pressure monitoring and taking blood samples for the first 96 hours, safety. The catheter was placed in the operating room before induction of general anesthesia and maintained during ICU stay. A questionnaire was administrated to the physician after arterial cannulation and each parameter was score as poor (2 points), middling (4 points), sufficient (6 points), good (8 points) or excellent (10 points); the maximum score was 70/70 points. Failures and complications were recorded. Appropriate statistical analysis was performed to compare effectiveness and safety of the three devices and p < 0.05 was considered to be significant. The non-inferiority margin was defined as 5 %.
Results 100 arterial cannulations for each device were performed by 10 medical doctors with a mean experience in arterial catheterization of 8 years. Seldinger kits obtained the best score (56/70 points), but Introcan Safety 3 resulted to be non-inferior (54/70 points), with a 4 % of failure rate. No statistical differences were founded for adequate size, easy recognition of the vascular space, easy Introduction, traumaticity, cannula fixation, efficacy in blood pressure monitoring and taking blood samples during the first 96 hours. Introcan Safety 3 emerged to be the safer device, due to its anti-reflux and antipuncture systems (p < 0.05). No severe complications were reported during and after procedures. Conclusions BBraun Introcan Safety 3 resulted a safe and effective device to perform arterial catheterization in adult high-risk surgical patients scheduled to postoperative ICU stay.
Introduction The transpulmonary thermodilution (TPTD) technique of cardiac output monitoring which applies the Stewart Hamilton principle is well established in terms of cardiac output accuracy.(1) However, it is an invasive procedure that involves various risks. (2) . Researchers are continuously exploring potential less invasive alternatives. Transthoracic echocardiographic left ventricular outflow tract (LVOT) measurements is a recognized tool for assessing the cardiac output noninvasively. However, there is paucity of definitive data concerning its accuracy.
Objectives We aimed to validate the noninvasive transthoracic echocardiographic estimates of the stroke volume against the stroke volume measurements obtained invasively by the TPTD technique. Methods Twenty successive critically ill patients in whom a PiCCO™ cardiac output monitor (9 female; 11 male; mean (SD) age 66 (12.9) years) were the subject of this study. We compared 20 pairs of stroke volume (SV) readings obtained simultaneously from the TPTD component of the PiCCO™ cardiac output monitor and from transthoracic echocardiography (LVOT diameter and velocity time integral).
The averaged values of SV measurements from Echocardiography compared to the TPTD were 61 (20) vs. 67 (28) ml. The SV measurements from Echocardiography and TPTD showed a significant correlation (p = 0.015), the mean bias was 6.1 ml and the 95 % limits of agreement (mean difference ± 1.96 SD) were 47.04 to -34.79 ml.
Conclusions Monitoring of the cardiac output noninvasively using transthoracic echocardiography is a reproducible feasible option. Background Traumatic Hemorrhagic Shock (THS) is a leading cause of preventable death following severe traumatic injury. The microcirculation is the ultimate structure concerned with tissue perfusion, and is therefore of primary importance during THS. The microcirculation was examined in a large animal model of THS, in order to investigate the effects of microcirculatory dysfunction during resuscitation. Methods Baseline standard microcirculatory parameters were obtained for 22 large white pigs using sublingual Incident Dark Field (IDF) video-microscopy. All animals were subjected to a standardized hind-limb injury followed by a controlled haemorrhage of approximately 35 % of blood volume (shock phase). This was followed by 60 min of fluid resuscitation with either 0.9 % saline or component blood products and a target SBP of 80 mmHg (early resuscitation phase). All animals were then given blood products to a target SBP of 110 mmHg for 120 min (mid resuscitation phase), and a further 100 min (late resuscitation phase). IDF readings were obtained at the mid point of each of these phases. Cardiac output was measured using a pulmonary artery catheter. Animals were divided into above average (A) and below average (B) perfused vessel density (PVD) groups based on the lowest recorded PVD measurement taken during the shock and early resuscitation phases.
Results During shock and early resuscitation Group A (n = 10) had a mean PVD of 10.5 (SD ± 2.5) mm/mm 2 , and Group B (n = 12) 5.5 (SD ± 4.1) mm/mm 2 . During the later resuscitation phases, Group A maintained a significantly higher PVD than Group B. Group A initially had a higher cardiac output but the difference between the groups narrowed as resuscitation progressed. At the end of resuscitation group A had significantly lower plasma lactate, higher lactate clearance, lower standard base deficit, and smaller mixed venous -arterial CO 2 gradient. There was no significant difference in blood pressure between the two groups at any stage. There was a wide spread of PVD for a given blood pressure, especially during the shock and early (hypotensive) resuscitation phases (Fig. 78) . The choice of initial resuscitation fluid appeared not to produce differing effects in terms of microcirculatory perfusion (Figs. 79 and 80) .
Note: This abstract has been previously published and is available at [1] . It is included here as a complete record of the abstracts from the conference. Conclusions Early changes in microvascular perfusion are key determinants in subsequent tissue perfusion following fluid resuscitation, and appear unrelated to pressure based parameters. Choice of initial resuscitation fluid appears to have little impact on microcirculatory perfusion during resuscitation from traumatic haemorrhagic shock. Microcirculatory parameters may be more reliable markers of physiological insult than global haemodynamic parameters, and are potential targets for goal-directed resuscitation. Table 58 . Radial arterial pressure waveforms were recorded with a FloTrac™ sensor (Edwards Lifesciences, Irvine, CA). The waveforms were passed to the algorithm to calculate the hypotension probability. The receiver operating characteristic (ROC) analysis was used to assess algorithm performance.
Results 16,078 hypotensive events were registered, on average 34 events per patient with a duration of 11 (±89) minutes per event.
The algorithm was able to predict hypotension with a sensitivity and specificity of 90 %, 87 % and 86 %, for 5, 10, and 15 minutes prior to the event, respectively. The area under the curve (AUC) is 0.96, 0.94, and 0.93, for 5, 10, and 15 minutes prior to the event, respectively (Fig. 81) .
Conclusions These data suggest that HPI™ is capable of predicting hypotensive events with high sensitivity and specificity in ICU patients, up to 15 minutes prior to event. Introduction Machine learning is an emerging technique that enables computers to learn from data without been explicitly programmed [1] , in the medical field has been used for classification and prediction analysis in both supervised and supervised fashion [2] . Cardiomechanics determinants end-systolic and arterial elastances and ventricular arterial coupling (VAC) in the critical care patient treated for hemodynamic derangement has been recently investigated [3] .
Objectives In this study we aimed to identify the possibility of a machine learning approach to classify hemodynamic data in the intensive care unit. Methods We used three non linear supervised machine learning approaches (multilayer perceptron neural network, decision tree and gaussian support vector machine) to classify responders vs non responders from a dataset of 115 patients using Matlab R2015b software. The classification models were run three times with respect to independent variables: mean arterial pressure (MAP), arterial elastance (Ea), VAC.
Results Best performance of the classification models was carried out by decision trees, in all runs. With accuracy of 86.7 % with respect to MAP increase, 96.8 % with respect to VAC decrease and 80 % with respect to Ea increase.
Conclusions In this analysis we demonstrated the feasibility of a machine learning approach to hemodynamic data analysis in the intensive care patient. Decision tree was found to be the most effective technique in analysing hemodynamic data. The models Introduction Evaluating and monitoring contractile cardiac function is a key element in hemodynamic management of critically ill patients. However, evaluation of intrinsic contractile cardiac function is difficult in a clinical setting.
Objectives Aim of the study was to evaluate a novel approach of assessing load-independent left-ventricular contractility based on pulse contour analysis (rate of aortic maximum pressure rise (dP/ dt Ao )) and estimation of end-diastolic volume (VED) by transcardiopulmonary thermodilution (TCPTD) in an experimental animal model in pigs.
Methods 16 domestic pigs were studied. dP/dt Ao as evaluated by pulse contour analysis was related to VED by TCPTD. Direct measurement of rate of maximum pressure rise in left ventricle (dP/ dt LV ) related to VED (cdP/dt LV ) served as experimental reference of preload independent contractility. [1] Measurements were carried out in normal cardiac function and experimentally impaired cardiac function (continuous infusion of verapamil) during a wide modification of cardiac preload (withdrawal of blood 20 ml kg -1 bodyweight).
Results While impairment of contractile cardiac function by continuous infusion of verapamil resulted in significant changes of cdP/dt Ao and cdP/dt LV (p < 0.05), neither in normal as well as in impaired cardiac function did cdP/dt Ao and cdP/dt LV present significant changes during preload modifications (p > 0.05).
Conclusions Estimation of cdP/dt Ao by means of pulse contour analysis and thermodilution provides reliable assessment of preloadindependent left ventricular contractility and its changes in an experimental animal model. (1), with correlation demonstrated between derangement in muscle tissue oxygenation and mortality (2) . Human skin has an exquisite microcirculatory blood supply which can be visualized by means of infrared thermography. Thermography may therefore be a potentially useful non-contact, real-time monitor of microcirculatory function.
Objectives To investigate the thermal infrared profile of the palm during a VOT in healthy volunteers. Methods Participants were recruited from faculty and students at the University of Leicester. Room temperature was confirmed between 19-21oC throughout data acquisition and participants were allowed a period of acclimatization prior to measurement. Baseline blood pressure was measured in the left forearm. The right forearm was then placed on a bench with a blood pressure cuff placed around it. A FLIR T650sc thermal imaging camera was placed at a distance of 1 meter from the participant. Thermal video recording was commenced and the blood pressure cuff was inflated to 50 mmHg above the previously measured systolic pressure for a total of 3 minutes. Recording continued for 5 minutes following deflation of the cuff. Average palm temperatures were measured using a 100 x 100 pixel sample. Data were extracted using FLIR Tools + software and analyzed using Microsoft Excel and R-Studio. Conclusion From these results it can be concluded that the rate of reheating per second measured using infrared thermography following a vascular occlusion test in healthy volunteers is 0.015 + / -0.009°C .s -1 . It is our hypothesis that this gradient will be prolonged in patients with sepsis. If demonstrated to be true, this technique could be used as a non-invasive diagnostic technique in sepsis.
Introduction Focused Intensive Care Echo (FICE) is becoming an increasingly important tool in the intensivists' arsenal of haemodynamic assessment. It has the ability to diagnose structural and dynamic problems, is non-invasive, and inter-user variability is limited. Rigorous training and CPD is essential in order to prevent mismanagement based on incorrect findings. In the UK the Intensive Care Society administers FICE accreditation with this becoming compulsory for critical care trainees in future. Methods Every patient who undergoes diagnostic FICE has the result documented in their notes and in an audit folder. This follows a standardised "sticker". All results documented in this folder, ranging between December 2014 and January 2015, were collated and analysed in a spreadsheet. The aim was to assess how FICE impacts on care at a district general critical care unit. Results 57 patients underwent documented FICE 37 % of these scans occurred during the weekend Indications for scan: Haemodynamic Instability (5/57), Haemodynamic Instability -Post Operative (9/57), PE (1/57), Post Cardiac Arrest (8) Conclusion It is clear that FICE echo has had a significant impact on the management strategies of a significant number of patients, however the impact of this on morbidity/mortality is impossible to assess. It is also interesting to see that a disproportionate number of scans were performed during the weekend, when formal cardiac investigations aren't always as available as during the week. Documentation was generally good but some gaps in documentation were found and require improvement. We suggest that this data, although limited in number, supports funding of expanded FICE training and availability at district general critical care units.
Bedside assessment of preload in critically ill septic patients by echocardiography and electrical cardiometry D. Introduction Sepsis is a clinical syndrome characterized by a systemic inflammatory response to an infectious process. Patient with acute myocardial infarction (AMI) may be predisposed to develop to sepsis during admission.
Objectives The aim of this study was to evaluate the rates of sepsis during admission in patients with acute myocardial infarction (AMI) and their associated factors, and the long-term mortality in patients with AMI in associated with or without sepsis. Methods The data from the National Healthcare Insurance Research Database (NHIRD) in Taiwan between January of 2000 and December of 2012 was used in this study. All patients who were first admitted to AMI were enrolled. Among the 186,112 identified cases hospitalized for AMI, 13,065 cases with an alternative diagnosis of sepsis (ICD: 038) were identified. Of the remaining 173,047 cases, patients with any diagnosis of infectious disease were excluded, leaving 146,737 AMI cases for comparison. For analysis, survival was defined as the end date of National Healthcare Insurance coverage.
Results The overall rate of sepsis during admission in patients with AMI was 8.18 %. The rates of sepsis in patients with AMI were 11.70 % in female and 6.63 % in male (P < 0.001). The rates of sepsis in patients with AMI were 3.19 % in percutaneous coronary intervention (PCI) group and 14.06 % in non-PCI group (P < 0.001). The rates of sepsis in patients with AMI were 3.79 % in below-65-year-old group and 11.32 % in equal-to-or-more-than-65-year-old group (P < 0.001). About the comorbidities, patients with AMI and sepsis have significant higher rates of hypertension, dyslipidemia, diabetes, peripheral vascular disease, congestive heart failure, end-stage renal disease, cerebral vascular accident and chronic obstructive pulmonary disease (all P < 0.05 Conclusions In patients with ACS, clinical manifestations of AHF at admission constitute a strong predictor of adverse outcome in the follow up that may be significantly modified by the coronary revascularization strategy
Ten (1). There is no consistent evidence of mortality reduction, however a recent meta-analysis (2) demonstrated that levosimendan reduced mortality in the overall population and subpopulations of cardiac surgery and cardiology.
Objectives Given the uncertain benefits, an analysis of the utilisation of levosimendan for low cardiac output states was undertaken.
Methods The retrospective analysis was performed at a single center. Data from 62 admissions due to low cardiac output state, treated with levosimendan, was retrospectively abstracted; demographics, illness severity, co-morbidity, haemodynamic, metabolic, biochemical, resource utilisation, organ support and hospital outcomes where analysed.
The population group had a mean age of 59.2 years (range 19-84) and a mean APACHE II score of 23.7 (range 7 -61). Causes of low CO state included myocardial infarction (n = 14, 22.5 %), after cardiac arrest (n = 6, 9.7 %), after cardiac surgery (n = 7, 11.3 %), septic cardiac dysfunction (n = 5, 8.1 %), acute cardiomyopathies (n = 7, 11.3 %) amongst other causes (n = 23, 37 %).
Levosimendan was received at a variable point during their ICU treatment (mean day 3.7, range 0 -14 days) and was usually the 3rd inotrope (range 0-5) commenced. Treatment with levosimendan resulted in significant improvements in CI (p = 0.013) and acidosis (p < 0.0001) . There was a trend towards improved lactate clearance and oxygenation. Overall length of stay (LOS) in ICU was 12.7 days (range 1 -60), 30day mortality was 59.7 % and survival to discharge was 38.7 %. Commencing levosimendan within 48 hours after admission resulted in decreased duration of ventilation (p 0.013) and ICU LOS (p 0.0009), with a trend towards a reduction in length of renal replacement therapy (p 0.06) (Table 64) . Similar benefits were not demonstrated if levosimendan was introduced as a first or second vasoactive agent compared to a third or fourth agent. However survival to discharge was improved (41.5 % vs 33.3 % respectively).
Conclusions When levosimendan was used early in the disease process ICU LOS and duration of ventilation were reduced. When used as a first or second inotrope, rather than a third or fourth, survival to discharge was higher. More research is required to determine the optimum timing of therapy. Table 66 .
Conclusions In three periods study there was significant differences between mortality and thrombolysis place in STEMI. Early thrombolysis in prehospital and emergency hospital areas showed decreased in mortality ICU.
Introduction The Killip class classification for heart failure it is used to predict short-term mortality in patients with acute coronary syndrome (ACS) Objectives To determine the contemporary long-term prognosis of ACS with acute heart failure graded according to the Killip classification.
Methods Cohort study of consecutive hospitalized patients with ACS diagnosis from 2004 to 2009. Follow-up was done by clinical review or telephone contact and death or cardiovascular events were recorded, as well as the cause of death Results 5070 patients were included with a complete follow up after a mean of 5.8 ± 2.6 years. The clinical characteristics were analyzed in relation with Killip class at admission (shown in Table) . A stepwise gradient in the adjusted hazard ratio (HR) for mortality was observed with increasing Killip class: class > I HR 4.35 (95 % CI 3.81 to 4.97) unexpectedly, in a landmark analysis excluding deaths < 30 days after admission, patients in Killip class IV had a lower adjusted long-term mortality than those in class III (shown in Figure) .
Conclusions The heterogeneity in early versus late risk in patients with Killip class IV heart failure it is present in our contemporary cohort highlighting the importance of an appropriate early treatment in cardiogenic shock patients. Conclusions Type 2 MI reveals rather common and frequently misdiagnosed in ICU patients. This lead to management delay and errors. Patients are rather young, without underlying cardiovascular risk factors. They exhibit a myriad of clinical conditions in which the common factor is oxygen supply-demand mismatch. They have less cTn I levels but relatively high mortality related to the associated illness severity. Background HAS-BLED scoring in assessment of bleeding risk among patients with atrial fibrillation has been proven effective in risk stratification. This helps in anticoagulation management as well as in assessing morbidity and mortality of patients with atrial fibrillation who are on anti coagulants. Objective This study aims to show if HASBLED scoring is also useful in bleeding risk assessment among patients without atrial fibrillation admitted in the medical intensive care unit. Study design This is a single centered retrospective cross sectional Study.
Methods Descriptive statistics will be reported as mean ± SD, median (IQR) or proportion (%) as applicable and presented in tables or graphs. Cox regression analysis was used to determine association of Introduction As myocardial infarction can result in permanent ischaemic damage, early revascularization is vital to spare myocardium. However, the downside of this treatment is reperfusion injury, and this in itself will contribute to long-term ventricular dysfunction. Strategies attenuating reperfusion injury have, to date, proved unsuccessful. As reactive oxygen species (ROS) derived from the mitochondrial electron transport chain (ETC) are the main cause of reperfusion injury, modulation of oxidative phosphorylation (peri-revascularization) may confer benefit. Sulphide donors reversibly inhibit complex IV of the ETC so this approach offers putative benefit.
Objectives To test the slow-release sulphide donor, MGC-0109, in a cell (cardiomyocyte) model of ischaemia/reperfusion injury. Methods H9C2 cells were subjected to 24 h hypoxia followed by 2 h reoxygenation (in room air). Cells received MGC-0109 (0.005-5.5 mM) or vehicle (cell medium) at the beginning of the reoxygenation period. In separate experiments, normoxic cells were treated with the ROS, hydrogen peroxide (H 2 O 2 ) 500 microM for 4 h with MGC-0109 (5.5.mM) added to half the wells after 1 h. Cell viability was assessed by flow cytometry using an Annexin V/PI assay. One-way ANOVA and Tukey posthoc testing (SPSS v20) was used to test for statistical significance.
Results Ischaemia/reperfusion reduced cell viability from 94 % to 79 % (Fig. 86) . MGC-0109 adminstered at the onset of reperfusion increased cell survival in a dose-dependent manner. At the highest concentration survival was similar to cells that did not undergo I/R. Protective effects were also seen with addition of MGC-0109 to H 2 O 2 -treated normoxic cells (data not shown).
Conclusions MGC-0109 reversed cell death related to reperfusion injury. Further studies are ongoing to confirm if its mechanism of action is via mitochondrial ETC inhibition. Introduction Rapid revascularisation is the treatment of choice to minimize ischaemic injury in acute myocardial infarction. However, this procedure can itself induce reperfusion injury that may further damage the myocardium [1] . Experimental models of myocardial infarction and reperfusion involve temporary ligation of the left anterior descending coronary artery (LAD). This model, though representative of the clinical scenario, is associated with infarcts of variable size, and, consequently, insult severity [2] . However, periprocedural haemodynamics are not well described.
Objectives To assess the impact of insult severity on cardiac, haemodynamic and perfusion markers. Methods Eight instrumented, mechanically ventilated, thoracotomized, male Wistar rats (250-300 g) were subjected to 20 minutes of myocardial ischaemia by temporary occlusion of the LAD. Animals were monitored for up to 240 min post-reperfusion. At baseline, endischaemia and at hourly intervals post-reperfusion, mean arterial pressure (MAP), echocardiographic and arterial blood gas measurements were performed. Aortic peak systolic blood flow velocity (Vmax) was used as a marker of myocardial contractility. At experiment end the infarct area/left ventricle ratio (IA/LV) was assessed by histology to determine insult severity. Comparisons were drawn between mild (<19 % IA/LV, n = 4) and severe (>19 % IA/LV, n = 4) insults, with analysis by two-way ANOVA. P values < 0.05 were considered significantly different. Normality was tested by the Shapiro-Wilk test.
Results Insult severity (IA/LV ratio) was normally distributed with a mean ± SEM of 19 ± 10 %. The severe group (IA/LV > 19 %) had significantly lower MAP and higher lactate values than the mild severity group (Fig. 87, top panel) . Temporal changes in cardiac contractility and output did not however relate to insult severity (Fig. 87, bottom  panel) .
In an experimental rat myocardial ischaemia/reperfusion injury model, blood pressure and metabolic impairments related to insult severity. By contrast, cardiac contractility and cardiac output showed no significant temporal change. 
The application of innovative design of an electrocardiogram exam accessory device to improve ambulance prehospital electrocardiogram implantation rate in a city based multicenter trial W. 
The prehospital electrocardiogram (ECG) was identified as an critical part of treatment for patients with STEMI. However, it remained a challenging issue to set up prehospital ECG in Asia.
This study is to investigate the application of innovative design of an electrocardiogram exam accessory device to improve ambulance prehospital ambulance electrocardiogram implantation rate via in a city based multicenter trail. 
This study started since Sep, 2011 via a multidisciplinary team among Kaohsiung veterans General hospital, fire bureau and department of health, Kaohsiung city government. The unique accessory device for 12 lead electrocardiography apparatus has 10 holes, which are arranged according to a standard electrode placement for the 12 lead ECG measurements. The design of inter-nipple line and mid-sternum line on the device can assist the staffs to perform ECG shortly. This breakthrough innovation designed to address the core issue of the efficiency of the ambulance pre-hospital ECG system. Therefore, the invention successfully promoted Kaohsiung city council to set up Asian first ambulance prehospital telemetry electrocardiogram system. The innovative design of a ECG exam accessory device was patented in Taiwan and won golden award in Geneva and Korean international invention. The consecutative chest pain patients received ambulance ECG exam were enrolled from Jan. 2011 to September. 2015 in 18 different fire brigades at Kaohsiung city. The ECG implementation rate is defined as chest pain patients received ambulance ECG exam divided by all patients with chest pain.
The ECG implementation rate increased from 0 % in preinterventional to 62.2 % in post-interventional group (p < 0.001). Total 66 patients with STEMI was detected in 1205 chest pain patients received ambulance ECG exam. In these STEMI patients, average door to balloon time was 51 minutes, average ischemia to balloon time was 125 minutes and in-hospital mortality was 0 %.
This study demonstrates that application of innovative design of an electrocardiogram exam accessory device can solve the main problem of system and assist to set up first ambulance prehospital telemetry electrocardiogram system in Asia and further improve ambulance prehospital electrocardiogram implantation rate in Kaohsiung city.
To investigate the effect of increased ICU demand on the quality of care provided S. Grewal 1 , S. Gopal 1 , C. Corbett 2
The demand for critical care services is increasing steadily both nationally and internationally. It is important that with increasing demand the quality of care delivered is maintained. A well-recognised quality marker for intensive care units(ICU) are readmissions within 48 hours of discharge [1] . ICU readmission is associated with significantly increased morbidity, mortality, prolonged hospital admissions and increased cost [2, 3] . The reported average of unplanned readmissions is 1.4 % in the UK [4] . Globally this varies between 1.3-13.7 % [2] . There have been no specific causal factors found [2] . Objectives Identify the 48 hour readmission rate over two consecutive years and its impact on patient care.
This was a retrospective study in a 16 bedded adult general medicosurgical ICU in a large acute hospital in England. The sample was collated from the ICU discharges in 2014 and 2015, identifying those patients who were readmitted within 48 hours of discharge. Specific times of discharge and readmission, underlying cause, length of readmission stay and final outcome data was collected. The results of 2014 and 2015 were compared.
In 2014, 672 patients were discharged from ICU, with 21 readmissions and only 2 within 48 hours (0.3 %). The time of re-admission ranged from 14 to 48 hours. Following readmission, the length of stay ranged from 10 days to 17 days. In 2015, there were 702 discharges with 30 readmissions. 14 of these were within 48 hours (2.0 %). The time of readmission varied from 9 to 48 hours (median = 25 hours). Cardio-respiratory failure was the most common cause for readmission. The length of the readmission stay on ICU ranged from 1 day to 68 days (median = 8 days). Over the two year period the ICU mortality rate remained unchanged at 16 % however patients readmitted within 48 hours showed considerably higher hospital mortality rates of 50 % in 2014 and 42 % in 2015.
Over the two year period, there was an increase in admissions and discharges from ICU. This was associated with an increase in the midnight bed occupancy rate from 79.5 % in 2014 to 84.3 % in 2015. However, this was linked with a 7 fold rise in readmissions within 48 hours and an associated hospital mortality rate higher than both the previous year and national average. An increasing demand for ICU services can have an adverse effect on the quality of care delivered. Further research is needed to inform clinicians and commissioners how quality can be maintained with increasing demand.
There is growing evidence that a protective lung ventilation strategy offers benefits to all patients undergoing mechanical ventilation [1] . In addition, the deleterious effects of excess oxygen in critically ill patients are becoming increasingly well recognised [2] . We present the results of a 10-month-long quality improvement project that has improved adherence to a lung protective ventilation strategy on our unit. The project has also yielded a culture shift in the way that oxygen is prescribed and titrated for all our patients. Objectives 
Our project consisted of a series of tools to raise awareness, educational interventions, daily prompts and practical measures to promote adherence. In addition we adopted a pressure-control, volumeguarantee mode of ventilation as the initial standard for all patients ventilated on our unit. Our critical care technologists offered ongoing practice education for members of the clinical team whilst a run-chart of week-by-week performance offered immediate feedback on the status of the project.
We have reviewed over 4200 patient-days of data in a rolling audit of the effectiveness of our project. Fig. 88 demonstrates the percentage of patients for whom an IBW was recorded and for whom a target oxygen saturation was prescribed each month. Our latest results (April 2016) showed that 88 % (75/85) of patients on our unit had their IBW recorded and 100 % (14/14) of those receiving controlled ventilation had an appropriate tidal volume prescribed. Ventilation matched the prescription in 71 % (10/14) of cases. Routinely knowing the IBW of every patient on the unit has also been useful for the safe prescribing of haemofiltration and critical care drugs. 76 % (65/85) of patients had target oxygen saturations prescribed although only 38 % (25/65) were 'on target' at the time of data collection. Most importantly, prescribing an oxygen saturation target has empowered our nursing staff to wean inspired oxygen concentrations without waiting for an arterial blood gas.
Our project has demonstrated that a series of simple interventions can help to optimise mechanical ventilation and oxygen titration within critical care. There have been associated benefits in terms of safe prescribing and a reduction in our reliance on arterial blood gas analysis. 
This continuous quality improvement program shows that the systematic use of evidence based and PDCA-cycle driven process improvements may contribute to reduce VAP-rate.
Morbidity and mortality conferences (MMCs) are a traditional tool of improving local care management, and clinical management education especially in high risk specialty, but they lack a precise format for practice in intensive care units (ICU). 
Although confounding factors were not controlled, goal oriented MMC reduced some adverse event and probably mortality rate especially with continuous monitoring and improvement.
Intensive care is one of the most resource-intensive forms of medical care due to severely ill patients. During recent years the quality of intensive care has been in focus however there is still lacking result from nursing point of view.
To describe nurse/patient ratio in relation to Care burdened measurement (VTS) and optimal medical and nursing-related result usually used indicators as mortality and complications during intensive care.
This is a retrospective registry study includes a survey of critical care of registry data (all patients > 15 years) receiving care in two general Level I critical care units with similar rate of admissions during 2010-2014. Data of nurse/patient ratio is collected from each unit. The data is analyzed by descriptive and comparative statistical Method
The result showed differences in specialized nurse/patient ratio of 0,5:1 to 1:1 ratio and Care burdened measurement (VTS) despite similarities in admission rate. Differences in cause of admission (surgicalv.s medical) and in the amount of unexpected surgery patients were found. Differences were also found in mean time on noninvasive ventilation and mean time on ventilator. Complications during critical care was measured by readmission and unplanned reintubation and showed that unplanned reintubation varied between 2.4-1.6 percent. ICU mortality showed differences with the lowest ICU mortality in the hospital with lower nurse/patient ratio. However, 30 days mortality was lower in the hospital with higher nurse/patient ratio. Further analysis is needed.
Preliminary results show differences in nurse/patient ratios and Care burdened measurement (VTS) with differences in and quality measurements in general critical care units. 
The use of quality indicators (QIs) for improvement of care in the intensive care unit (ICU) is increasing. Incidence of adverse events like ventilator associated pneumonia (VAP) and pressure ulcers are not routinely measured in norwegian ICUs.
The aim of this pilot study was to evaluate the frequency of these two adverse events measured by specific QIs in two ICUs at the Oslo University Hospital Ullevål (OUHU Care that takes the needs of families into account is very important, but in order to offer family-centered care, it is necessary to understand families experiences.
To develop a valid and reliable tool to measure the perceived quality of care, the quality of the process of death and the satisfaction generated from the perspective of relatives of deceased patients in an ICU.
Elaboration of an ad hoc questionnaire after literature review and validated by a multidisciplinary panel of experts. The construct of quality of service (QS) was measured by using three different constructs: quality of the communication (QS1), with two dimensions ("kindness and respect" and "sincerity and empathy"); quality of the information (QS2), with four dimensions ("welcome", "information about disease", "shared decission making" and "empathy with family needs"); technical and infraestructural quality (QS3), with six dimensions ("human aproach, "professionalism", "waiting room", "facilities", "visiting hours" and "meals"). The construct about the process of death was measured by using three dimensions ("technical quality", "human quality" and "quality of the information given". Finally, the construct about overall satisfaction with the service was measured with three dimensions about satisfaction with "form and content of the information", "technical and structural quality", and "process of death". 95 relatives of deceased patients participated with a post mail questionnaire (response rate: 38,9 %). After a month since the death, recruitment by telephone was carried out. Analysis of psychometric properties: convergent validity with correlation coefficient of Pearson, predictive validity with multiple regression models in order to predict the dimensions of satisfaction from the scales of quality, and reliability with α Cronbach and test of two halves.
Nearly all of the correlation coefficients between the items of each construct were > 0,5, which meant, therefore, that all constructs had convergent validity. The three regression models performed to evaluate the predictive validity showed high determination coefficients (78,2 %. 94,9 % and 75,4 %). The evaluation of the items of all dimensions were high, with mean values around 6, except dimensions "empathy with family needs" and "waiting room", with scores < 5.
The ad hoc tool developed was easy to use and showed adequate psychometric properties of validity and reliability which could be improved by removing some items that showed low correlations.
Reducing antibiotic resistance -watch out for protocols! T. Objectives
The purpose of this study was to evaluate the profile of antibiotic resistance and the effect of the Introduction of an antibiotic protocol in the ICU length of stay and mortality, costs and consumption of antibiotics.
We conducted a retrospective study from a total of 476 patients admitted with in the ICU between January 2015 and December 2015.
For the purpose of this study, and to obtain a profile of the microorganisms in our ICU, resistant microorganisms (RM) were defined as those with non-susceptibility to one (RM1) or more than one class of antibiotics (RM2).We also compared our results whit previous studies conducted in the ICU.
Most prevalent microorganisms were: Staphylococcus aureus, Escherichia coli, Pseudomonas aeruginosa and Klebsiella pneumonia, 33 % of all microorganisms identified were resistant to more than one class of antibiotics (RM2) and 17 % of the patients had a RM1.Resistance was statistically significantly (p < 0,05) associated with:Previous stay in wards -in particular patients coming from surgical wards or Emergency;Number of days from admission in hospital to ICU admission -patients with RM2 had a mean hospital stay before ICU admission of 12 days;Number of previous surgeries in the same hospital event -RM2 were identified in patients with an average of two previous surgeries;Admission type -mainly patients coming from urgent surgery and medical causes;Number of days in ICU -patients with RM2 stay in average at least 5 days more in ICU than patients with microorganisms with no resistance;Antibiotic treatment previous to ICU admission (for at least 5 days before ICU admission), more than 30 % of patients with RM2 were submitted to antibiotic treatment before ICU admission.After the implementation of the antibiotic protocols we verified that the ICU length of stay was reduced in almost 3 days; the number of agents isolated increased 33 %; microbiological analyses increased 53 % which allowed us the practice of de-escalation consumption of antibiotics, by category, decreased by 82 % for the carbapenems, 33 % for antifungals and 35 % for antipseudomonal beta-lactams.There was a significant decrease in mortality, from 31,8 % to 26,8 %;There was a 22 % reduction in antibiotics consumption, with a total saving of 65,862€ in one year.
Resistance was associated with previous stay in wards, previous surgery and antibiotic treatment previous to surgery. The implementation of antibiotic protocols has had a positive impact as it was significantly associated with reduction on the length of ICU stay and ICU mortality, as well as consumption and costs associated with antibiotic therapy 
The low response rate and the potential for response bias due to the most dissatisfied relatives declining to respond limit this study. Its strengths are that it provides individualised feedback which can be used to enhance quality of care locally. Future quality improvement projects will target improving communication and include disseminating a study summary to staff members to highlight the importance of communication, more information in the waiting room on expectations in the intensive care unit and the use of family ward rounds. 
Critical illness of different etiology triggers an inflammatory cascade associated with organ dysfunction. However it is not known if the inflammatory pattern is disease specific or related to the severity of injury. We hypothesized that in critical ill patients of different etiology a specific pattern of cytokines measured in the early phase after ICU admission may predict mortality. Objectives Aim of this study was to investigate the early inflammatory profile in critical ill patients and its association with ICU mortality.
Local Ethic Committee approved the study protocol. Critical ill patients admitted to ICU for sepsis-associated acute respiratory distress syndrome (ARDS), severe traumatic brain injury (TBI) and subarachnoid hemorrhage (SAH) were studied. Demographic data, severity indexes at admission and physiological variables were recorded. Blood samples for cytokines analysis were collected at days 1, 2 and 4 after admission. The cytokine analysis was performed with Bioplex technology and 27 cytokines were analysed. Statistical analysis: Multivariate projection technique was applied to analyse variation and collinearity within the cytokines dataset without a priori selecting potential relevant molecules. Principal component analysis (PCA) was used to identify principal components (PC) which account for the majority of the variation within the dataset.
Eighty-six critical ill patients admitted for sepsis-associated ARDS (n = 36), severe TBI (n = 29), SAH (n = 21) were studied. 
Primary graft dysfunction is a significant cause of lung transplant morbidity and mortality, but its underlying mechanisms are not completely understood.
Objectives Aims of the study: 1) to confirm that right ventricular function is a risk factor for severe primary graft dysfunction; 2) to propose a clinical model for predicting the development of severe primary graft dysfunction. Method A prospective cohort study was performed over 14 months. The primary outcome was development of primary graft dysfunction grade 3. An echocardiogram was performed immediately before transplantation, measuring conventional and speckle-tracking parameters. Pulmonary artery catheter data were also measured. A classification and a regression tree were made to identify prognostic models for the development of severe graft dysfunction.
Seventy lung transplant recipients were included. Patients who developed severe primary graft dysfunction had better right ventricular function, as estimated by cardiac index (3.5 ± 0.8 vs. 2.6 ± 0.7 l/min*m 2 ; p < 0.01) and basal longitudinal strain (-25.7 ± 7.3 vs. -19.5 ± 6.6 %; p < 0.01). Regression tree analysis provided an algorithm based on the combined use of three variables (Basal longitudinal strain, pulmonary fibrosis disease and ischemia time), allowing accurate preoperative discrimination of three distinct subgroups with low (11 to 20 %), intermediate (54 %) and high (75 %) risk of severe primary graft dysfunction (AUROC 0.81).
Better right ventricular function is a risk factor for the development of severe primary graft dysfunction. Preoperative estimation of right ventricular function could allow early identification of recipients at increased risk, who would benefit the most from careful perioperative management in order to limit pulmonary overflow.
Pulmonary alveolar proteinosis (PAP) is a rare disorder characterized by a perturbation in surfactant homeostasis, resulting in its accumulation within alveolar spaces, with a consequent development of severe hypoxemia. Whole lung lavage (WLL) is a complex procedure, dedicated to those patients affected by a severe condition not responsive to medical treatment [1] .
To analyze the evolution of gas exchanges during WLL, evaluating PaO 2 variations during the different phases of the procedure.
We We collected data regarding patient gas exchanges by performing several blood gas analysis during the different steps of WLL. We expressed data as mean ± standard deviation (SD).
Results Figure 95 shows the mean values of PaO 2 during the different phases of WLL. During bipulmonary ventilation gas exchanges improved in response to FiO 2 1 and PEEP. Monopulmonary ventilation, instead, induced a clear reduction of PaO 2 , which increased in lateral position and during liquid tidal ventilation, with a substantial effect of elevated hydrostatic lavage pressures. The wide SD indicates an uneven response of gas exchanges in the studied population.
The pathophysiology of PAP is characterized by altered alveolocapillary diffusion and intrapulmonary shunt, thus significantly responsive to FiO 2 and PEEP, respectively. During monopulmonary ventilation, shunt is reduced by the lateral position, which provides a better perfusion of the ventilated lung, and the elevated hydrostatic lavage pressures, which are able to limit perfusion in the contralateral lung under WLL. were of Category C, who were admitted to ICU directly. 71.6 % (n = 58) were managed with non invasive ventilatory support only, and 14.6 % (n = 12) were intubated and mechanically ventilated. 10 out of 12 patients requiring intubation and mechanical ventilation belonged to Category C. 75 % (n = 9) of intubated patients had refractory hypoxemia (mean PaO2/FIO2 ratio 61.33 ± 4.05), and 6 patients required early prone ventilation. 8.5 % (n = 7) patients died and all of them were mechanically ventilated. 89 % (n = 73) were successfully discharged from the hospital. Mean ICU and hospital LOS was 3.83 ± 4.06 days and 7.53 ± 4.2 days respectively. Higher mortality rates was also seen in those patients who had more than 3 days of time lag for initiation of oseltamivir after the symptom onset (n = 5).
Conclusions Influenza A H1N1 pneumonia is a significant burden during epidemics associated with a high morbidity. The mortality among severe refractory ARDS patients who were invasively ventilated is very high.
Severe community-acquired pneumonia patients bear the highest morbidity, in-hospital mortality, and cost of all patients with community acquired pneumonia [1] . The appropriate management of these patients has received close attention in the current era of rising health care costs. Nevertheless, the outcome of these patients remains poor [2] and it is unknown which patient characteristics or treatment modalities are associated with a better outcome. By combining a national registry with a specifically designed questionnaire we were able to examine the factors related to organizational characteristics and treatment policies that might explain the variation in mortality outcomes in sCAP patients in the ICU.
This study used a dataset from a national registry containing data on patient and ICU level combined with a web-based survey on treatment policies. The relationship between in-hospital mortality and determinants was analyzed using multivariable logistic regression analysis. Conclusions CAP is a disease with a high in-hospital mortality. We have shown that, after correction for confounding factors some treatment and organizational factors are related with outcome in patients with sCAP. The need for mechanical ventilation remained an independent risk factor for mortality, and liberal use of tracheostomies for the weaning process was also associated with higher mortality. The mean number of ICU admissions with sCAP per year was inversely correlated with hospital mortality. Many other parameters that are often claimed to be associated with better or worse outcome (like differences in antibiotic therapy) did not correlate with outcome. Background and objectives Severe asthmatic patient who requires the use of invasive mechanical ventilation in an intensive care unit is, despite its low incidence, a potentially very serious case, which requires early and very specific respiratory care. This care will largely determine the average ICU stay, occurrence of secondary injuries or even death. Our objective is to describe the characteristics of severe asthmatic patient admitted to ICU and to analyze the initial treatment.
Descriptive study of patients admitted to the ICU of the Clinical Hospital Virgin of Arrixaca in the period between January 2011 and September 2015. We analyzed different variables, age, sex, APACHE II, SAPS II, parameters of mechanical ventilation, ICU stay and laboratory parameters. Results 18 patients (6 women) admitted to the ICU with a diagnosis of severe asthma. The average age was 35.06. The average stay in the ICU was 14.39 ± 25.55 days, with 16.89 ± 6.67 APACHE II and SAPS II 33.72 ± 13.45 points. Eight patients needed non invasive mechanical ventilation (44.4 %) with a failure rate of 50 % (4 patients). The use of invasive mechanical ventilation was required in 10 patients, 3 of them needed tracheostomy for prolonged mechanical ventilation and sevoflurane Anaconda® device was used in 2 of them. Data respirator parameters were collected during the first 48 hours, highlighting VT (ml / kg) 6.46 ± 1.23, 2.25 ± 2.26 initial PEEP, Ppeak 37.0 ± 13.32 and 12.57 ± 4.68 AutoPEEP cm H2O. The average pH at admission was 7.21 ± 0.14 with a range of [6.99 to 7.40], PCO2 of 64.5 ± 24.22 mm Hg and a lactate concentration of 2.91 ± 2.11 mMol/L. All patients were administered inhaled beta-agonists (two patients salbutamol endovenous) and corticosteroids. 5 patients required magnesium sulfate, 11 patients required sedation; 6 of these patients required relaxation with atracurium or cisatracurium. One patient presented barotrauma while using noninvasive mechanical ventilation prior to endotracheal intubation.
The clinical profile of patients admitted to the ICU with severe/status asthmaticus is a young male, with requirements of invasive mechanical ventilation after the failure in using medical gases such as helium and noninvasive mechanical ventilation. The strategy of ventilation is protective with permissive hypercapnia. Introduction Viral influenza, especially influenza A (H1N1) pandemic influenza, is associated with a significant increase in morbidity and Intensive Care Unit (ICU) admissions.
The aim of this study is to characterise the burden of illness and secondary infection among critically unwell patients admitted to our ICU this year.
A retrospective, observational, cohort study of critically ill adult patients with influenza admitted to a Level 3 ICU Dublin, between Decemeber 2015 and March 2016. IntelliVue Clinical Information Portfolio (ICIP) was used to obtain data.
Critical illness occurred in twenty patients with confirmed influenza; 12 A(H1N1) (60 %), 1 A(H3N2) (5 %), 4 A(non-subtyped) (20 %) and 3 B (15 %). The median age was 50 years (42.5-66.5); 14 patients (70 %) were under 65; 11 (55 %) were male. Thirteen (65 %) had comorbidities, including respiratory disease 5 (25 %), morbid obesity 3 (15 %) and malignancy or immunosuppression 3 (15 %). One was pregnant (5 %) and 8 (40 %) had a smoking history. Nine (45 %) were retrieved from outside the Ireland East Hospital Group. The mean APACHE (Acute Physiology and Chronic Health Evaluation) II Score and the mean SOFA (Sequential Organ Failure Assessment) score, on day one, were 17.85 ± 5.78 and 9.85 ± 3.33 respectively. Twenty (100 %) were mechanically ventilated, for a median of 17.5 days (9.5-32). Eighteen (90 %) satisfied the criteria for Acute Respiratory Distress Syndrome, with a mean PaO2/FIO2 ratio on day one of 13.35 ± 6.46. Fifteen (83.3 %) required rescue therapies for severe hypoxaemia, including extracorporeal life support (ECLS) in five (25 %), prone ventilation and inhaled nitric oxide. Sixteen (80 %) received vasopressors, and 12 (60 %) required renal replacement therapy. The median ICU length of stay was 18.5 days (11-42) and as of 31st March 2016, three (15 %) had died. Four (20 %) had documented early secondary infection, at less than 48 hours; streptococcus pneumoniae was the sole isolate (100 %). Seven (35 %) were treated for presumed late (greater than 48 hours) secondary infection; aspergillus fumigatus (28.6 %) and pansensitive staphylococcus aureus (42.9 %) were the most prevalent. All patients received a neuraminidase inhibitor: oseltamivir was prescribed in 19 (95 %), for a median of 7 days (7-9.75), with 3 (20 %) patients receiving the higher, 150 mg twice daily, dosing regime. Conclusion Seasonal influenza is a major public health concern. It is associated with severe morbidity, resulting in significant economic consequences, as well as a substantial burden on tertiary ICUs. In keeping with national trends, the predominant circulating virus was influenza A(H1N1) and secondary coinfection was common. Although traditional teaching emphasises S.aureus as a common coinfection in viral illness, our results highlight the importance of considering a broad spectrum of bacterial, viral and fungal microorganisms when prescribing empirically in the critically ill patient.
About 10-16 % patients are reintubated after planned endotracheal intubation for 48-72 hours. Reintubation will increase the risk of pneumonia, ventilator and ICU days, and resulting in 25-50 % mortality. Many studies had explored the risk factors of failed extubation, but the integrated indexes for successfully planned endotracheal extubation are inadequate. Objectives To establish useful predictors for successfully-planned extubation which can be followed by medical personnel.
The patients admitted to the adult ICUs of a tertiary hospital in southern Taiwan, who met the criteria of intubated over 48 hours and prepared for extubation were collected retrospectively between January 2005 to December 2015. Patient's characteristics, disease severity, rapid shallow breath index (RSBI), maximal inspiratory pressure 
High IAP predicts failure of SBT and need for re-intubation within 48 hours.
The use of life support in intensive care units (ICUs) is common and associated with a high risk of poor outcome. However, the prognostic importance of the duration of life support is less studied.
We aimed to assess the use of life support and the association between its duration and 90-day mortality in adult ICU patients.
We performed a post-hoc analysis of the SUP-ICU 7-day inception cohort study (1) conducted from Dec 2013 till April 2014 in 97 ICUs in 11 countries. From this cohort (n = 1034), we included adult general ICU patients with an ICU stay of ≥3 days. We assessed the use of life support day 1-3 in the ICU and the crude and adjusted association between its duration and 90-day mortality using logistic regression analysis.
We included 690 patients with a 90-day mortality rate of 23 %. During the first 3 days in ICU, 65 % of the patients received respiratory support, 57 % circulatory support and 13 % renal replacement therapy (RRT (Fig. 96) .
The outcome of adult ICU patients was associated with both type and duration of life support. RRT seemed to be associated with worst outcome, potentially because kidney failure often occurs concomitantly to respiratory and circulatory failure.
Effective lung volume (ELV) can be calculated continuously using a capnodynamic equation, and correlates well with functional residual capacity (FRC) in healthy lungs in a porcine model [1] . Hypercapnia is common in the ICU during lung protective mechanical ventilation, and may affect the capnodynamic method.
The aim of this study was to evaluate ELV during induced hypercapnia in pigs, and to confirm its stability during hemodynamic challenges. Method A cyclic sequence altering breaths with expiratory holds with normal breaths induces periodic changes in alveolar concentration of carbon dioxide. By integrating these variations into the capnodynamic equation ELV can be calculated. Hypercapnia was induced by increasing instrumental dead space in eight anaesthetized, relaxed and mechanically ventilated pigs. FRC was measured with a Sulfur-hexafluoride wash out technique. Cardiac output (CO) was measured using an ultrasonic flow probe placed around the pulmonary artery trunk. Hemodynamic measurements and blood gas analysis were obtained during normocapnia and during hypercapnia at baseline, preload reduction (cava balloon inflation) and dobutamine stimulation.
Carbon dioxide levels raised from (mean (SD)) 5.6 kPa (0.40) to 9.2 kPa (0.47) during hypercapnia. The bias (limits of agreement, LoA) for ELV at normocapnia was 303 (131 to 476) ml, and percentage error (PE) was 31 %. During hypercapnia, bias (LoA) decreased to -75 (-188 to 39) ml, and PE to 20 %. The hemodynamic interventions resulted in significant changes in CO, i.e. a decrease by 41 % (caval occlusion) followed by a 59 % increase (dobutamine inf.). ELV and FRC remained stable throughout these changes (Fig. 97) .
Conclusions ELV showed good performance during hypercapnia. The Method shows good stability during severe changes in cardiac output. This indicates that it would be interesting to further evaluate if the Method could be suitable for monitoring lung function in the ICU for instance during protective lung ventilation with permissive hypercapnia or in septic patient with hyper dynamic hemodynamics.
In ARDS, independent of severity, lung protective strategy implies a high-PEEP ventilation setting to prevent end-expiratory collapse and to prevent cyclic alveolar opening and closing. 
Chronic obstructive pulmonary disease (COPD) is a common preventable and treatable disease. Low level laser (LLL) therapy appears to be a promising noninvasive modality in COPD management.
Study the short-term effects of LLL therapy on clinical and cardiac status in stable COPD patients.
After exclusion of patients with Impaired left ventricular systolic function, atrial fibrillation, pulmonary hypertension due to causes other than COPD, and those who had any contraindication to exercise test, thirty stable COPD patients were divided into laser and control groups (15 pts each). Medical treatment was optimized in each group with the addition of LLL in the laser group. In addition to history and physical examination, MMRC scale, 6 MWT, echocardiography with measurements of RV dimensions, TAPSE, and lateral tricuspid annulus tissue Doppler velocities were assessed in each patient before and after LLL. The LLL was done using the following parameters: Wave length: 905 nm, Output 5-20 mw & Frequency 500 HZ. Laser probe was placed on intercostal space corresponding to the site of lesion both anteriorly and posteriorly on chest wall and arm with standardized laser acupuncture points of application with a frequency of 5 sessions/week for 2 successive weeks. 
Timing of extubation is of clinical importance as extended periods of intubation and premature extubation resulting in reintubation are both associated with negative patient outcomes [1] . Adult intensive care unit (AICU) extubation failure rates of 10-20 % have been reported [2] . Within a large, UK teaching hospital it was identified that extubation assessment was a multidisciplinary decision but different clinicians applied varying criteria and assessment was not standardised. Following a review of extubation failure rates, a quality improvement initiative was instigated including the development of local ventilator weaning guidelines and physiotherapy (PT) led assessment of extubation suitability.
The aims of this evaluation were to describe the PT assessment of extubation suitability in the AICU and to report extubation failure rates.
All patients under consideration for extubation by the AICU physicians, who underwent a PT assessment of extubation were included. This assessment was documented within the patient's electronic casenotes. Data was collected by retrospective casenote review during a 3 week period in August 2015. The project was registered as a service evaluation and therefore ethics requirements were waived. Demographics, details of the PT assessment ,and outcomes following extubation were collected (Table 72) . Extubation failure was defined as reintubation up to one week following extubation. 
Data was collected from 45 PT assessments. These assessments most frequently included neurological status, Rapid Shallow Breathing index (RSBi), occlusion pressure during initial 100 ms of inspiration (P0.1), Negative Inspiratory Force (NIF), peak cough flow (PCF) and secretion load.
Range of values for the assessed parameters are shown below. When providing opinion regarding suitability for extubation, PTs gave more weight to neurological status, PCF and secretion load than other weaning parameters (see image below). They were more likely to recommend against extubation in the presence of low PCF, inappropriate neurology and large secretion load.
Physiotherapists frequently include neurological status, work of breathing, PCF, secretion load and NIF in their assessment for extubation. They predominantly use neurological status, cough strength and secretion load to inform recommendations regarding extubation. The extubation failure rate of 15 % is in keeping with current literature although the studied sample size was small.
Reclassification after 24 hours using PaO 2 /FiO 2 and PEEP thresholds improves the prognostication of patients with moderate/severe ARDS [1, 2] but it is uncertain if this also holds true for patients with mild ARDS.
The aim of this investigation was to determine if reclassification after 24 hours using PaO2/FiO2 and PEEP thresholds improves prognostication of mortality in a cohort of prospectively identified patients with mild ARDS in two intensive care units in the Netherlands.
Patients with mild ARDS, according to the Berlin definition [3] , were categorized into 4 groups based on measurements obtained at presentation of ARDS or 24 hours after: PaO2/FiO2 ≥ 250 mm Hg and PEEP = 5 cm H2O (group I); PaO2/FiO2 ≥ 250 mm Hg and PEEP > 5 cm H2O (group II); PaO2/FiO2 < 250 mm Hg and PEEP = 5 cm H2O (group III); PaO2/FiO2 < 250 mm Hg and PEEP > 5 cm H2O (group IV). Patients no longer receiving mechanical ventilation after 24 hours were classified as 'extubated' (group 0). No patients died within 24 hours. The primary outcome was all-cause in hospital mortality. Secondary outcomes were , ICU-and 90-day mortality and the number of ventilator-free days and alive at day 28.
Of 7,784 patients, 693 patients had ARDS of which 164 patients with mild ARDS and on invasive ventilation were included in the analysis. Table 75 shows outcomes per group at the moment mild ARDS was diagnosed, and after 24 hours. Reclassification after 24 hours showed an improved prognostication with regard to hospital mortality, ICU-and 90-day mortality and the number of ventilator-free days and alive at day 28.
Reclassification after 24 hours using two simple cutoffs improves prognostication in mild ARDS patients. 
Introduction In the Lung Injury Prevention Study with Budesonide and formoterol (LIPS-B), we studied feasibility of nebulized budesonide and formoterol to prevent or alleviate lung injury in patients at risk for ARDS. All available blood samples obtained prior to study drug and on hospital day 2 were analyzed for biomarkers associated with progression or severity of ARDS.
To determine if early administration of inhaled budesonide and formoterol modulates ARDS-associated plasma biomarkers.
Serum samples were analyzed in duplicates with Luminex Plate in a 1:2 dilution and per manufacturer´s directions. Analytes were IL-6, vWF-A2, IL-8, IL-10, RAGE, ICAM-1, and SP-D. We analyzed biomarker concentrations in specimens from the treatment versus placebo arms at baseline (before the study drug delivery) and day 2 (after at least one dose of the study drug). The observed concentrations that were above or below calibrated expected range were replaced with highest and lowest observed within the range concentration values, respectively. Subsequently, the values were log-transformed and differences between treatment arms were compared by type 3 folded F test.
Of 59 enrolled patients, 39 had samples available for baseline and day 2. The log-transformed values of IL-6, vWF-A2, IL-8, RAGE, and ICAM-1 decreased on day 2 with the observed decreases being greater in the treatment arm. However, the differences were not statistically significant: IL-6 p = 0.16, vWF-A2 p = 0.9, IL-8 p = 0.68, RAGE p = 0.27, ICAM-1 p = 0.1. Interestingly, IL-10 also decreased in the treatment arm while slightly increasing in the placebo arm, although differences were not significant (p = 0.28). The concentration of SP-D increased on day 2 in both arms with a non-significant greater increase in the placebo arm (p = 0.5). 
In the past 20 years, management of the acute respiratory distress syndrome (ARDS) has been revolutionised by the application of lower tidal volume, lung protective ventilation strategies. Whilst our understanding of ARDS management has improved, the worldwide incidence and outcomes are unclear, with several studies reporting highly variable regional incidence rates, and no studies characterising ARDS epidemiology in Asia.
The goal of this observation study was to determine the incidence, mortality and management practices of ARDS in a developed South East Asian country.
We conducted a prospective, population based observational study in 6 public hospitals. During a one month period from May to June 2015, we identified all patients admitted to any Singapore public hospital intensive care unit (ICU) who met ARDS criteria. Demographic information, clinical management data and ICU outcomes data were collected. Concurrently, a survey was conducted to determine ARDS management preferences of physicians at the study centres involved.
A total of 904 adult patients were admitted to the ICUs during the study period and 16 patients met ARDS criteria, using the Berlin definition. Based on this, the unadjusted incidence of ARDS in Singapore is 5.49 cases per 100,000 population and 1.76 % of all ICU patients. Most patients belonged to Medical ICUs (56 %), were male (75 %), Chinese (62 %) and had pneumonia (73 %). Management strategies varied across all ICUs. Our survey results showed that the majority of physicians thought that it was useful to study ARDS prevalence but that they believed overall mortality and prevalence was decreasing. Our 28 day in hospital mortality was 15 % and median length of stay was 7 ± 3 days.
The incidence of ARDS in a developed S.E Asia country is comparable to European reported rates. The proportion of ventilated patients developing ARDS is lower than international studies published in different regions. However, management strategies varied considerably. 
A trend towards improved mortality with less fluid was observed but not statistically significant. Higher than expected mortality could be explained by the exclusion criteria for the FACTT population in particular chronic lung disease. Further education of junior medical and nursing staff, a daily review of fluid balance has been emphasised and re-audit in 18 months to keep awareness high were recommended.
Old patients have become an increasingly prevalent proportion of the critically ill population. The outcomes of patients with acute respiratory distress syndrome (ARDS) were improving in recent years. However, limited information existed on the studies for elderly of ARDS patients.
To evaluate the factors associated with mortality of ARDS patients and investigate the relationship between age and mortality in ARDS patients.
We performed a prospective observational study in adult ICUs at the Chang Gung Memorial Hospital from October 2012 to May 2015. Patients were included if they met the Berlin definition of ARDS. Data collected included patients' demographic, severity of illness, management and clinical outcomes. All the studied patients were followed until discharged from the hospital.
During the study period, 22470 receiving invasive mechanical ventilation patients admitted to adult ICUs with PaO2/FiO2 < 300 mmHg were screened. Totally, 945 ARDS patients were included for analysis. The mean age and hospital mortality were 63.2 ± 16.1 years and 56.9 %. Of these 945 ARDS patients, 463 (49 %) patients were older than 65 years. By multivariate logistic regression analysis, factor associated with hospital mortality included body mass index (odds ratio 1.07, 95 % confidence interval 1.04-1.11; p < 0.001), Sequential Organ Failure Assessment score (odds ratio 0.88, 95 % confidence interval 0.81-0.95; p = 0.002), Lung Injury Score (odds ratio 0.68, 95 % confidence interval 0.46-1.00; p = 0.05) and PaO2/FiO2 (odds ration 0.995, 95 % confidence interval 0.991-1.00; p = 0.04). The hospital mortality in ARDS patients younger than 65 years was significantly lower than ARDS patients older than 65 years patients (50.2 % vs. 63.9 %, p < 0.001). For ARDS patients older than 65 years, we classified the patients as the young-old (65~74 years, n = 194, 41.9 %), middle-old (75~84 years, n = 189, 40.8 %) and old-old (≥85 years, n = 80, 17.3 %). The hospital mortality were not significantly different between these three group (63.9 % vs. 65.6 % vs.60 %, p = 0.682).
For ARDS patients, younger patients had lower mortality than older patients. For ARDS patients older than 65 years, the age did not influence the hospital mortality. Introduction ARDS is a life-threatening condition characterized by increased lung weight and loss of lung aeration. Recently, prone position as adjunct to lung protective ventilation demonstrated significant mortality reduction in ARDS patients [1] . Lung Ultrasound (LUS) has emerged as a powerful diagnostic tool that could help in diagnosis and guide management at the bedside. Performance of serial CT scans, the gold standard for lung recruitment assessment, can be challenging and not feasible outside research protocols.
We hypothesized that, in ARDS patients, LUS could detect changes in regional inflation during prone position compared to supine position and over time. We also hypothesized that such changes correlate with commonly monitored parameters of aeration, oxygenation and ventilation, as measured by arterial blood gas analysis and respiratory mechanics. Finally, we hypothesized that specific LUS aeration patterns, identified immediately before and after prone position initiation, are predictive of clinical response to this adjunctive treatment.
In this observational prospective study on ARDS patients, we performed LUS on the first day of prone position treatment at different time points: before (supine -S0), immediately after (P0) and 1 hour after (P1) initiation of prone position, immediately before (Pfin) and after returning the patient supine (Sfin). For the LUS protocol, we used a 2-4 MHz curvilinear transducer and we divided each hemithorax in 2 anterior, 2 lateral and 3 posterior zones. The worst LUS pattern detected in each zone was considered as characterizing the examined region. Off-line image review by two independent physicians, unaware of timing, position and patient's characteristics, was used to calculate a modified LUS aeration score, as previously described [2] . Spearman's rank correlation coefficient was used to correlate changes in LUS score (V-LUSS) with changes in compliance and PaO2/FiO2 (P/F).
We enrolled 13 ARDS patients, admitted to the Padova University Hospital ICU [median age 58 years (IQR 53-61); median SAPSII 45.5 (IQR 33-52)]. V-LUSS between P0 and P1 correlated with changes in compliance (r = 0.690; p < 0.05) and P/F (r = 0.70; p < 0.02) between S0 and Sfin. V-LUSS P0-Pfin also correlated with changes in P/F (r = 0.61; p < 0.05) and compliance (r = 0.60; p < 0.05) between S0 and SFin.
Conclusions LUS is feasible in ARDS patients in prone position and V-LUSS correlates with changes in compliance and P/F. Moreover, the V-LUSS at 1 hour after initiation of prone position may predict the change in compliance and P/F at the end of a pronation cycle, after returning the patient in supine position.
Influenza A (H1N1) pneumonia could cause severe hypoxemia and need mechanical ventilation support. The incidence of development to ARDS and the related mortality rate in H1N1 pneumonia with respiratory failure were not clear.
Our purpose is to analyze the outcome of patients with ARDS caused by influenza A (H1N1) in intensive care unit (ICU) requiring mechanical ventilation.
This was a retrospective study including adult patients with ARDS due to confirmed influenza A(H1N1) pneumonia needed mechanical ventilation in a medical center between July 2009 and May 2014 in Chang Gung Memorial Hospital in Taiwan. We investigated the patients' characteristics, clinical presentation, severity of illness and outcomes.
There were 199 influenza-infected patients hospitalized in ICU during the study period. Seventy-three patients were confirmed influenza A (H1N1), and 54 (82 %) patients developed to ARDS, including 36 (67 %) with severe ARDS and 14 (26 %) with moderate ARDS by Berlin definition. Compared with non-ARDS influenza A (H1N1) patients, age was younger (50 ± 14 vs. 62 ± 16 years, p = 0.016) and body mass index (BMI) was higher (26.7 ± 4.7 vs. 23.7 ± 4.0 kg/m 2 , p = 0.045) in ARDS patients. The duration of oseltamivir therapy in ARDS patients was longer (7.2 ± 2.6 vs. 4.9 ± 0.7 days, p = 0.010) than no ARDS patients. Despite significantly prolonged mechanical ventilation support (20.7 ± 18.5 vs. 9.6 ± 9.8 days, p = 0.013) and intensive care unit stay (21.7 ± 16.0 vs. 8.7 ± 8.2 days, p = 0.003) in ARDS patients, there were no significant difference in the mortality rate of ICU (18.5 % vs. 33.3 %, p = 0.256) and hospital (37 % vs. 33.3 %, p = 0.809) between ARDS and non-ARDS patients.
For patients with influenza A (H1N1) pneumonia complicated respiratory failure, high incidence developed to severe ARDS but not correspond to high mortality rate.
In the last years, there has been an enormous research effort into the knowledge of physiopathology of acute respiratory distress syndrome (ARDS) which, together with the advances in critical care, has led to a reduction in mortality. With declining fatality rates, the interest of researchers has shifted from mortality statistics to other outcome parameters such as health-related quality of life (HRQL) after ARDS.
The aim of our study was to investigate HRQL in long-term survivors (longer than 2 years) after ARDS, all of them ventilated with the lowtidal volume protocol. Method A total of 54 patients more than 2-year survival after an ADRS episode were identified between June 2008 and May 2009. 8 patients were excluded because of pulmonary o cardiovascular previous disease. 15 patients refused to participate. Finally, 31 previously healthy patients participated in this study. The medical records were searched for demographic data, smoke status, ventilator data, length of ICU and hospital stays and measures of severity of illness such APACHEII, LIS and SOFA. HRQL was evaluated using the St George's Respiratory Questionnaire (SGRQ). SGRQ is a self-administered questionnaire that measures perceived quality of life and impairments in health due to respiratory disease. It contains 76 items in three domains (symptoms, activity, and impacts on daily life) and a summary or total score. Scores range from 0 (good health) to 100 (poor health). The questionnaire has been validated in a Spanish population.
The results of the demographic and clinical variables are shown in Table 76 .
Regarding the evaluation of HRQL by SGRQ, the mean scores were slightly higher in all domains with regard to the reference values from Spanish population by age and sex, indicating subjective respiratory problems with an impact on daily life. Only 7 of our 31 patients (22.6 %) had scores normal in all domains and in the total scores. 18 patients (58.1 %) had higher scores in all domains. The other 6 patients (19.3 %) had a higher score in some of the domains. Table 77 Conclusions · ARDS has a negative impact on the quality of life of survivors detectable even beyond two years after the acute episode. · Domains of activity and symptoms are the most affected in patients who survive ADRS.
Appropriated level of positive end expiratory pressure (PEEP) can improve oxygenation and avoid ventilator induced lung injury. Many Method for setting PEEP have been proposed, but they are longstanding and difficult to perform in clinical practice, or based in oxygenation table, ignoring individual mechanical characteristics. We propose a Method to titrate PEEP at bedside, that considers regional respiratory mechanical differences, in a fast and practical way.
Compare agreement between a PEEP titration Method performed fast (about 7 minutes) and slow (about 45 minutes). 
Eleven mechanically ventilated patients after elective cardiac surgery with moderated ARDS according to the Berlin criteria, but using a P/F ≤ 250 mmHg, received descending PEEP titration in steps of 2cmH 2 O from 23 to 5cmH 2 O performed in two randomly ways. One of them was performed with steps of 40 seconds (total time less than 7 minutes), and the other, in steps of 4 minutes (total time of 45 minutes). Each PEEP trials were preceded by standard (or maximal) alveolar recruitment manouver. PEEP trials were performed with PEEP titration tool available in Electrical Impedance Tomography (EIT) device (ENLIGHT 1800, TIMPEL). This tool [1] provides a report with a functional map ventilation, demonstrating the amount of collapsed and hyperdistension tissue for each step of PEEP. The minor PEEP with less than 5 % of collapse was chosen as the optimal PEEP. This is part of a translational research, in the experimental setting, 3 pigs with establish lung injury received a descendent PEEP titration using EIT monitoring and dynamic Computed Tomography (CT). The CT was performed to evaluate the correlation of collapsed tissue amount in each step of PEEP between CT and EIT.
There were no differences in optimal PEEP titrated with fast and slow titration Method (13,20 ± 3,58cmH 2 O versus 13,40 ± 3,37cmH 2 O, p =0,727). The mean difference between two Method was 0,20 ± 1,75cmH 2 O with limits of agreement of -3,23 to 3,63cmH 2 O. Analysing the amount of collapse during entire titration, there was no significant differences between the fast and the slow titration (p = 0,401), however there were differences between each PEEP steps (p < 0,001) and there was no interaction between the fast and the slow titration groups and PEEP steps (p = 0,997). There was a good correlation between collapsed tissue provided by the EIT and CT (R 2 = 0,97).
There is agreement between the fast and the slow titration Method and the PEEP titration can be performed easily in less than 7 minutes with EIT monitoring, at bedside.
Ventilation Induced Lung Injury (VILI) is associated with an increased mortality in ARDS [1] . Through mechanical stress and strain of the lung, VILI triggers an inflammatory response, which may be spatially characterized by imaging techniques such as Positron Emission Tomography combined with computed tomography (PET/CT). 11 C-PK11195 is a PET radiotracer with short half-life and potential to repeatedly quantify macrophage inflammation.
To evaluate 11 C-PK11195 lung uptake and its association with mechanical strain assessed with CT, as well as its relation with both macrophage lung recruitment and histologic injury.
Method VILI was performed in 5 anesthetized pigs by increasing the tidal volume (VT) to obtain a transpulmonary pressure (TPP) between 35 and 40 cmH 2 O under zero end-expiratory pressure. CT and PET acquisitions, were performed before (T1) and after 4 hours of high volume ventilation (T2), and measurements were performed globally on the whole lungs, and regionally by partitioning the lung in 4 regions defined by the cephalo-caudal and the antero-posterior planes. 11 C-PK11195 uptake was quantified using the Standardized Uptake Value (SUV), corrected for the fraction of tissue in each lung region (as assessed in CT). Regional strains (dynamic and static) were estimated by CT analysis. After euthanasia, a semi-quantitative lung injury score and macrophages recruitment were quantified in lung samples.
Between T1 and T2, VT and TPP increased from 6.0 ± 0.1 to 49.4 ± 2.9 ml/kg and from 9 ± 2 to 38 ± 4 cmH 2 O, respectively. Between T1 and T2, global 11 C-PK11195 SUV and global dynamic strain increased significantly from 1.83 ± 0.58 to 2.97 ± 0.53, and from 0.36 ± 0.03 to 2.06 ± 0.23, respectively, whereas static strain did not change significantly. Regional 11 C-PK11195 SUV significantly increased between T1 and T2, without significant inter-regional differences, while regional dynamic strain increased after VILI, with significant inter-regional differences between antero-caudal and postero-caudal regions. Regional static strain differed neither between T1 and T2, nor between regions. In multivariate analysis, regional dynamic strain was independently associated with regional SUV (p = 0.04). Histologic analysis showed greater alveolar damage in the caudal regions (p < 0.01). SUV was positively correlated with macrophages recruitment (p = 0.03).
Conclusions 11 C-PK11195 is a macrophage-specific PET radiotracer whose lung uptake is independently associated with dynamic strain and macrophage lung recruitment in a high-volume VILI model.
Experimental evidence suggest that ventilator induced lung injury (VILI) depends on the energy load applied to the respiratory system, which in healthy lungs encompasses tidal volume, respiratory rate and flow. [1] Objectives To investigate if putative mechanisms of VILI (lung strain [2] , lung inhomogeneities [3] , collapse and decollapse [4] ) are associated with an increased energy load per breath.
Patients underwent a CT scan at PEEP 5 cmH 2 O end-expiration and a second CT scan at end-inspiration. Airway and esophageal pressure were recorded during tidal ventilation. Energy load per breath (Joule) was defined as the area between the inspiratory limb of the deltatranspulmonary pressure (x-axis)-volume curve and the volume axis (y). Tidal strain was defined as tidal volume (ml)/gas volume at PEEP 5 cmH 2 O (ml); lung inhomogeneities were computed as previoulsy described [2] . Intratidal collapse and decollapse was defined as the difference in not inflated tissue between end-inspiration and endexpiration expressed as fraction of total lung weight. (J) was significantly related to lung strain (Fig. 101, upper panel) and inhomogeneity (Fig. 101, lower panel) ; the relationship between delivered energy and intratidal collapsedecollapse did not reach statististical significance (r 2 = 0.10, p = 0.11).
Greater lung strain and lung inhomogeneities increase the energy delivered to the respiratory system by the tidal volume.
Invasive mechanical ventilation (IMV) is frequently applied in critically ill elderly patients. Age, comprehensive geriatric assessment (CGA) parameters and recently frailty were reported as general prognostic factors in these patients [1, 2] . However, there aren't enough studies about the prognostic factors specifically in patients with IMV.
To investigate the clinical characteristics of elderly patients receiving IMV and to show the impact of age, CGA parameters and particularly frailty on weaning success and outcomes of these patients.
The patients, >50 years old, admitted to the medical and pulmonary intensive care units (ICU) in Gazi University Hospital were prospectively included. Patients without consent and stayed < 24 hours in the ICU were excluded. Frieds, Clinical and Edmonton frailty scores (FS) were calculated and CGA parameters were assessed by the geriatrician. The length and the result of weaning were recorded. The weaning was classified as simple, difficult and prolonged weaning.
IMV was applied in %49 of 180 patients. While the age had no impact on the need of IMV(p = 0.407), frailty defined by Edmonton FS was an independent factor for IMV; increasing the need approximately 3 times (p = 0.023). The presence and the degree of frailty according to all FSs and CGA parameters had no impact on weaning and mortality in patients with IMV(p > 0.05). In the whole study group, when the patients with and without fraility according to the Edmonton FS were compared, disease severity scores (APACHE and SOFA scores), duration of weaning were similar in both groups (p > 0.05), but the comorbidities in the ICU such as development of infection and septic shock, frequency of renal replacement therapy and and mortality were higher in the frail patients (p = 0.03, p = 0.04, p = 0.02 and p = < 0.01, respectively).
The presence of frailty in critically ill elderly patients increased the need for IMV. After initiation of IMV, frailty had no impact on weaning and mortality in these patients. On the other hand, as the need for IMV, comorbidities in the ICU and therefore overall mortality are found to be incresead with fraility.
Refractory hypoxemia is the leading cause of early mortality following lung transplantation (LT). Rescue therapies, such as extracorporeal membrane oxygenation, have been shown to be useful for supporting LT recipients with refractory hypoxemia. Prone position (PP) is a low cost measure that has been shown to improve gas interchange in patients with severe acute respiratory distress syndrome. Major thoracic surgery has been considered a contraindication for its implementation. Thus, to date there is no published evidence of the beneficial effects of PP as a bridge to recovery for patients with refractory hypoxemia after LT.
The primary objective was to assess the gas interchange improvement with PP. The secondary objective was to compare the outcomes of these patients with those of the general population of our LT recipients.
Prospectively collected data from 131 consecutive adult patients undergoing LT between January 2013 and December 2014 were evaluated. Indications, associated complications, time to initiation and duration of the maneuver were analyzed and the effects of PP on gas interchange were evaluated. Finally, outcomes in this cohort were compared against the rest of LT recipients. Continuous data are reported as median and interquartile range(IQR) and categorical data as numbers and percentages. Differences between categorical variables were assessed with the Chi-square test and continuous variables with the Mann-Whitney test. The Student "t" test was used to evaluate the effects of PP on gas interchange. Conclusions PP was found to be a safe and successful therapy for refractory hypoxemia after LT and should be considered as an option in treating these patients. Background Iron is an essential element for both proper immune function and for the growth of most human pathogens. Alterations in iron status may affect the immune system and the risk of infections. No populationbased studies have investigated the association between markers of iron status and the risk of bloodstream infection (BSI).
We assessed the associations of serum iron concentration (SI), total iron binding capacity (TIBC) and transferrin saturation percent (TS) with the risk of BSI and fatal BSI (death within 30 days after detection of a BSI).
We studied 64033 participants with baseline measurements of SI, TIBC and TS in the second survey of the population-based HUNT Study in Nord-Trøndelag County, Norway (HUNT2, 1995-97). SI, TIBC and TS were categorized as low (<2.5-percentile), high (>97.5 percentile) and quintiles of values between the 2.5 and 97.5 percentiles. Incident BSIs through 2011 were identified though linkage to prospectively recorded information at the local and regional hospitals. For each measure of iron status, we assessed the risk of a first-time BSI and fatal BSI using Cox proportional hazards regression, with the middle quintile as the reference. The primary analyses were adjusted for age and sex. Additionally, we adjusted for self-reported comorbid conditions; lung disease, cardiovascular disease, cancer, kidney failure, diabetes and body mass index at baseline.
During a median follow-up of 15 years, 1840 persons had at least one episode of BSI, and 396 experienced a fatal BSI. In age-and sexadjusted analyses, BSI risk was increased among participants with indices of iron deficiency, either low SI (HR 
In this large population-based cohort study, indices of low iron status were associated with increased risk of BSI. Iron is a crucial element in our immune response and these findings suggest that alterations in this fine tuned system could influence the risk of BSI.
The study was supported by a grant from the Liasion Committee between the Central Norway Regional Health Authority and the Norwegian University of Science and Technology. Introduction Bloodstream infection (BSI) causes considerable morbidity and mortality. As emerging antibiotic resistance seriously threatens global public health, primary prevention of bacterial infections should be a priority. Lifestyle factors are of particular interest since they are modifiable, and optimization could reduce the population-level burden of BSI.
To assess the associations of smoking, obesity, alcohol intake and physical inactivity with the risk of incident and fatal BSI.
In a prospective population-based cohort study, 65236 participants of the HUNT2 Survey (1995-97) in Norway were followed up through 2011 by linkage to prospectively recorded information on BSI at the local and regional hospitals. Using Cox regression, we estimated ageand sex-adjusted hazard ratios (HR) of a first-time BSI and fatal BSI (death within 30 days after BSI) by baseline body mass index (BMI) measurements and self-reported smoking habits, leisure time physical activity and alcohol intake. In additional analysis we also adjusted for education and lifestyle factors. Recent observational studies showed that obese critically-ill patients have an unexpectedly reduced risk of death, having low mortality rate in the course of septic shock, as well. This situation is described as "obesity paradox". Leptin, a hormone made by white adipose cells regulating energy balance by inhibiting hunger and which rises proportionally to body weight has also been shown to have a role in immune modulation. Therefore, leptin could play the pivot role in case of obesity paradox. The aim of this study was to investigate the relationship between mortality and body mass index (BMI) in patients with septic shock. In addition, we tested association of leptin levels with BMI and mortality.
Between September 2014 and January 2016, 52 patients with septic shock were included in the study. As a control group, 27 healthy people with BMI (kg/m 2 ) similar to patients' BMI values were included. Patients who had uncontrolled diabetes mellitus, malignancy and who received corticosteroids chronically prior to ICU admission were excluded. Patients were categorized into five groups according to BMI (group 1 (n = 6) ≤18; group 2 (n = 14) 18.1-24.9; group 3 (n = 19) 25-29.9; group 4 (n = 10) 30-39.9; grup 5 (n = 3) ≥40 kg/m 2 ). We measured leptin levels at 9:00 a.m. after patient has been diagnosed with septic shock.
The median (min-max) age of 52 patients was 68 (19-88). 25 of these patients were male. The median APACHE II score was 28. 
Our study showed that increased BMI was not related to increased survival. Leptin levels were lower in patients with septic shock compared to control patients. Although leptin levels correlated with BMI, there was no difference in leptin levels between surviving and nonsurviving patients.
ICU-acquired weakness is related to loss of muscle mass and function, especially in long-stayers. Both factors can be assessed at the bedside using independent techniques, but the correlation between mass and function is unknown Objectives To evaluate any correlation between muscle mass and force in longstay ICU patients.
Muscle mass and force were assessed on admission and at the end of the ICU stay in patients with an expected length of stay (LOS) of at least 5 days. Mass was measured from anthropometric variables (skinfolds of calf and arm) using the Lee formula (1) and bioelectric impedance (phase angle (PhA)) at 50 Hz. Force was measured using the Medical Research Council (MRC) score (2) and dynamometry (handgrip test). Effect of time over the ICU stay was assessed using a Student's t test. Correlations between mass and force, and between these variables and the APACHE II score, the duration of ICU stay and of mechanical ventilation were investigated.
Eighteen patients (age 56 ± 16 years, 12 male, APACHE II 20 ± 5) were included. During the ICU stay (17 ± 12 days), muscle mass assessed by skin folds and by PhA at 50 Hz decreased from 26.8 ± 5.4 kg to 25.6 ± 5.4 kg (p < 0.003) and from 4.0 ± 1.6 to 3.4 ± 1.4 (NS), respectively. Likewise, force evaluated with MRC score decreased from 52 ± 2 to 42 ± 5 (NS). There was a correlation between the percentage change in mass and in force (r =0.57, p < 0.01), between the percentage change in mass and length of ICU stay (r = -0.79; p < 0.0001) and between the durations of mechanical ventilation and ICU stay (r = 0.89; p < 0.0001). The APACHE II score was negatively correlated with force measured using the handgrip test (r = -0.67; p = 0.002), with the MRC score (r = -0.765; p < 0.0001) and with muscle mass evaluated by PhA (r = -0.665; p = 0.004).
Muscle mass and function decrease during a long ICU stay, and these changes are correlated. Use of these bedside Method to guide therapeutic management needs to be assessed.
The mortality of severe acute respiratory distress syndrome(ARDS) caused by pulmonary infection after renal transplantation is high. Prone position ventilation can effectively improve the prognosis of patients with ARDS. Post-pylorus feeding can significantly improve the nutritional intake and reduce the risk of aspiration.
To evaluate the value of prone position combined with post-pylorus feeding on severe ARDS caused by severe pneumonia after renal transplantation.
Prospective observational study in a surgical intensive care unit (10 beds) of a university hospital. Patients met the berlin criteria of severe ARDS after renal transplantation and needed invasive mechanically ventilation were included.12 consective hours of prone position ventilation and post-pylorus feeding tube placement were applied to all included patients Results
In total, 8 patients were included, average 38 ± 10 years, 6 (75 %) were men. The 28-day mortality was 12.5 %(1/8). The ratio of the partial pressure of arterial oxygen(Pao2) to the fraction of inspired oxygen (Fio2)on 1 h,6 h and 12 h after prone positon were improved significantly than before(P < 0.05). The time to reach target feeds was 73 ± 15 hours through Post-pyloric feeding, the rate of aspiration is 0, Nutritional status of all patiens was gradually improved.
Prone position combined with post-pylorus feeding can improve the prognosis of severe ARDS cuased by pulmonary infection after renal transplantation.
Nutritional support is an essential part of intensive care unit management However, the appropriate caloric intake for critically ill patients still remains unclear. Permissive underfeeding is based on the fact that provision of 100 % of estimated nutrient requirements may be metabolically and functionally detrimental to some patient populations. It has also been shown that meeting a patient's estimated needs may result in inflammation, cytokine release, and oxidant production while short term restriction of nutrient intake may limit the pathologic processes that occur in critical illness and reduce organ dysfunction.
To evaluate the effect of permissive underfeeding, as compared with standard protocol enteral feeding, on 28-day mortality among septic mechanically ventilated critically ill patients Method A single centre study of patients admitted to a 25 bed University Hospital ICU over a period of one year. Demographics, severity of illness scores (APACHE and SOFA), BMI and "Malnutrition Universal Screening Tool" (MUST) were measured upon admission. Daily nutrition requirements were calculated for each patient. Patients were randomly assigned to permissive underfeeding group with caloric goal: 50-70 % of the calculated requirement or standard protocol feeding groups with caloric goal: 80-100 % of calculated requirement. Each patient was monitored for 14 days. The protein intake (1.5 g/kg/day) was maintained the same in both groups. The primary outcome was 28-day mortality. Results are expressed as mean ± SD. P < 0.05 was considered significant.
A total of 74 patients (38 men) mechanically ventilated septic patients having a mean(±SD) age of 68.4 ± 18.4 years were studied. All patients met the consensus criteria for sepsis. Baseline characteristics were similar in the two groups. APACHE II and SOFA at study entry were 22 ± 4 and 8 ± 4respectively.The mean height of the patients was 164.0 cm. The mean(±SD) BMI was ≈ 21.5 ± 3.4 kg/m 2 . Obese patients were excluded from the study. During the study period, the permissive-underfeeding group received fewer calories than did the standard-protocol feeding group (962 ± 314 kcal per day vs. 1308 ± 513 kcal per day) achieving caloric requirements of 51 ± 14 % vs. 82 ± 11 %, respectively (P < 0.001). Protein intake was similar in both groups (57 ± 24 g per day and 59 ± 25 g per day, respectively). The 28-day mortality was lower in the permissive-underfeeding group (18.4 %) than in the standard-feeding group (28.9 %). There were no significant differences among the groups with respect to feeding intolerance, diarrhoea or serious adverse events.
In critically ill patients, permissive underfeeding may be associated with lower mortality rates than standard-protocol feeding. It is evident that permissive underfeeding is a strategy that should be considered in the ICU septic patient. Employing such an approach may offer clinical benefit.
The serum total cholesterol (TC) level is known to be associated with survival of critical illness, especially in sepsis and surgical patients. However, there are only a few studies evaluating TC as a prognostic factor in medical patients.
The aim of this study was to determine the relationship between TC level and survival in medical patients admitted in intensive care unit (ICU).
From September 2013 to February 2014, the data was acquired at the nine intensive care units in the four provincial academic medical centers retrospectively. Statistical analysis was conducted to confirm risk factors with using correlation analysis and logistic regression.
In this study, a total of 503 patients were enrolled. The hospital mortality which is based on 28 days after admission was 28.2 %. TC levels derived at specific point of time showed negative correlation with APACHE IV score (initial TC, r = -0.231, p < 0.001; second week TC, r = -0.361, p < 0.001; third week TC, r = -0.327, p < 0.001) TC level of the second week, C-reactive protein level and status of ARDS were the independent risk factor for mortality in multivariate analysis (hazard ratio (HR) =0.98, p < 0.001; HR = 1.05, p = 0.02, HR = 8.24, p = 0.001, respectively) Conclusions Lower TC level is a prognostic indicator of hospital mortality in medical patients admitted in ICU. Following up TC level regularly has the advantage of managing critically ill patients.
Acute pancreatitis accompanied by organ dysfunction is termed severe acute pancreatitis (SAP) and if local complications (such as infected pancreatic pseudocysts) develop it may be described as complex SAP. As these patients often require care by specialist hepatopancreaticobiliary (HPB) surgeons and interventional radiologists, they may be transferred to specialist HPB centres. Fig. 102 (abstract A249) . The second week TC and APACHE4 score ICU-acquired weakness affects up to 40 % of patients on the ICU and is greatest in those with multiple organ systems requiring support. It is associated with prolonged need for mechanical ventilation and ICU stay, increased risk of death following hospital discharge, and long-term complications including impaired physical function [1, 2] . One Method of quantifying muscle wasting is the measurement of the cross sectional area (CSA) of para-spinal muscles at the level of the third lumbar vertebra from CT imaging [3] . The ICU at RSCH receives patients transferred from other ICUs for specialist care relating to their complex SAP. For clinical reasons these patients often have repeated CT imaging of their abdomens.
To characterise patients requiring critical care who have been transferred for specialist care of their complex pancreatitis between 2008 and 2014; and to measure their L3 para-spinal muscle CSA (L3MCSA) from each CT scan to ascertain their rate of muscle wasting.
Patients were identified from our ICU patient database (Ward-Watcher) and additional clinical details acquired from electronic databases. CT Images were exported as DICOM files from our PACS system. The cross-sectional area of the paraspinal muscles were measured using ImageJ software in duplicate by two independent users and the average values were used. Analysis used Excel (MS) and GraphPad (PRISM).
Results 45 patients met inclusion criteria and of these, 21 patients had ≥ 2 CT scans in ICU, enabling serial estimation of L3 paraspinal muscle CSA (L3MCSA). The average age was 53 (16.6) years. The median APACHE II score was 17. Patients underwent a median of 2 interventional/surgical procedures. The mean ICU LOS was 48 (26.9) days and ICU mortality was 19.1 %. 95 % of patients had a decrease in their L3MCSA during their ICU stay. See Table 80 . The median % L3MCSA change / day was -0.56 %. Higher pancreatitis severity score (Glasgow score at admission to our ICU) was associated with greater loss of muscle (p = 0.03). Increased systemic inflammation (% of time with CRP > 200 mg/l) was associated with increased rate of loss of muscle (r = -0.45 and p = 0.03). L3MCSA was not demonstrated to relate to duration of ventilation or ICU mortality.
This cohort of ICU patients with complex SAP showed profound muscle wasting, greatest in those with persistent severe inflammation. Identification of preventative strategies is a research priority.
Oxidative stress is known to adversely affect a variety of cellular functions, promote inflammation and take part in development of multiorgan dysfunction. Oxidant status can be evaluated by thiol/disulphide homeostasis. Previous studies have indicated that certain lipid formulations may contribute to decrease the oxidative stress. Potentiation of PON1 activity is one of the suggested mechanisms [1] .
Our aim was to evaluate basal paraoxonase1 activity(PON1), salt stimulated paraoxonase(stPON1), arylesterase(ARE), plasma native thiol, total thiol and disulphide levels in critically ill patients on parenteral nutrition(PN) containing different lipid formulations.
Critically ill patients for whom PN was planned, and who did not have a contraindication to PN were included in the study. Patients already on PN or who did not give consent were excluded. Three different PN solutions were used: a soya oil containing solution [long chain fatty acids(LCT)], an olive oil containing solution, and a solution containing middle and long chain fatty acids(MCT/LCT). Nutritional support was planned to provide 25-30 kcal/kg/day. Age, sex, admission diagnosis, smoking status, APACHEII and SOFA scores, invasive procedures performed, FiO 2 levels, administered drugs, transfusion were recorded for 3 days(0, 24 and 48th hour). Lipid profiles(HDL, LDL, total cholesterol, triglyceride), liver enzyme levels(AST, ALT, GGT, ALP, total/direct bilirubin), CRP, prealbumin values were recorded. As well, nosocomial infections that developed during admission, ICU and hospital length of stays and outcomes were recorded. Serum samples were collected before start of PN, at 24th and 48th hours of PN for PON-1, stPON1, ARE and total thiol levels and stored at -20°C. Biochemical studies were conducted after collection of all samples. PON1, stPON1 and ARE were measured spectrophotometrically. Plasma native thiol, total thiol and disulphide levels were measured as previously defined.
A total of 36 patients, 12 in each group, were included in the study. Age, sex, day of admission to hospital, APACHEII scores, smoking status were similar across the groups. Lipid profiles, liver enzyme levels, CRP levels were also similar. Although initial (prenutrition) plasma native thiol, total thiol and disulfite levels were different across groups; on follow-up no difference was observed between the groups on the basis of PON1, stPON1, ARE, plasma thiol, total thiol and disulphide levels.
Based on the results of this study, different PN solutions with different lipid compositions do not seem to alter the oxidant status as evaluated by the thiol/disulphide homeostasis. Although olive oil is expected to promote PON1 activity, this could not be demonstrated in this study. Prospective, randomized, dose dependent studies may be planned for further evaluation.
Autophagy is a survival process involved in the removal of protein aggregates and organelles that cannot be processed by the proteasome.
Recently an impairment of this system has been hypothesized in the development of organ failure of the ICU patients.
Autophagy is a highly dynamic process that cannot be studied in human in vivo. The aim of this study was to develop an experimental model to study the autophagy flux in ICU patients and to investigate which step of the autophagic pathway is impaired. We have developed an in vitro screening Method to measure autophagic flux in human primary myotubes incubated with serum from ICU patients.
Human primary myotubes were incubated with serum from consecutive ICU patients taken in the first 24 h of admission (n = 95) and healthy volunteers (n = 10) with a similar age range (40 -60 years old). Myotubes were cultured in 96-well plates, at 7 days of differentiation they were incubated with 10 % of human serum for 24 hours in the presence or absence of chloroquine (50 μM, 6 hr), an inhibitor of autophagy. p62 expression, a marker of autophagic vacuole accumulation, was measured by in-cell western, with an Odyssey scanner. The autophagic flux was calculated as followed: autophagic flux = p62 expression (+CQ) -p62 expression (-CQ). The results were normalized against cells number and expressed as a % of the autophagic flux in control condition. The screening on all serum samples have been repeated in 5 independent experiments. Results were analyzed by ANOVA with a Fisher post-hoc test.
We observe a larger variation in the expression of p62 induced by the patients' serum compared to the variation induce by the serum from healthy volunteers. p62 expression in myotubes incubated with the serum from 66 patients (ICU group) was similar to the healthy group (131 ± 4 vs. 122 ± 9 % of control; ICU vs. healthy). Interestingly, the serum from 29 ICU patients (ICU+ and  ICU Conclusion Serum from ICU patients was able to activate or block the flux of autophagy in human primary myotubes. Interestingly, even if the serum was collected during the first 24 h of admission we observed differences in the length of stay between our groups. The group inducing a block in autophagy corresponded to the long stayers patients.
Nasal or oro-gastric nutrition tube placement is verified radiologically. Daily placement verification is typically by air insufflation into the tube and auscultation, which has been shown to be unreliable. Tubes may move with patient movement, patient pulling, or coughing; necessitating ongoing placement verification. Other verification Method are testing gastric aspirate pH or pepsin, tube CO 2 output, visualization of gastric aspirate, and record of tube insertion length. Our intensive care unit (ICU) at Mount Sinai Hospital initiated a quality improvement (QI) project to change from auscultation to the gastric pH, with record of tube insertion length and visualization of gastric aspirate.
To adopt an evidenced based practice change and complete plan, do, see, act (PDSA) cycles, then make further changes based on our results.
Gastric aspirate samples were sent to the laboratory for testing by pH meter. Nursing education was done to introduce the test and procedure. A pH ≤ 5.5 was considered confirmation of gastric placement. Data collected included aspirate pH, use of acid inhibiting drugs, calories from EN and ordered and delivered, time EN held before pH testing, tube insertion marking length, and aspirate appearance. Ongoing education and changes to nursing and nutrition practice were made as results were evaluated as part of our PDSA cycle. Statistical analysis included mean pH, stratified by acid inhibitor, mean calorie deficit from holding EN for the test, and the 90 th percentile laboratory turnaround time.
Ninety pH tests were done and 21 tests missed, for 12 patients. The overall mean pH was 5.2 and median pH 5.7. Stratification by drug therapy results can be found in Table 81 . A cumulative percentile chart of pH with acid inhibitor Method is reported in Fig. 103 . All patients received EN. The mean calorie deficit observed was 1513 calories, for all reasons, not the gastric pH test alone. EN was held for 1 h before the test. The lab reported results usually in 30 minutes. Length of the feeding tube to insertion point was recorded for 1 patient.
Nurses were accepting of this process as evidenced by the few missed tests. Tests weren't done due to confusion over tube types requiring the test, inability to aspirate fluid from the tube, and forgetting. This created an opportunity for staff education to improve our process. Our data suggest that gastric aspirate pH ≤ 5.5 alone is not a reliable marker of gastric feeding tube placement when patients receive acid inhibiting drugs. There is opportunity to develop a confirmation bundle including a description of the aspirate, recording of length of the tube at insertion, and use of acid suppressing therapy. The possibility of underfeeding is an opportunity to implement a volume based EN protocol to allow the nurse to adjust the hourly volume of EN to compensate for time EN is held. This ICU QI project implemented a best practice following a PDSA cycle. 
Following insertion of a naso/oro gastric enteral tube and periodically afterwards in the United Kingdom it is essential to ensure that the distal portion of the tube is in the lower protion of the GI tract (the stomach). This is achieved principally through measuring the pH of gastric aspirate (1st line test) =/-x-ray (2nd line test) (NPSA, 2011). This small pilot study illuminates the accuracy (and potential for errors) with using pH indicator strips to confirm gastric placment.
To establish the accuracy of Nurses and Doctors interpretation of a range of known pH solutions using CE marked pH indicator strips with visual interpretation of pH results Method 50 nursing and medical staff were asked to identify the pH of clear/ colourless solutions with pH values ranging between 1 and 7. They were blinded to the pH value of the soultion until after they had completed the test. The pH indicator strips used had a possible range of 0-6.0.
All staff agreed to participate in this small study with the assurance of anonymity. Staff were observed to perform the test correctly if they a) waited 10-60 seconds prior to reading the strip; b) did not wipe the strip after immersion in the test solution. 100 % acheived accurate testing procedures.
The majority of staff (approximately 80 %) correctly interpreted the pH of solutions between 1 and 4 but demonstrated slightly less accuracy with pH of 5.8 (75 % accurate), erring on the lower value on the pH indicator strip of 5.5 When challenged with a pH solution which was know to be 7, only 1 out of ten staff they could not identify the pH value since the colour change was out of range of the pH indicator strip. The remaing staff (9-90 %) incorrectly interpreted the solution as having a pH of 6).
Although this was a small study, there is clearly a danger in relying on visual interpretation of colour change of CE marked pH indicator strips to confirm correct placement of naso/orogastric feeding tubes.
Future/further studies intend to compare alternative Method of pH quantification, incuding electronic pH testing devices.
Measurements of cardiac output (CO) are frequentlydone in surgical and critically ill patients as part of optimizationstrategies Transthoracic echocardiography (TTE) Method of CO measurement is more popular in critically ill patients.
Whether TTE Method of CO measurement is accurate as transpulmonary thermodilution (TPTD).
We compared near-simultaneously performed CO measurements in severe sepsis patients using TPTD with the PiCCO (Pulse index Continuous Cardiac Output) system or TTE. Outcomes were compared using t-tests, linear regression Results Forty severe sepsis patients were studied. An analysis of 120 data pairs revealed that PiCCO yielded similar CO measurements to TTE (p > 0.05). PiCCO-derived CO measurements highly related to and TTE-derived CO measurements (R = 0.75, p < 0.05).
Conclusions TTE can used for objective cardiovascular monitoring and to guide goal-directed fluid resuscitation in severe sepsis patients instead of PiCCO, and is noninvasive and convenient.
Norepinephrine (NE) is the most common vasoconstrictor drug used in the treatment of septic shock. High doses of NE are associated to bad prognosis, but the limits of refractory septic shock have not been well established.
To analyze the prognostic value of the maximum dose of norepinephrine on the mortality of patients admitted to ICU with septic shock. Method A two-years retrospective study in a single ICU on patients admitted with septic shock treated with NE. The NE maximum dose was analyzed, the time to reach this dose, the days of treatment, the origin and focus of sepsis, the use of other amines, the APACHE II and SOFA score and ICU and hospital mortality. Prognostic value of maximum dose of NE was analyzed using multivariate logistic regression and a ROC curve analysis was carried out to assess its discriminating ability.
We analyzed 128 consecutive patients, with an average age of 64 years (SD 15,6), a mean APACHE II 20 (SD 8) and a mean SOFA score of 8,3 (SD 3,4). The average value of the maximum dose of NE was 0,94 μg/Kg/min (SD 0,84) and the median time to achieve it was 1 day (range 0-22). ICU mortality was 30 % and hospital mortality was 34 %. In the multivariate analysis, the maximum dose of NE was independently associated with ICU mortality (14,6 95 % CI: 6,1-34, 8; p < 0,001) and hospital mortality (9,2 95 % CI: 4,0-19,3; p < 0,001). ROC curve of the maximum dose of NE showed a high discriminative ability for ICU mortality with a r = 0, 93 (95 % CI 0,88-0,97; p < 0,001) and for hospital mortality with r = 0,87 (95 % CI 0,81-0,94, p < 0,001), with a cut-off point of maximum sensitivity (0,82) and specificity (0,83) on 1 μg/Kg/min. In-hospital mortality of patients with dose maximum of NE > 1 μg/Kg/min was 72 % versus 10,3 % in patients with lower doses and it was 100 % in the patients with septic shock with doses greater than 2 μg/Kg/min (20 cases).
The maximum dose of norepinephrine had an independent prognostic value in septic shock. Doses higher than 1 μg/Kg/min are associated with a clear worse prognosis, so it could be considered the limit of refractory septic shock.
The 6S trial showed increased 90-day mortality with hydroxyethyl starch (HES) 130/0.42 vs. Ringer's acetate in patients with severe sepsis [1] , but the pathophysiology driving this has not been fully elucidated.
To compare changes in cytokine plasma concentrations in the days after randomisation into the 6S trial.
In a subgroup of 226 patients from the 6S trial we analysed differences between the HES-and Ringer's groups in delta plasma concentrations of TNF-α, IL-6 and IL-10 from baseline to day 2 after randomisation using multiple linear regression analysis. Additionally, associations between the changes in cytokines and 90-day mortality were investigated using multiple logistic regression analysis. We imputed values missing due to discharge or errors using multiple imputation.
Baseline characteristics were similar in the HES-and the Ringer's groups. By day 2, 13 (11 %) patients in the HES group had died vs. 11 (10 %) in the Ringer's group (P = 0.91). Plasma concentrations of TNF-α, IL-6 and IL-10 decreased from baseline to day 2 in the HESand the Ringer's groups, but mean delta cytokine concentrations did not differ between the groups (Table 82) . Also, no associations were observed between changes in the cytokine plasma concentrations and 90-day mortality (TNF-α: odds ratio for 1-unit increase, 1.000 (95 % Confidence Interval, 0.998 -1.003), P = 0.87; IL-6: 1.001 (0.999 -1.002), P = 0.32; IL-10: 1.000 (0.999 -1.001), P = 0.89).
Resuscitation with HES 130/0.42 vs Ringer's acetate did not affect TNF-α, IL-6 and IL-10 plasma concentrations and changes in these cytokines were not associated with 90-day mortality in patients with severe sepsis. Consequently, our results suggest that the increased mortality seen with HES in the 6S trial was not mediated by early changes in systemic inflammation.
Fluid overload is associated with poor outcomes in septic patients. Btype natriuretic peptide (BNP) concentrations are useful tools to guide the therapy of patients with heart failure. However, BNP concentrations in the patients after septic shock resucitation are poorly studied. If BNP concentrations can predict the day of the peak fluid balance, BNP guided therapy enables us to restrict the fluid volume and start the diuresis appropriately.
We investigated daily BNP concentrations and fluid balance in septic patients. We hypothesized that the day of the peak BNP concentration predict the day of maximum fluid balance. The patient age, sources of infection are included in the analysis as confounders.
Our inclusion criteria was as follows; 1) septic patients of any sources of infection (urinary tract infection, pneumonia, soft tissue infections, upper and lower GI tract perforation, and bacteremia), 2) those admitted to our ICU, and 3) the daily BNP concentrations were measured during the ICU stay. We excluded patients who had been already on hemodialysis. We first described the time lag between the day of the peak BNP concentration and that of maximum daily fluid balance. We conducted multivariate regression analysis on this time lag with patient age, sources of infection, and maximum daily fluid balance as covariates.
We included 48 patients, aged 75 in average. The peak BNP concentration followed the maximum daily fluid balance by 0.57 day (SD, 2.36). In multivariate regression analysis, the delay of maximum BNP concentration after the maximum daily fluid balance was associated with older age (β 0.08, p = 0.03), but was not associated with net daily fluid balance or sites of infections.
Our study suggested that the timing of maximum BNP concentrations and the maximum daily fluid balance might parallel in septic patients. However, the peak BNP concentrations tended to follow the maximum daily fluid balance as the patients get older. Thus, BNP cannot be used to estimate the refilling phase.
None. The imputed dataset from all the 202 day 2 survivors were analysed and adjusted for SAPS II and the stratification variables: university hospital, hematologic malignancy and shock at randomization Introduction Microcirculatory alterations in sepsis plays a vital role in development of multi organ system failure, and this is clear from the observation that despite correction of systemic hemodynamic parameters still usually the course of multi organ system failure continue [1] . Effective fluid resuscitation is a corner stone in the effective management of patients with septic shock with the goal to improve tissue perfusion at the micro circulatory level [2] .
The aim of this work is to compare and evaluate the influence of gelatin and saline on sublingual microcirculation in patients with severe sepsis and septic shock. Another objective is to assess its effects on the incidence of renal dysfunction and acid base disturbance.
Prospective, randomized, controlled study was conducted on 42 patients with severe sepsis and septic shock, Patients meeting inclusion criteria was randomly assigned to receive either gelatin 4 % (21 pts) or saline 0.9 % (21 pts). Patients received 500 ml of either solution every 30 minutes till reaching the goals of initial resuscitation, using a Sidestream Dark Field device mean flow index was determined before and 6 hours after resuscitation. Arterial blood pressure, heart rate, and vasopressor therapy was recorded every 30 min during the first 6 h. Arterial blood samples were collected at three specific times: on randomization before fluid administration, 6 and 24 hours after initial resuscitation. Urea, creatinine, urine output and SOFA score was measured daily for the first 5 days after resuscitation.
Among forty two patients enrolled in the study, demographic data and patients´characteristics were comparable among both groups. After 6 hours from resuscitation, no difference arose in the Sublingual microcirculation parameters between both groups, mean flow index after resuscitation in gelatin group (1.65 ± 0.65) which was not superior to saline group (1.74 ± 0.65). No difference was noticed in acute kidney injury nor acid base disturbance, but there was significantly greater net cumulative fluid balance in saline group 2726 (1429) ml compared to gelatin group 930 (2450) ml (P = 0.006) which indicates more fluid need for the first 24 hours in the saline group.
The main finding in this prospective randomized study was that the use of gelatin in resuscitation of patients with septic shock does not confer any advantage over saline in recruitment of sublingual microcirculation.
Central venous oxygen saturation (ScvO2) is an indirect indicator of the adequacy of oxygen delivery and cardiac output. A reduction in the level of ScvO2 below normal levels indicates an increase in oxygen extraction by the tissues in response to a decrease in the arterial oxygen content or cardiac output [1] . The ScvO2 has been widely utilized for hemodynamic optimization in severe sepsis/septic shock [2] . A time lag usually occurs between admission of a septic patient to the emergency department and the insertion of a central venous catheter (CVC). Thus, the need for a surrogate to the ScvO2 which is easily and rapidly obtainable.
To date peripheral venous oxygen saturation (SpvO2), which involves an antecubital blood sample has not been validated to replace the ScvO2 for the purpose of hemodynamic optimization in severe sepsis/ septic shock.
The objective of this study was to assess the feasibility of replacing the ScvO2 with the antecubital SpvO2 for the management of severe sepsis/septic shock.
Thirty five successive patients with severe sepsis/septic shock in whom a CVC was inserted were the subject of this study. Simultaneous central venous and antecubital peripheral venous samples were withdrawn and tested for oxygen saturations. We compared 35 pairs of simultaneous ScvO2 and SpvO2 samples.
Mean age was 65.3 ± 16 years. Sex-ratio (M/F) was 1.7. Eleven patients (31.4 %) had severe sepsis and 24 patients (68.6 %) had septic shock. Spearman's correlation coefficient between ScvO2 and SpvO2 was 0.497 (p = 0.002). Subgroup analysis of patients with severe sepsis and patients with septic shock showed a Spearman's rho coefficient of 0.727 (p = 0.011) and 0.422 (p = 0.065) respectively.
SpvO2 showed good correlation with ScvO2 in patients with severe sepsis. Therefore, it may be a useful tool for early implication of hemodynamic optimization in patients with severe sepsis.
For several decades, RDW has been typically used in combination with the MCV to differentiate the cause of underlying anaemia in clinical practice. Recently, high RDW has been associated with increased mortality in patients with severe sepsis and Septic Shock [2] . The pathophysiologic mechanisms underlying the association between RDW and mortality are unclear; however, it is possible that its relationship with inflammation and oxidative states plays role in this [3] . RDW has been linked with inflammation in critically ill patients and with oxidative stress in animal models.
To assess the prognostic value of red cell distribution in patients with sepsis and its relation with hemodynamic parameters assessed noninvasively. 
High RDW is associated with higher mortality in sepsis patients and is higher in patients who developed respiratory failure during ICU stay. RDW showed significant correlations with shock index and lactate levels.
The installation of progressive microcirculatory dysfunction has been identified as a crucial factor in the development of MODS in sepsis, which is why the identification, prevention or recovery of microcirculatory damage has been a major focus of research. In clinical practice, the sublingual region has been the site of choice for evaluation of dysfunction in sepsis, mainly for ease of access. However, there are doubts as to its validity in relation to microcirculation of other organs commonly committed in sepsis. This study aimed to compare the sublingual microcirculation with intestinal, during the initial phase of sepsis in order to assess whether the sites with the same embryological origin have similarities in microcirculatory dynamics.
Wistar rats were subjected to sepsis (iv. E. coli 2x10 9 CFU/mL, DL80 in 26 hours, n = 10) and microcirculation of sublingual regions and jejunum were captured by Sidestream Darkfield images (SDF). The total vessel density (TVD) was analyzed by software AVA-3.0 at 0, 1, 2, 3, 4, 5 and 6 consecutive hours post sepsis. The sham group was injected with saline only. (n = 5). In all periods of the study the animals were kept under general anesthesia with mechanical ventilation, receiving hydration (7 ml saline/kg/hr, iv).
In sublingual, there was a significant reduction in vascular density of animals with sepsis only after 3 hours of sepsis compared to the sham group. (Fig. 104) . This suggests that reducing the density in sepsis is only noticeable during periods of increased severity of sepsis. The comparison between the periods of sepsis showed that only the first two hours had a higher density compared to other periods of sepsis. These results have shown that in sepsis, the density of the microcirculation decreases with the severity of sepsis, however, AVA-3.0 Method was able to show differences only between extreme stages (almost normal with the stages of extreme severity), indicating a low sensitivity of the Method to differentiate small changes in density. In the gut, no changes were detected between groups and between periods, showing that the jejunum density is not variable in sepsis. These data showed that the dynamic microcirculatory is organ-specific and independent of embryological origin. In short, the evaluation of microcirculatory dysfunction is site-dependent and appears to require assessment Method also organ-specific to the kinetic measurement of microcirculatory dysfunction in sepsis. 
Derangements on microvascular blood flow distribution have been implied on impairment of oxygen extraction by peripheral tissues.
To evaluate the effects of dobutamine on the heterogeneity of microvascular blood flow at intestinal and sublingual territories and its relationship with mesenteric and systemic oxygen extraction in a severe hypodynamic septic shock model.
Fifteen landrace pigs were anesthetized and mechanically ventilated. Catheters were inserted into carotid artery, pulmonary artery and portal vein for blood sampling, and for invasive pressures and cardiac output monitoring. A gas-tonometer was placed into jejunum for mucosal-CO 2 determination while a jejunostomy was prepared to visualize gutmucosal microcirculation. At each measurement time-point, arterial, mesenteric-venous and mixed-venous blood samples were obtained to blood gases analysis. Images of intestinal microcirculation were acquired using the Side-stream dark Field technique. These video-sequences were stored under a random number for ulterior blinded analysis. After baseline measurements (BL), fecal peritonitis was induced. When hypotension was not responsive to fluid resuscitation, norepinephrine was started and shock was declared (TS). Then, pigs were randomized to a fixed-dose of dobutamine at 5 μg/kg/min (n = 6) or placebo (n = 6). New measurements were performed 2 (T2H) and 6 hours (T6H) after. Three sham animals subjected to identical monitoring served as time- 
Septic shock is characterized by altered perfusion, potentially leading to tissue hypoxia. The central-peripheral difference of some metabolites (lactate, oxygen and CO 2 ) and their ratios may be good markers of peripheral hypoperfusion.
To characterize the evolution of some peripheral indexes of perfusion and metabolism in a model of sepsis due to peritonitis.
We studied 18 anesthetized, mechanical ventilated and invasively monitored sheep, in which autologous feces were injected into the abdomen. Fluid administration was titrated to maintain initial pulmonary artery occlusion pressure. Vasopressors were not used. Arterial, mixed venous (v), and right femoral venous (fv) blood samples were collected at baseline and every 4 hours to perform blood gas analysis and lactate (LACT) measurements. A microdialysis catheter was placed in the posterior leg muscle to measure the lactate/pyruvate (LP) ratio every hour. We calculated the fCO 2 gap as PfvCO 2 -PaCO 2 , fLACT gap as fvLACT -art LACT, fO 2 con- Tables 83 and 84 , and all data before and after the development of hypotension are presented in Table 85 . ( † = only 12 animals; * = p < 0.05 vs T1).
All peripheral indexes were influenced by the decreased blood flow, but the fCO 2 gap and the fLACT gap were altered earlier; these indexes could potentially be useful to detect tissue hypoperfusion during sepsis. 
Shock is best defined as a life-threatening, generalized form of acute circulatory failure associated with inadequate oxygen utilization by the cell. Importantly, peripheral vasodilation (relative hypovolemia and low systemic vascular resistance) coexist with cardiac dysfunction (left ventricular (LV) diastolic and systolic dysfunction secondary to primary myocardial injury or right ventricular dysfunction due to pulmonary hypertension) resulting in ventriculoarterial decoupling. Ventriculoarterial coupling is defined by the ratio of arterial elastance (Ea) to left ventricular end-systolic elastance (Ees).
In this study, we analyzed the variability of ventriculoarterial coupling in ICU patients with septic shock and the effect of therapeutic interventions such as vasopressor and inotropic agent to improve perfusion.
In this prospective study, we measured routine hemodynamics using indwelling arterial catheters and transthoracic echocardiograms in septic patients upon ICU admission. Hemodynamic variables included cardiac index (CI), heart rate (HR), mean arterial pressure (MAP). Ees was measured by echocardiography using a single-beat (EesSB) Method Ea was calculated as 0.9 systolic arterial pressure/stroke volume, and then the Ea/EesSB ratio was calculated (normal value < 1.36).The measure were repeated every day for a maximum of seven days.
We analyzed a series of measured parameters in six patients. 
During the first week of ICU admission, the excess of fluids seems to be caused by hidden fluids (maintenance and drug-related fluids). Furthermore, these appear to be related with a higher mortality, as does an insufficient resuscitation within the first 6 hours of ICU admission.
Real time heart rate variability is highly predictive of mortality in pediatric septic patients 
Heart rate variability (HRV), has shown promise in predicting pediatric patients at high risk for sepsis and death [1] . However, its use in clinical practice has been precluded by the absence of real-time data. Objective This study was conducted to evaluate the utility of electrical cardiometry for real-time determination of HRV and using these data in predicting the outcome in pediatric patients presented with septic shock.
Prospective enrolment of pediatric patients who met the criteria of septic shock. Electric cardiometry (ICON) was used to measure time-domain HRV continuously in real time for 2 hours after admission to intensive care unit. Electric impedance cardiography was used to determine cardiac output. Hemodynamic parameters which discriminate survivors from non-survivors were evaluated.
We enrolled 15 pediatric patients with septic shock of whom 5 (33 %) patients were discharged and 10 (66 %) died. Heart rate was similar between survivor and non-survivor. Note: This abstract has been previously published and is available at [1] . It is included here as a complete record of the abstracts from the conference.
Posttraumatic stress symptoms (PTSS) following intensive care treatment are frequent. In accident victims strong sense of coherence (SOC) has previously been associated with less PTSS. To our 
Intensive Care Units (ICU) are characterized not only for caring the sickest patients but also due to its high levels of anxiety and stress in health workers, which takes its maximum expression in the burnout syndrome. The cause of this burden is frequently related to specific ICU work factors such as physical and emotional workload. There are several theoretical approaches to these problems, for example the imbalance effort -reward (ERI) model, which has been poorly tested in the ICUs. In chilean ICUs, the multidisciplinary team is mostly composed by registered nurses and nurse aides whom must work hand in hand to ensure the quality and safety of care. The aim of this study was to investigate the prevalence of effort-reward imbalance and burnout among ICU registered nurses and nurse aides in a teaching hospital.
Comparative, cross-sectional study. A convenience sample of ICU registered nurses (RN) and nurse aides (NA) from a teaching hospital in Santiago, Chile was obtained. Three questionnaires were used for data collection:
i.) A sociodemographic questionnaire, ii.) Spanish short version of Effort-Reward Imbalance questionnaire by Siegrist, an ERI > 1 indicated an imbalance between efforts and rewards , and iii.) Maslach Burnout Inventory, including their 3 subscales: emotional exhaustion (EE), personal accomplishment (PA) and depersonalization (DP). A p-value < 0.1 was considered.
The response rate was 87.2 % (n = 82 
Most of the ICU nursing team has an effort-reward imbalance, which is higher in nurse aides due to a lower perception of rewards. Burnout seems not to be a problem, but low degree of personal accomplishment suggests that is necessary to perform early interventions based on the recognition and opportunities for personal development, specifically on nurse aides, this interventions could help to maintain low levels of burnout and improve effort reward imbalance.
None of the authors of this work received any grant or financial aid.
Nurses´perceptions of patient safety climate in intensive care units W. Egbaria 1 , R. Kigli 2 1
Climate safety is a design factor guiding the judgment and behavior of health care professionals, and highlights the issue of patient safety at the top of their priorities. At safety climate, employees are directed to act in accordance with company-wide commitment to safety, so that each state maintain personal safety norms and those of colleagues. This formed a consensus on the relative importance of safe behavior in situations that present conflicting requirements in safety competitors such as meeting deadlines.
Checking the safety climate concept among intensive care nurses while making a comparison between ICU nurses and CCU nurses.
And check whether the theoretical model fails to predict a safe culture among intensive care nurses?
The study population consisted of 81 nurses who work in intensive care units in hospitals at tel aviv district. The subjects were asked to complete a structured questionnaire containing 69 items. Which examined the perception of nurses´patient safety climate in workplace, communication between employees, frequency of reported incidents, organizational and departmental policies and procedures and practices. Data were collected in April-May 2015.
This study increased moderately positive correlation exists between the perception of workers ICU patient safety, and the total score of the atmosphere of safety (r = 0.623, p < 0.000). There is a positive medium correlation between the perception of icu workers of corporate policies and departmental and between process and Methodology (r = 0.568, p < 0.01), while in the ICU General (r = 0.626, p < 0.01), compared to intensive care Cardiology (r = 0.508, P < 0.01).
The findings support the theory of ZOHAR (2000, 2003) about the safety climate that is meaningful for intensive care nurses. Which refers to a common perception among members in all aspects of the organizational environment, that dictates the behavior at work and the extent to which certain aspects are rewarded and supported in the organization. There are differences between the general intensive care and cardiac intensive care in evaluating patient safety and an atmosphere of safety, particularly in assessing and evaluating the work area corporate policy.
Continuous endotracheal cuff-pressure (P cuff ) control in the prevention of ventilator-associated respiratory infections (VARI): a systematic review and meta-analysis B. Maertens 1 , K. Blot 1 , S. Blot 2
Ventilator-associated respiratory infections (VARI) are an important source of morbidity in ICU patients. Continuous endotracheal P cuffcontrol is a way to minimize micro-aspiration of subglottic secretions, which is considered to be a major pathogenic mechanism of VARI.
To perform a systematic review and meta-analysis to assess the efficacy of continuous P cuff -control in the prevention of VARI. Method MEDLINE, EMBASE, CENTRAL/CCTR, Clinicaltrials.gov and ICTRP were systematically searched. Eligible trials were randomized controlled clinical trials (RCTs) and quasi-RCTs comparing continuous P cuff -control with manual, intermittent P cuff -control in intubated patients. All studies reporting VARI incidence were included. VARI includes ventilator-associated pneumonia and ventilator-associated tracheobronchitis. Inclusion of trials was irrespective of publication status, date of publication or language.
Two RCTs [1, 2] and one quasi-RCT [3] meeting the inclusion criteria were identified (one using a pneumatic device [1] and two using an electronic device for continuous P cuff -control [2, 3] ). All studies were single-center; none of the trials was blinded for the intervention. 465 patients were allocated to the intervention arm and 455 to the control arm. 50 VARI episodes occurred in the intervention group and 91 in the control group. The pooled Odds Ratio for the incidence of VARI was 0.45 (random effects model, 95 % confidence interval, 0.30-0.69; z = 3.68 p < 0.001).
This meta-analysis shows that continuous P cuff -control appears to reduce the incidence of VARI. However, the number of included studies is small, and there is an inherent risk of bias due to the unblinded designs.
Introduction acute kidney injury (AKI) is a commom complication after heart transplantation and it is associated with high morbidity and mortality.
To evaluate the incidence of acute kidney injury (AKI) and outcomes in adult patients undergoing heart transplantation according KDIGO criteria.
We performed a retrospective cohort study in a tertiary hospital specialized in cardiac surgery and reference in Latin America. Patients older than 18 years old who had undergone heart transplantation between January 2011 and January 2015 were included. Patients with congenital heart disease were excluded.
Patients were divided into two groups (those who did not develop AKI and those who did develop AKI). The incidence of acute kidney injury was 86 %. We did not observe diference between the groups in relation to males (70.0 % vs. 66.7 %, p = 0.834), age (43 ± 13 years vs. 46 ± 12 years, p = 0.493) and EuroSCORE (8.2 ± 1.6 vs. 7.4 ± 2.2, p = 0.289), respectively in no AKI and AKI group. When we compared clinical characteristics before the transplantation, we found significant differences in relation to in inotropic dosis (18.6 ± 5.1 mcg/kg/ min vs. 14.2 ± 5.9 mcg/kg/min, p = 0.037) and the use of intra-aortic balloon pump (88.9 vs. 46.7, p = 0.012), respectively in no AKI and AKI group. The outcomes length of stay and mortality were greater in the postoperative period in the group of patients who did develop AKI when compared with the group who did not develop AKI.
The incidence of acute kidney injury in patients undergoing heart transplantation was 86 %. The mortality was higher with the presence of AKI.
Team leadership & staff engagement are key influences on performance, clinical outcomes & patient satisfaction [1, 2] . There is increasing recognition of stress experienced by critical care nurses [3, 4, 5] . These factors, alongside a shortage of critical care nurses, indicate that recruitment, retention & professional support for nurses are key issues in the delivery of safe & effective healthcare.
The study aimed to positively engage nurses, as key stakeholders in critical care, to identify the gold standard framework for a high performance team, from a nursing perspective. The study uses qualitative Methodology, which is recognised to be under-utilised as a research tool in critical care [6] . Results 117 abstracts were considered, 81 abstracts excluded and a total of 36 further considered. Studies were drawn from around the globe, with considerable work undertaken in UK (9 studies) and Brazil (10 studies). The empirical studies ranged from retrospective analyses, staff diaries and surveys, observational studies, prospective studies of the use of specific tools and staffing models and instrument development. The tools examined fell into two main groups: those related to the condition and needs of the patient, and those related to nursing activities and interventions.
Understanding nursing workload and activity is complex and there are numerous tools available to measure this. Nursing Activities Score (NAS) was the most extensively examined tool, with generally reliable results focusing on the whole of the ICU nurse's workload so most suitable for evaluating overall staffing levels. The risk based model provides a means of determining nurse allocation around risk as opposed to Workload or patient dependency. However, we concluded that there is a scope to develop a new tool using the elements from the tools examined in this review which then needs to be tested in clinical practice.
There is a direct link between Intensive Care Unit (ICU) staff numbers and clinical outcomes; an increase in the ICU staff capacity translates to improved clinical outcomes, which results in a decrease in ICU mortality rates. This effect is more pronounced when the staff are dedicated and specifically trained to care for critically ill patients. Furthermore, an increase in ICU staff numbers has a cost saving benefit to both the patient and the healthcare institution. 
It is well acknowledged that the intensive care unit (ICU) environment can create a stressful work atmosphere for clinicians. Promoting a healthy work environment for ICU settings has been identified as a way to reduce work-related stress in the ICU. As part of an overall initiative to enhance the work environment in the ICU at a 620 bed university affiliated medical center, an employee appreciation day was designated and 10 minute massages were provided to clinical staff.
The objective of this study was to assess the impact of a massage intervention on self-reported stress ratings.
The Numeric Stress Scale, an established Likert scale ranging from "0" or "No Stress" to "10" or "Unbearable Stress" was used to collect self-assessed perceptions of stress ratings. A 10 minute massage was provided by certified massage therapists using portable massage chairs set up in a conference room.
A total of 182 nurses and other clinicians completed a pre-post assessment of self-reported levels of stress. Before the massage, clinicians rated their own level of stress as being, on average, 6 out of ten (moderate). After the 10 minute massage, stress ratings were found to decrease, with over one third of respondents reporting low levels of stress [0 or 1], and 30 % of respondents reporting "no stress". The number of clinicians reporting high levels of stress [9 or 10] decreased from 11 to 3 after the massage intervention. An independent samples T-test was used to compare the pre (mean = 6.15, standard deviation 2.02) and post (mean = 2.25, standard deviation 2.14) stress ratings. The change in self-reported levels of stress was found to be a statistically significant decrease (t-statistic = 12.5, df 181, p < .000).
A 10 minute massage intervention was found to result in decreased levels of self-reported stress levels in ICU clinicians in this single center study. Exploring the impact of stress reducing interventions for ICU clinicians requires further investigation as part of an overall focus in promoting a healthy work environment in the ICU.
Diabetic ketoacidosis (DKA) is a major complication of diabetes mellitus. It is more and more frequent in Tunisia with an incidence ranging from 4 to 8 per 1000 diabetic patients. There are many insulin administration protocols and many unresolved questions : the place of alkalinization and the signification of hyperchloremic acidosis.
The aim of this work was to evaluate the management of DKA in a Tunisian medical intensive care unit and to determine the prognosis factors in our diabetic patients.
We conducted a retrospective analysis over two years (January 2013 -December 2015), of records of patients who were admitted to our intensive care unit (ICU The mean capillary glycaemia was 5, 16 ± 1, 40 g/l. Twenty two patients (40 %) had pseud hyponatremia. Seven patients (13 %) presented hyperkaliemia at admission. The mean c-reactive protein level was 15,28 ± 23,81 mg/l. The mean level of bicarbonate value was 10,68 ± 5 mEq/l at admission. The mean overall osmolarity was 318 ± 16 mEq/l. 28 patients were infected (54 %). All patients had a close bedside monitoring of blood glucose, blood gas and blood electrolyte measurement according to our local protocol management which will be detailed in this work. The fluid replacement therapy was based on crystalloids. Three patients received alkalinization. Four patients presented a coronary syndrome. Five patients developed hyperchloremic acidosis. The overall mortality rate was 13.5 % (7 patients).
The mean hospital stay in our ICU was 37,8 ± 22,7 hours. Factors associated with mortality were type 1 of diabetes (p = 0.004), SAPS 2 (p < 10 -6 ), shock ((p < 10 -6 ), and acute renal failure (ARF)(p < 10 -6 ) in univariate
Both NT-proBNP and Doppler echocardiography have been approved in the diagnosis of heart failure. In our Study, we compared the contribution of the NT-proBNP levels with the Doppler echocardiography findings in the diagnosis of decompensated congestive leftheart failure (CHF) in patients with acute dyspnea.
To compare NT-proBNP levels and echocardiography finding in the determination of the etiology of difficult-to-diagnose severe dyspnea in the emergency department.
It was a prospective, observational study at the teaching department of emergency and intensive care in the regional hospital of Zaghouan, including patients with severe dyspnea over six months. All patients underwent physical examination, 12-lead ECG, RX Thorax, NT-ProBNP essay and echocardiography by an attending cardiologist on admission. 
Major oesophagogastric surgery is associated with significant postoperative morbidity, reduced functional capacity and quality of life [1] . Evidence from colorectal surgery populations demonstrates significant benefits of prehabilitation [2] . There is no evidence to support this approach for patients undergoing oesophagectomy and TG.
To assess the impact of implementing prehabilitation and enhanced post-operative physiotherapy in patients undergoing oesophagectomy and TG.
Consecutive patients from November 2014 to March 2015 were entered into a standardised ERAS programme incorporating twice daily physiotherapy for five days postoperatively with pre-specified mobility milestones. Of these, 17 were eligible and offered prehabilitation, incorporating twice-weekly cardiovascular and strengthening classes for 4 weeks, of which 13 attended. Outcomes measured were functional capacity by incremental shuttle walk test (ISWT), anxiety and depression by HADS score, and perceived health status by EQ5D. We also compared data for those who attended prehabilitation to those who received ERAS only post operatively. Postoperative outcomes were time to mobilise 30 m, mobility level at critical care discharge by MMS and total hospital length of stay (LOS).
Thirteen patients attended prehabilitation, with improvements seen for all outcomes on completion (see Table 86 ). Post operatively, patients who attended prehabilitation were more mobile at ICU discharge (MMS 7 vs 6) and quicker to mobilise 30 m (3.2 vs 4.7 days). A reduction in LOS was also seen for prehabilitation patients in comparison to those receiving ERAS alone (14.7 days vs 17.5 days).
Implementation of a programme of prehabilitation is feasible in patients undergoing major oesophagogastric surgery and was associated with improved outcomes preoperatively. These improvements were associated with a higher level of mobility at the point of critical care discharge and shorter hospital length of stay. Future appropriately powered research is needed to confirm these findings.
Infusion pumps are often associated with poor usability and an increased likelihood of medication errors [1] . Critically ill patients in the intensive care unit (ICU) usually receive multiple infusions simultaneously, which increases the likelihood of pump-related errors. Furthermore, the ICU is frequently a hectic environment, compounding the likelihood of human error. Improving the usability of infusion pumps could help prevent injury or death in this vulnerable population. Where previous usability studies focused on individual pumps, this study focuses on the pump system as a whole, a situation more representative of the ICU.
The aim of this study is to develop and test a pump display that facilitates centralized monitoring and control of multiple infusion pumps to improve the safety and efficiency in the interaction with infusion technology. Method A central pump display was developed according to the latest guidelines in user-centered design [2] . The usability of this display was compared to that of a conventional pump setup in a simulation study where 18 ICU nurses performed common pump-related tasks with either the central or conventional interface. Participants had a mean of 12 (±12) years of ICU work experience. Task execution times and key presses were recorded and logs were scanned for errors after the experiment. A usability questionnaire with a 5-point Likert scale was administered at the end of each experimental run to assess end-user satisfaction.
Overall there was no difference in total task execution time between the central (M = 421 ± 107 seconds) and conventional system (M = 405 ± 119), p = 0.78. Fewer clicks were needed to execute the tasks with the centralized system compared to the conventional system (40 ± 3 and 73 ± 20 clicks respectively), p = 0.001. Fewer errors were made with the centralized system compared to the conventional system (0.9 ± 1 and 2.9 ± 2 errors respectively), p = 0.031. Questionnaire results indicated an overall preference towards the centralized system (4.6 ± 0.3 vs. 4.1 ± 0.5), p = 0.033.
Expert users with significant experience using the conventional pump interface demonstrated a more efficient and safer performance using the central control display. The central control display had a better overall usability than the conventional pump control interface, despite participants never having used it before. The results of this 
Renal failure in a patient, whether it develops during hospitalization or admission, is an independent predictor of mortality so efforts to detect it earlier in an ICU setting should be performed in all patients in order to set up preventive and therapeutic maneuvers. Despite well established diagnostic criteria for acute kidney injury (AKI), the detection is often delayed in the clinical practice. When making the analogy with cardiac angina, even though several biomarkers have been developed for an early detection of AKI none of them have the sensitivity and specificity of troponin levels in a cardiac setting. Therefore, the concept of renal angina was developed considering risk factors and clinical signs of renal failure, scoring patients in 4 groups according to the need of Continuous Renal Replacement Therapy (CRRT): very high, high, moderate and low risk.
In pediatric ICU populations this concept has been widespread, not as well in adult ICU patients.
To present a pilot study where we describe 8 patients who required CRRT in the last month and determine the risk for the presence of renal angina at admission. Method Descriptive pilot study. We retrospectively analyzed all adults patients who required CRRT during March 2016 in which all data needed to evaluate the risk for renal angina was completed. We obtained and interpreted their demographics and laboratory results as well as their pre-medical history.
All patients were male, with a mean age of 74 ± 12 (55-89). 3 patients died. The most common diagnosis was community acquired pneumonia (50 %), and second was acute on chronic cardiac failure (25 %). At admission they were all classified in the very high risk group. Also, the 8 patients had one or more mayor chronic criteria. The most frequent risk factors were hypertension history or hypotension at admission (75 % respectively), age and sepsis (62.5 % respectively). All patients had early elevation of serum creatinine (sCr) of at least 0.1 mg/dl. Average days between admission to the ICU and beginning of CRRT was 3.
Determining renal angina score in patients admitted to the ICU might be a cornerstone for treatment and prevention of renal failure, especially in patients within the very high and high risk groups. This will allow clinicians to be very suspicious of the slightest sCr elevation (as low as 0.1 mg/dl), as it can predict the need for CRRT, and thus establish preventive maneuvers or initiate replacement therapy early.
Acute kidney after cardiac surgery is well described [1] . AKI is associated with an increase in morbidity and mortality both in the short and long term [2] . The severity of AKI is directly proportional to outcome [3] and is independently associated with mortality, specifically if sustained injury occurs [4] . In 2012 we implemented a protocol post cardiac surgery to ensure adequate fluid resuscitation as a strategy to reduce complications, namely AKI. The incidence of AKI was reduced from 19.9 % to 6.5 %.
To ensure our efforts to reduce the incidence of AKI were still effective. Method Pre-operative baseline and peak creatinine data is prospectively recorded by our audit team to monitor the incidence of AKI. Baseline characteristics were collected along with the discharge creatinine, incidence of CVVH, length of ICU and hospital stay, ICU readmissions and mortality.
Over 6 month period, 431 cardiac surgical admissions occurred in CTICU of those 9.28 % (n = 40) sustained AKI using the KDIGO classification. Of those 4.87 % (n = 20) sustained stage I, 1.62 % (n = 7) sustained stage II, and 2.78 % (n = 12) sustained stage III. 12.5 % (n = 5) died. 10 % (n = 4) were re-admitted to ICU and 44 % (n = 15) of those surviving, the AKI had resolved prior to hospital discharge.
The incidence of AKI remained below the baseline from 2012. Though resolution of AKI did not occur in most. Further follow up is required by GP's to ensure further injury doesn't occur and to highlight caution. There was no evidence of AKI within the surgical discharge summary. Our recommendation is to write ICU discharge letters including such events. Although the incidence of AKI has remained lower, AKI still occurs. Identifying patients at risk for AKI during pre-op assessment is recommended. Modifiable risk factors should be optimized and high risk patients should be identified prior to cardiac surgery as recommended in the literature to reduce this complication further.
Pressure ulcers (PU) are a frequent adverse event in intensive care unit (ICU analysis for each of the markers was performed. The predictive ability of the markers was assessed through areas under the corresponding ROC curves, which were estimated by 95 % confidence intervals. Optimal cutoff for each of the markers was considered those ones that corresponded to the sensitivity and specificity values that minimized the following expression: . For these cut-off sensitivity, specificity, positive predictive value, negative predictive value, positive likelihood ratio and negative likelihood ratio were obtained. These parameters were estimated by 95 % confidence. A hypothesis test was considered statistically significant when the corresponding p-value was less than .05 and the obtained area under the two ROC curves were also compared.
Results Figure 110 shows the variables of the study in the groups defined as presence or absence of renal failure. The behavior of the variables analyzed is similar in both study groups. Conclusion NGAL is a good marker of early acute renal injury in patients after cardiac surgery and it did not show statistically significant differences when comparing urine vs. plasma levels. 
New clinical criteria of sepsis have sufficient specificity and high sensitivity in patients receiving anticancer therapy.
Traumatic brain injury (TBI) doesn't seem to be a single insult with a monophasic resolution. Recently, degenerative mechanisms have been suggested to occur in the chronic phase and could constituted "tertiary" lesions [1] . These degenerative phenomena can potentially have a worsening impact on the long-term functional prognosis.
The objective of this prospective study was to longitudinally evaluate (1) white and grey matter structures volumes measured from T1 three-dimensional (3D) and (2) white matter integrity assessed from diffusion tensor imaging (DTI) in severe TBI. Method 20 severe TBI (37 ± 16 yrs) and 12 healthy volunteers (HV; 42 ± 6 yrs) underwent multimodal magnetic resonance imaging in the subacute phase (within 21 ± 8 days after injury). A longitudinal follow-up was obtained for all of them at the chronic phase of injury (median 64 ± 16 months after injury) together with neuropsychological assessments. Longitudinal imaging changes were assessed using cortical volumetric reconstruction and segmentation of white and deep grey matter structures with Freesurfer [2] ; cortical sulci were automatically reconstructed and identified with Brainvisa software, and a voxelbased DTI analysis was performed with Comasoft. The Extended GOS (GOSE) was used to classify at 5 years the TBI subjects into " good" (GOSE 6-7; n = 11) and "intermediate" (GOSE 3-5; n = 9) recovery. Cortical morphometry and fractional anisotropy (FA) derived from DTI were used with linear mixed effects models to link changes to behaviour status.
At baseline, there were no volumetric differences between the 3 groups (GOSE 3-5; GOSE 6-7; HV). At 5 years, patients with TBI demonstrated a significant volumetric reduction of the whole white matter (-10 ± 4 %; P < 0.01), and of the deep grey matter structures (-13 ± 10 %; P < 0.03). In contrast, HV did not present any significant change over the same period. Specifically, direct comparisons between patient groups revealed that over time GOSE 3-5 showed greater atrophy than GOSE 6-7 in the parietal lobe (-5 ± 2 vs. -3 ± 5 % respectively; P < 0.001), brain stem (-12 ± 6 vs. -6 ± 7 %; P < 0.006), corpus callosum (-19 ± 19 vs. -10 ± 15 %; P < 0.01), and cingulate (-7 ± 5 vs. -2 ± 6 %; P < 0.023). This was associated with higher depth mean on sulci data. Furthermore, FA was lower at the first MRI in GOSE 3-5 group in the same regions.Finally, neuropsychological score (Z-score) correlated significantly with the volume loss in these anatomical regions.
We observed a strong correlation between neuropsychological scores and morphometric changes over time suggesting (1) occurrence of tertiary lesions and (2) that lesions location influence functional outcome. These data provide further insight into early and late pathophysiology of cognitive dysfunctions after TBI. Objectives
The goal of this study was to assess the pharmacokinetics of dexmedetomidine in the PICU settings during the prolonged infusion to assess the influence of routinely collected covariates on underlying PK parameters.
Thirty eight patients were enrolled into the study. Continuous intravenous infusion of DEX was initiated at the rate of 0.8 μg/kg/h following by gradual increase or decrease to keep the level of sedation between 7 and 14 points in the Cook Scale. Blood samples for PK assessment (2.0 mL) were collected from the arterial catheter. The analysis was made for the concentrations obtained at two occasions: first from 0 to 24 hr after infusion initiation and second from 0 to 8 hr after infusion end. Data analysis was conducted using WINBUGS software With informative literature priors.
The incorporation of time-depended (different between two occasions) PK parameters improved the model. The typical value of the volume of the central compartment (V 1 ) scaled to 70 kg was 52 L, whereas the volume of the peripheral compartment was slightly higher (V 2 = 70 L). The typical systemic clearance (CL) of DEX and the distribution clearance (Q) were 41.6 L/h and 56.8 L/h for a patient with a weight of 70 kg. The IIV estimated for the CL, Q, and V 1 and V 2 , were 56 %, 83 %, 152 %, 68 % with a strong correlation (0.7) between Q and V 1 . Those values are consistent with literature parameters in children and adults and are very close to the priors used. It was observed that volume of distribution and clearance is 1.5-fold and 1.3-fold, respectively higher during the second occasion. Conclusions Population PK model was successfully developed to describe the time course and variability of dexmedetomidine in PICU patients using allometric principles and clearance maturation model. More data is needed to fully confirm clinical significance of the phenomenon of an increase in the volume of distribution and clearance after infusion cessation. The disease status described by PRISM score, the duration of infusion, gender, body weight and age were not found to be independent significant covariates in this study.
CRRT are being used increasingly in the intensive care unit, not only for renal indications but also other organ-supportive strategies. Although early initiation of RRT is not clearly associated with benefit, avoiding or delaying RRT is associated with higher mortality and increased hospital/ICU lengths of stay Objectives To describe the use of CRRT for the treatment of non-renal metabolic acidosis in a cardiothoracic intensive care unit.
We performed a retrospective observational study including all patients admitted to level 3 areas requiring CRRT for refractory metabolic acidosis at Harefield Hospital during 2015, i.e. pH less than 7.15 and base deficit less than or equal to -8 mmol/L. This population included patients admitted after cardiac and thoracic surgery, heart or lung transplantation, mechanical circulatory devices, out of hospital cardiac arrests (OOHCA) and medical admissions from the cardiology or cardio-thoracic surgical wards. Demographic variables were collected, along with the timing and duration of CRRT.
Of the 1829 patients admitted to level 3 areas at Harefield Hospital during 2015, 229 (12.5 %), required CRRT during their admission. 134 (58.5 %) of those patients were initiated on CRRT due to refractory metabolic acidosis. The median age of this group was 61 years: 70.1 % were male, 47.8 % hypertensive and 19.4 % diabetic. Most patients (113 patients, 84.3 %) were haemodynamically unstable, defined as the need for one inotropic drug at a high dose or the combination of two or more vasoactive drugs. The reason for admission also differed from the general CRRT group, with a higher frequency of heart transplantations and OOHCA, as shown in Table 87 and Fig. 113 . Time from admission to ITU to initiation of CRRT was shorter at 1 day in the refractory metabolic acidosis CRRT group vs. 4 days in the general CRRT group. The ITU mortality in the study group was 42.5 % vs. 36.2 % in the general CRRT group.
CRRT for refractory metabolic acidosis in the context of cardiac instability is used in the critically ill patient as an adjunct strategy and is applied earlier than CRRT initiated for other indications.
Respective proportions of final etiologies are disparate in cohorts of cardiac arrest patients, depending on examined population and diagnostic algorithms. In particular, incidence and characteristics of sudden unexplained death (SUD) are debated. We aimed at describing etiologies in a large cohort of out-of-hospital cardiac arrest (OHCA) patients, in order to characterize victims without identified diagnosis.
We analyzed data from our prospective registry of OHCA patients admitted between January 2000 and December 2014. Initial diagnostic strategy included coronary angiography, brain and chest CT scan. This was completed by an extensive diagnostic strategy, encompassing biological and toxicological tests, repeated electrocardiograms and echocardiography, MRI, Holter monitoring and endocavitary explorations. Two independent investigators reviewed each final diagnosis. Baseline characteristics were compared between subgroups of patients with chi-square test and Mann-Whitney test, as appropriate. One-year mortality was compared between subgroups using univariate Kaplan-Meier curves.
Over the study period, 1,857 patients were admitted in our unit after a resuscitated OHCA. The event was related to a non-cardiac and a cardiac cause in 526 (30.7 %) and 1,057 (61.8 %) patients, respectively. The main cause of cardiac related OHCA was ischemic heart disease (78,4 %) while non-structural cardiomyopathies accounted for only 2,2 %. No diagnosis was evidenced in 127 (7.4 %) patients. In these SUD patients, baseline characteristics and one-year survival of patients under 35y were similar to those with identified non-structural cardiomyopathy.
We observed that ischemic heart disease was by far the most common cause of cardiac arrest, while non-structural cardiomyopathies accounted for a very low part of diagnosis. Young patients victims of a sudden unexplained death shared similar baseline characteristics and outcome with patients with non-structural cardiomyopathies. Focusing on this subgroup of patients for further investigations and follow-up may help in managing themselves and their relatives.
Note: This abstract has been previously published and is available at [1] . It is included here as a complete record of the abstracts from the conference.
Patients after cardiac surgery are prone to develop postoperative pulmonary complication (PPCs), which are currently diagnosed by chest Xray (CXR). LUS may provide accurate diagnostic information in patients with acute respiratory distress [1] . The role of LUS in detecting PPCs in patients after cardiac surgery has yet to be determined.
To compare the rates of PPCs detected by LUS -and CXR in patients after cardiac surgery admitted to ICU. Additionally, we assessed the inter-observer agreement for LUS and compared the time it takes to perform LUS and CXR. Method This is a prospective observational single centre study. The study was approved by the institutional review board. On admission to the ICU, 
Respiratory infection is a common complication in ICU patients admitted after a cardiac arrest. Amoxicillin-clavulanate is used as empirical antibiotic therapy in these patients to prevent aspiration pneumonia. However, recent studies have shown a resistance rate up to 15 %.
To describe the resistance pattern of microorganisms isolated from bronchial sample of patients admitted to the ICU after a resuscitated cardiac arrest. To assess the appropriate empiric antibiotic therapy.
Prospective, observational study from 2013 to 2015. We included all patients admitted in the ICU after a recovered out-of-hospital cardiac arrest and all patients with an in-of-hospital cardiac arrest admitted in the hospital less than 48 hours and without previous administration of antibiotics. We took samples of tracheobronchial secretions through the endotracheal tube in all patients within the first three days of admission. Demographic information, comorbidities, performing of therapeutic hypothermia, empirical antibiotic therapy administered and the result of bronchial aspirates culture were collected. Empiric antibiotic therapy was considered adequate when at least one effective antibiotic was administered within the first 24 hours of ICU admission. 
In both groups the percentage of the initial dose of norepinephrine was reduced 96 hours septic shock onset, higher in group 2 (61 %) than group 1 (54 %). ICU mortality in the series of patients globally was 19 %, higher percentage in group 1 (23 %) than in group 2 (16 %). Hospital mortality showed an increase of 8 points in group 1 and 10 points in group 2; the global hospital mortality was 29 %.
In refractory septic shock patients, after the SSC measures correctly applied in time, an early horizontal treatment with HFVVCHV and HFVVCVHV could improve the prognosis.
Neutrophil gelatinase-associated lipocalin (NGAL) is used as a biomarker of acute kidney injury (AKI), measured in serum and urine. Recently, serum NGAL has been reported as biomarker of mortality and organ dysfunction in sepsis and post cardiac arrest patients, which is related to systemic inflammation. Therefore, we measured serum NGAL in emergency department patients, and tried to assess which type of pathophysiology was related to increased serum NGAL.
To assess serum NGAL could be a biomarker of systemic inflammation in emergency department. Method Forty-four cases admitted emergency department were retrospectively analyzed. Serum NGAL, C-reactive protein (CRP), and white blood cell count (WBC) were compared between 2 groups (estimated glomerular filtration rate (eGFR) >40 mL/min/1.73 m 2 or not). Correlation analysis was also performed between serum NGAL and others.
Median age was 64 y.o., 61 % of patients were male. Median value of serum NGAL was 83 ng/mL. The value of serum NGAL was significant difference between the groups of eGFR > 40 ng/mL and eGFR < 40 ng/ mL (80 ng/mL v.s. 163 ng/mL, P = 0.045). Serum NGAL and CRP were significantly correlated in the group of eGFR > 40 ng/mL (R = 0.650, P < 0.001).
Serum NGAL might reflects systemic inflammation with patient in emergency department. 
In comatose cardiac arrest survivors, the extent of myocardial damage and cardiovascular instability have an important role in the course of developing post cardiac arrest syndrome and predicting long-term outcome. Recent clinical studies have revealed that inhaled xenon provides beneficial cardiovascular effect and mitigate ischemic brain injury in out-of-hospital cardiac arrest (OHCA) patients [1, 2] .
The purpose of this study was to assess the effect of xenon inhalation on myocardial ischemic damage and left ventricular function after OHCA. Method A total of 110 comatose patients who had experienced OHCA were randomized to receive either inhaled xenon combined with hypothermia (33°C) for 24 hours (n = 55 in the xenon group) or hypothermia treatment alone (n = 55 in the control group). Whenever indicated, coronary angiography and percutaneous interventions were performed before intensive care unit admission or later during hospital stay. Xenon was administered with at least 40 % end-tidal concentration and completed at start of rewarming. Troponin-T (TnT) was measured at hospital admission, and at 24 h, 48 h and 72 h post cardiac arrest. Left ventricular function was assessed with echocardiography by cardiologist at intensive care arrival and at 24 hours after completing rewarming.
Among the 110 patients comprehensive TnT measurements were available from 51 xenon patients (median age 63) and 53 control patients (median age 60). Complete echocardiographic data was available on 18 xenon and 20 control patients. The number of STelevation myocardial infarction and primary coronary intervention, time for return of spontaneous circulation, cardiovascular medication among other baseline characteristics did not differ significantly between the groups. 
Inhaled xenon in combination with mild therapeutic hypothermia may protect against ischemic myocardial injury as demonstrated by significantly attenuated short-term TnT release and better left ventricular function when compared with hypothermia treatment alone. These observations suggest that inhaled xenon may provide cardioprotective effect in OHCA patients.
Both NT-proBNP and Doppler echocardiography have been approved in the diagnosis of heart failure. In our Study, we compared the contribution of the NT-proBNP levels with the Doppler echocardiography findings in the diagnosis of decompensated congestive leftheart failure (CHF) in patients with acute dyspnea.
It was a prospective, observation al study at the teaching department of emergency and intensive care in the regional hospital of Zaghouan, including patients with severe dyspnea over six months. All patients underwent physical examination, 12-lead ECG, RX Thorax, NT-ProBNP essay and echocardiography by an attending cardiologist on admission. Note: This abstract has been previously published and is available at [1] . It is included here as a complete record of the abstracts from the conference.
The predictive mortality of major trauma patients in the South Korea is 35-40 %. High mortality late of major trauma in the South Korea is due to underdevelopment of prehospital management and transport system, hospital care system, and insufficient supporting system of government policy. Establishment and operation of level I trauma center and management of major trauma patients in the South Korea is at an early stage. In house trauma surgeon´s role in the initial resuscitation of patient with major trauma is very important. 
Fluid resuscitation is a crucial component of initial resuscitation in major burn patients to avoid early mortality. Large amount of intravenous fluids are given during this period of time no matter Parkland formula or other formulae are used as the fluid resuscitation guidelines. Furthermore, it is a trend to administrate even larger amount of intravenous fluids in these years, which is known as "fluid creep" phenomenon [1] . However, excessive intravenous fluids would produce generalized and lung edema, which may preclude wound healing and prolong intubation. Besides, no guideline tells us how to adjust intravenous fluids after the first 48 hours.
We investigate the impact of total intravenous fluids given in the first week to prognosis. Method This is a retrospective cohort study. Patients who injured in Taiwan Fig. 114 ].
As the results, Group A patients had significantly less days of mechanical ventilation than Group B patients, while length of ICU stay, length of hospitalization, sepsis insults, and organ dysfunctions were all similar in 2 groups [Table 95 ].
We concluded that a more restrictive fluid resuscitation strategy might shorten the period of mechanical ventilation in major burn patients. The aggressive resuscitation fluids should be tapered down quickly after 72 hours. Results 85 patients were included. In Table 96 we described the characteristics of the study population. The beginning of cardiopulmonary resuscitation (CPR) maneuvers were immediate on ward, according to IHCA protocol. The arrival of IHCA team was less than 5 minutes in all cases. Figure 117 shows the distribution of NEWS in the IHCA analyzed. In 43.5 % of cases there are not enough information to make a NEWS. In the remaining patients it was able to perform the NEWS although we could only obtain all data in 6.5 % of patients, in the remaining 50 % of IHCA in which was calculated the NEWS some data (vital sings) was missing. Respiratory rate and oxygen saturations were the most frequent missed data. It could be probably underestimating the NEWS performed. Figure 118 shows the relationship between a greater hospital mortality and a higher NEWS.
Conclusions Abnormal vital signs are common within 24 hours before IHCA events on hospital wards. A suitable recording vital signs could be useful to alert patients at risk and anticipate in the detection of IHCA.
Introduction We conducted a retrospective review of all our ICU admissions post cardiac arrest to identify OOHVF survivors and compare our own care in the post TTM era with ILCOR standards of care and unit guidelines.
Objectives To analyse the electronic record of all OOHVF patients admitted to our unit between October 2014 and July 2015 and identify Fig. 116 (abstract A303) . National Early Warning Score (NEWS) Use of EEG and SSEP to assist prognostication common on our unit in prolonged coma. The incidence of seizures is common in the post TTM phase.
Introduction Sudden cardiac death represents a major health problem. In adults, the prevalence of out of hospital cardiac arrests (OHCA) attended by the emergency medical services is 75 per 100,000. Mortality remains high, and exceeds 90 %. It is well documented that patients with a shockable rhythm have a consistently higher survival than those whose initial cardiac rhythm is non-shockable (1).
Objectives The aim of this study was to look at outcome from cardiac arrests admitted to a tertiary referral service and assess whether the presentation of a shockable rhythm was associated with a better prognosis.
Methods A retrospective case note review over a one year period of all patients admitted to the Golden Jubilee National hospital with an OHCA with initial rhythm being ventricular tachycardia (VT) or ventricular fibrillation (VF) were included. We looked at cause of cardiac arrest, ICU survival and dependance upon survival, age and length of stay.
Results Sixty three patients were identified, and a full data set obtained for 59. Median age of admission was 59 years, with age range from 26 years to 83 years. All presenting rhythms were either VF or VT. 58 % of this cohort of patients survived post cardiac arrest. Median length of stay was 5 days (IQ range 1-14days). Of the 34patients that survived, 32 of these patients went on to live an independant life. Of the 25patients that died, all of these patients died during their admission to Intensive Care and did not die post ICU discharge. Interestingly, patients whose cause of cardiac arrest was purely arrhythmogenic all survived to hospital discharge, although these numbers are small (n = 11).
Conclusions Mortality from cardiac arrest is high and places a huge burden on ICU services. The median length of stay for OHCA patients is 5 days, and with patient numbers in this study is attributable to one ICU bed per day. Their length of stay is thought to quantify the difficulties in prognostication of survival in this cohort of patients, particularly when it comes to the secondary brain injury. Introduction Quantity of blood loss during liver resection is known to be a predictor for poor clinical outcome (1). One generally used approach for minimization of blood loss is to decrease central venous pressure (CVP) (2) . The rationale for this concept is that low CVP is supposed to reduce hepatic blood congestion. Objectives In order to assess blood congestion of the liver we aimed to evaluate the influence of a positive-end-expiratory-pressure (PEEP) and positioning of the patient on CVP and venous hepatic blood flow in patients undergoing liver resection. Further, we analyzed correlation between CVP and venous hepatic blood flow parameters. , p = 0,021 respectively) whereas no significant changes of flow velocity of the portal vein occurred in any of the maneuvers. No correlations between CVP and diameters or flow velocities of the right hepatic and the portal vein were found. Conclusions Changes of central venous pressure due to changes of PEEP and positioning were not correlated with changes of venous liver blood flow. Therefore, those strategies aiming for low central venous pressure maneuvers in liver resection are not supported by these results.
Introduction There are few data reporting which hemodynamic variables are associated with outcome 1 Despite the widespread of echocardiography, indices to assess the cardiac function in ICU are the same used in the cardiology ward although they have not been validated. Systolic longitudinal function (MAPSE) and total isovolumic time (t-IVT), although under recognized, are sensitive and early marker of myocardial perfusion mismatch and, the latter, of cardiac output(CO) and VO2 changes in patients with coronary artery disease and chronic heart failure1.
Objectives We sought to determine the correlation between echocardiographic systo-diastolic indices, including t-IVT and MAPSE, and hemodynamic parameters and their outcome value on 30-days mortality in the cardiothoracic ICU. Methods The local ethical committee approved the study. We retrospectively analyzed data for patients (n = 131; age 59 ± 18.3; 61.3 % male) admitted to ICU requiring an echocardiography from January to August 2012. Patients were divided in 3 groups: 55 patients had severe respiratory failure; 40 patients after cardiac surgery and 36 had primary cardiocirculatory failure. In addition to demographic and hemodynamic parameters, echocardiographic indices included: MAPSE (M-mode on the four portion of the mitral annulus), ejection fraction(EF), fractional shortening(FS), E/ A, E/E', Doppler assessment ejection time (ET-aortic forward flow)& filling time(FT-mitral inflow), t-IVT (calculated as [60-(total ET + total FT)]) and SV&CO derived from aortic VTI. Continuous variables were compared using the Wilcoxon rank-sum test, categorical variables were compared using the Pearson χ2 test. The significance of differences in mortality between groups was assessed using the log-rank test.
Results In univariate analysis a strong inverse correlation was found between t-IVT and MAPSE and SV&CO. In the univariate logistic analysis, SV&CO, MAPSE and t-IVT were all good predictors of the 30 days outcome. In the multivariate model, along with SAPS II (HR 1.07, IC 95 %1.05-1.098), t-IVT (HR 5.1, IC 95 % 2. [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] 8) and MAPSE (HR 0.17, IC95%0.02 -0.97)showed to be independent predictors of mortality. EF and FS do not correlate with other echocardiographic and hemodynamic parameters and no relation with outcome was found. Conclusions This is the first study investigating the role of those echocardiographic indices in the ICU cohort. EF, a validated index to stratify patients according to the systolic function, failed to correlate with hemodynamic parameters and outcome. t-IVT, index of systodiastolic interaction correlating with the consequences, in term of cardiac output, of those variations, and MAPSE resulted the most sensitive parameters reflecting cardiac efficiency and outcome. Introduction To improve accessibility, central vein catheterization in upper body region classically done in trendelenburg position but it may impose potential disadvantages to respiratory system and disturb physiologic status of many other organs. Passive leg raising (PLR), a simple maneuver , widely used to improve cardiac preload and to predict patients' volume responsiveness could be an alternative.
Objectives In this study, we evaluated the effect of PLR maneuver on right internal jugular vein (RIJV) diameter in intensive care unit patients under mechanical ventilation.
Methods As a prospective study , twenty patients under synchronized intermittent mandatory ventilation (SIMV) without valvular heart problem or heart failure and acute respiratory distress syndrome were studied. RIJV diameter was measured with bedside color Doppler sonography of neck , first in supine position and then for second and third measurement, after 30°PLR for 1 and 10 minutes. Measurements were at the end of inspiratory cycle with positive end expiratory pressure of 5. We chose 30°PLR to keep bedridden patients away from possible damage that may be induced with higher upward slope.
Results RIJV diameter increased with 30°PLR maneuver , more prominent after 1 minute in comparison to 10 th minute time point . Mean RIJV diameter was 11.66 mm in supine, 13.37 mm (P = 0.001) and 12.95 mm (P = 0.005), 1 and 10 minutes after 30°PLR maneuver respectively . Increments in diameter were slightly lower than that associated with trendelenburg position reported in other studies . No complication was noted.
Conclusions PLR maneuver can be safely considered as an alternative to trendelenberg position to increase internal jugular vein diameter in mechanically ventilated patients. Introduction Electrical impedance tomography (EIT) is a noninvasive and radiation free bedside monitoring technology, primarily used to detect ventilation disorders. First experimental data in animals suggests that measurement of central hemodynamics within the descending aorta might become possible with EIT. 1 To achieve this goal, it is first necessary to determine within the EIT images the exact location of an individual´s aorta.
Objectives The aim of this study was to improve and validate an algorithm to automatically detect the aorta by EIT using a hypertonic saline bolus. 2 Methods Ten domestic pigs were anesthetized and mechanically ventilated. A bolus of hypertonic saline (10 mL, 20 %), with a higher conductivity than blood was administered into the ascending aorta while EIT data were recorded. The resulting EIT images were analyzed pixel by pixel to identify the aortic pixel (p A ), in which the bolus caused the highest transient impedance peak in time (Fig. 120) . After completion of the EIT measurements a thoracic computed tomography scan (CT) was performed for each pig. The CT-images were segmented individually for the relevant anatomical structures. EIT images were reconstructed using the GREIT model, based on the individual´s thoracic contours derived from the segmented CTimages. 3 The resulting spatial resolution of EIT images was 3 mm / pixel.
The location of the aorta could be detected by EIT in all animals, showing a mean offset of 15 ± 7.5 mm when compared to the center of the true anatomical location identified by CT (Fig. 121) .
Conclusions It is possible to detect the aorta by EIT using an intraaortic bolus of hypertonic saline. There is a misalignment between the location of the aorta identified by EIT and CT. The significance of this offset for an accurate measurement of fluid responsiveness needs to be determined in further studies. Table 100 for all values) and the concordance rate was 100 % (see Fig. 122 ).
Conclusions CO EPBF performed well during hypercapnia, both during different types of low minute ventilation and increased dead space. The performance was maintained during major changes in cardiac output and trending was excellent. These results indicate that the capnodynamic method should be tested during lung protective ventilation with permissive hypercapnia and even in laparoscopic surgery.
Introduction Echocardiography in the setting of the critically ill patient might be hindered due to poor transthoracic acoustic window. The modified subcostal window, which is obtained from an extrathoracic region, gives us a short-axis parasternal-like view, at the level of the great vessels.
Objectives To address the consistency of cardiac output values, measured from the modified subcostal view as compared with those obtained from a transthoracic approach.
Methods In 54 consecutive critically-ill patients undergoing transthoracic ecocardiography (Philips Sparq) for both initial diagnosis of shock or subsequent hemodynamic monitoring, velocity time integral of pulsed wave Doppler of the left ventricular outflow tract (VTI LVOT ) and the pulmonary flow (VTI Pu-Ps and VTI Pu-Ms ) were measured from the apical four-chamber view, the short-axis paraesternal and modified subcostal views respectively. Results were analyzed with predictive performance test and the consistency analysis. Interobserver reproducibility analysis was assessed in 20 patients with repeated measurements by two experienced physicians using the intraclass correlation coefficient (ICC Introduction Transcranial cerebral oximetry is a non-invasive method to monitor the changes in the cerebral oxygen metabolism. It is a near-infrared spectroscopy method that uses multi-wavelength radiation between 690-1100 nm spectrum. This photons can pass skin, bone, brain and cerebrospinal fluid.
Objectives The aim of the study is to analyze the association of monitoring transcranial cerebral oximertry with morbidity and mortality in patients with postresuscitation syndrome.
Methods In this study we retrospectively analyzed the data of 23 patients with postresuscitation syndrome. Introduction Classically, central venous pressure (CVP) and pulmonary artery occlusion pressures (PAOPs) have been used as surrogates for volume measurements.However dynamic preload variables like as pulse pressure variations (PPV) and stroke volumen variations (SVV) could be very useful in hepatic postresection phase to optimize the volumen needed for the patients.
Objectives The aim of this study is to assess if is better to reduce postoperative complications, optimizing hemodynamic situation after hepatic resection guided by dynamic variables preload (PPV and SVV) versus using liberal fluid management.
Methods Experimental clinical trial, controlled, randomized, single blind, in patients undergoing hepatic resection. In both groups perioperative fluid restriction was done (5 ml/kg/hour of Ringer Lactate) until removal of the surgical specimen was performed. Affer that, two randomized groups were established. In the control group fluids (colloids) were administered until hemodiámica stability was achiveved and standard pressures were got (MAP > 65 mmHg CVP 8-14, urine output > 0.5 ml / kg / h). In the other group volume was administered until a SVV < 12 and a PPV < 14 and MAP > 65 mmHg were achieved. In both groups the volume administered to achieve quantified objectives and postoperative complications (nausea and vomiting, respiratory and infectious complications) was registred. Results 9 patients were enrolled in the GDT group and 10 patients in the control group. There were no statistically significant differences in preoperative variables. A statistically significant difference in the volume administered after resection in both groups (1290 +/-375 vs 128 +/-485.55, p < 0.01) was found. In the surgical time we found no correlation between VPP and CVP (r = 0,172, p = 0.656) and between the VSS and CVP (r = 0,243, p =0.492). We found very good ability to predict the Introduction Incidence of acute kidney injury in critically ill patients increases with chronic diseases, nephrotoxic drugs, and the use of contrast in diagnostic/therapeutic techniques. Contrast-associated acute kidney injury (CA-AKI) is strongly predictive of adverse outcomes.
Objectives To build a statistical predictive model to evaluate the probability of developing contrast-associated acute kidney injury in critical patients.
Methods This study has been endorsed by the Spanish Society of Intensive Critical and Emergency Care Medicine (SEMICYUC). Data were obtained in a prospective multicenter study in 33 Spanish Intensive Care Units, with a total of 1009 patients. The criteria used to define CA-AKI was the AKIN criteria: a rise of serum creatinine of ≥0.5 mg/dl or a 50 % relative rise in creatinine at 48-72 hours after contrast exposure. The predictive model has been developed employing a binary logistic regression using the software R. The ROC curve was obtained (Fig. 126 ) and the model was calibrated using this graph. From the model, we have generated a graphical nomogram (Fig. 127) to facilitate its use in a clinical environment. The nomogram includes the 4 variables shown to have prognostic value.
Results 12 % of the patients developed CA-AKI. Predicting factors were elevated APACHE II test score, hemoglobin and baseline serum creatinine, shock or acute myocardium infarct at admission, vasoactive drugs and diuretics at the moment of the contrast administration, and the following comorbidities: chronic heart failure and chronic kidney failure. Significant risk factors in the univariate analysis were selected for the predictive model (Table 102) . A bootstrap method was used to select the best subset of risk factors to avoid overfitting the data. The corresponding ROC curve of the model (Fig. 126) has an area under the curve of AUC = 0.75 (range 0.71-0-79). Conclusions A predictive model of CA-AKI has been developed. Predicting variables with prognostic value are the hemoglobin content, the APACHE II test score on admission and the use of vasoactive drugs and of diuretics. The corresponding nomogram allows for easy evaluation of the probability of developing CA-AKI in critical patients. Note: This abstract has been previously published and is available at [2] . It is included here as a complete record of the abstracts from the conference. , log rank p = 0.0009 (Fig. 130) . CVVH blood flow was higher and more stable throughout sessions in the E group (p < 0.001) (Fig. 131) . Median heparin dose used for anticoagulation was higher in the C group (p < 0.001) (Fig. 132 ) but without effect on the activated partial thromboplastin time (aPTT) all over the session. Conclusions In our experience, connection of CVVH lines to ECMO is associated with an increased lifespan of the CVVH circuit, the direct connection of CVVH circuit to ECMO allowing higher blood flow. Introduction Volume resuscitation is the mainstay of treatment in most types of shock, especially in hypovolemic, hemorrhagic and septic shock [1, 2] . Although there has been an increasing amount of research within the last decade in order to evaluate the optimal amount and composition of fluids for volume resuscitation (e.g. colloids, crystalloids, red blood cell transfusion, albumin, fresh frozen plasma), results remain inconclusive and to some extent contradictive.
Objectives To evaluate the impact of amount and type of fluids administered on the use of renal replacement therapy (RRT) and outcome.
Methods Single-centred retrospective observational study analysing patient charts on the medical and surgical ICU of the University Hospital Basel from 2011 until 2015.
Results We retrospectively analysed type and amount of fluid administered within the first 72 hours after ICU admission to patients receiving continuous veno-venous hemodiafiltration (RRT) or hemodialysis in the surgical or medical ICU at Basel University hospital during a 5-year period. A total of 343 ICU patients underwent RRT from 1st January 2011 to 31st December 2015 (median duration of 3 days, interquartile range (IQR) 1-7 days). We found a significant difference comparing patient survival and patient death among age (p < 0.001), SAPS II score, total volume within the first 72 hours on the ICU, fluid balance in the second and Introduction High Flow Nasal Cannula (HFNC) is a non-invasive respiratory support that positively modifies clinical outcomes of hypoxemic Acute Respiratory Failure (ARF) patients [1] . Available data suggest that HFNC support induces a number of physiological benefits over conventional oxygen therapy, however little is known about the correlation between physiological effects of HFNC and flow rates.
Objective Aim of this study was to disclose whether physiological effects of HFNC linearly or non-linearly follow increased flow rates.
Methods We performed a prospective randomized cross-over study on 10 hypoxemic ARF patients with PaO 2 /FiO 2 ≤ 300 mmHg while on non-invasive oxygen support. FiO 2 was set to obtain SpO 2 of 90-95 % by facial mask and left unchanged throughout the study. Patients underwent four randomized steps, lasting 20 minutes each: facial mask (gas flow 12 L/min) vs. HFNC at 30, 45 and 60 L/min. During all phases we assessed gas exchange, lung volumes by electrical impedance tomography and inspiratory effort by esophageal pressure. Data measured during the 4 steps were compared using one-way ANOVA while best fitting of linear vs. non-linear correlations was assessed by lower Akaike´s information criterion (AIC) value.
Results Patients were 61 ± 10 year-old, five were female and PaO 2 / FiO 2 at enrollment was 171 ± 44 mmHg. At higher flow rates (Table 107) : PaO 2 improved (p < 0.001) while pH and PaCO 2 didn't vary; end-expiratory lung volume (ΔEELV) increased (p < 0.05) and peak expiratory flow (PEF) decreased (<0.05) suggesting positive expiratory pressure effect by increased expiratory resistance and/or improved respiratory system compliance; respiratory rate (RR) decreased (p < 0.001) and tidal volume (Vt) didn't change (p > 0.05), anyway yielding decreased minute ventilation (MV) (p < 0.01) and corrected minute ventilation (MV corr = MV*PaCO 2 /40 mmHg) (p < 0.01), indicating enhanced CO 2 removal; finally, esophageal pressure swing (ΔPes) and pressure-time product (PTPes) decreased (p < 0.01 for both). AIC for linear correlation with flow rates was lower for PaO 2 , RR, ΔEELV and PEF, as if improved aeration and its effects on oxygenation constantly increase with flow; while non-linear AIC was lower for MV, MV corr , ΔPes and PTPes, possibly suggesting that most of the improvement in CO 2 wash-out from upper airway dead space and its consequences on patient's effort is already obtained at 30 L/min. Conclusions HFNC induces multiple beneficial physiologic effects that might delay respiratory decompensation and improve clinical outcomes. However, not all effects linearly increase with HFNC flow so that its selection might be personalized to target the most clinically relevant physiologic derangement.
Introduction CIP appears frequently in ICU and can occur in up to 25 % of patients. After extubation CIP causes poor airway clearance due to respiratory muscle weakness and can lead to respiratory failure and reintubation. Reintubation, which increases severity of illness, is an independent risk of nosocomial pneumonia, increased hospital stay and mortality. Currently, standard treatment includes respiratory physiotherapy with manual assisted cough. However respiratory failures still occurs in 30 % of patients within 48 hours after planned extubation. Though we conducted a study evaluating, in patients with CIP, the efficiency of MI-E device in the prevention of respiratory failure during 48 hours after extubation. MI-E is a non-invasive technic to assist respiratory physiotherapy which aims to suction tracheal mucus. MI-E has been evaluated for neuromuscular disease patients, and it has been shown to increase peak expiratory flow and to improve airway clearance. Objectives Primary outcome: Incidence of respiratory failure after extubation Secondary outcomes:
reintubation rate mean length of stay in ICU mortality at day 28
Methods In a medical ICU of a university hospital we conducted a prospective randomized open study in two parallel groups. All intubated patients were screened with a Medical Research Council (MRC) muscular test. Patients were diagnosed CIP if the MRC score was equal or under 48/60. All patients with CIP and without exclusion criteria were randomized in the study. During the treatment period, patients received two daily session of MI-E plus manually assisted coughing or standard treatment (manually assisted coughing).
Results 123 patients were included in three years, 62 in the standard group, and 61 in the MI-E group. There was no difference between the two groups at baseline. The results show no difference for the primary outcome (p 0,6022): 7/62 respiratory failures in the standard group (11,5 %), 10/61 in the MI-E group (16,4 %). For the secondary outcomes, we found no statistical difference concerning reintubation (3.6 % vs 7 %), mean length of stay in ICU (6,5 vs 7,9 days) and mortality at day 28 (14.8 % vs 18.3 %) Conclusions The study demonstrated no superiority of the MI-E device in the prevention of post-extubation respiratory failure for ICU patients with CIP.
Introduction The noise is associated with morbidity and mortality in critically ill patients, related to sleep fragmentation and delirium primarily (1-3). The ventilation devices can generate noise, with further impact on the effectiveness of the technique. An example is the noninvasive CPAP devices and high nasal flow, widely used in ICU (4) .
Objectives To evaluate the intensity of the noise level as perceived by the patient and to compare the difference in noise intensity between several different devices for non-invasive respiratory support at different levels of assistance.
Methods Made in patients with acute respiratory failure, and pulmonary dummy-simulator with spontaneous breathing, were connected to differents device CPAP with 5, 10, 12.5, and 15cmH2O, as high flow system 35-110 L/min. We studied 3 models of noninvasive CPAP (Wisperflow/Vital Signs; Ventumask® HF, Starmed, Intersurgical; valve-Boussignac®, Vigon); device of high flow: Optiflow®-MR850 with Whisperflow high flow generator, and Airvo2® Fisher & Paykel. The flow is measured with Ohmeda 5410 Volume Monitor. The intensity of sound is measured at ear level using Speedlink SL-8691-SBK-01 microphones. The audio signal is recorded for 60 seconds in wav format (22,050 KHz). Three measurements were performed for each level of assistance and devices. The noise intensity was obtained from the spectral power (PSD) of sound pressure waves, hanning windows and fast Fourier transform was used. PSD is reported in decibels sound pressure level (dB SPL)/KHz, where: dB SPL = 20 log(P/P0), P is intensity of the stimulus, and P0 the reference's intensity at the threshold of human hearing at the frequency of 1 kHz. Analysis was perfomed with software Matlab R2008a of the maximum and mean (SD) spectral power/frequency of each signal. The comparisons are performed by analysis of variance for multiple samples. After propensity score matching (23 HNFC patients vs 23 MV patients), no significant differences were observed in RAGE, SP-D, ANG-2, IL6, IL8, IL33 and ST2 between matched patients who were treated with HFNC at ARDS onset and those who were intubated. After matching, no differences in mortality or length of stay were observed. All biomarkers with the exception of IL33 were higher in both groups of matched ARDS patients than in both control groups.
Conclusions Acute hypoxemic patients with bilateral infiltrates treated with HFNC present a similar pattern of biomarkers of inflammation and injury compared with those ARDS patients who were directly mechanically ventilated. The results suggest that these HFNC patients may be considered as ARDS patients. Changes in mean blood pressure, heart rate, respiratory rate and PaO2/FiO2 values induced by the procedure did not reach significance (P > 0.05).
Conclusions Application of the HFNC to be a safe and effective alternative to intubation for accomplishing bronchoscopy with BAL in patients with hypoxemic ARF. Conclusions HFNC can ameliorate the symptom of the mild to moderate ARDS, but the effect in the severe ARDS isn't certain. So, the symptom of patients must have been monitored frequently in order to avoid missing the chance of intubation.
Introduction Oxygen therapy is one of the most popular treatments in the ICU. We typically use oxygen masks to give oxygen to patients who breathe spontaneously. However, ordinary oxygen masks have a risk of CO 2 rebreathing-especially at lower flow rates (less than 5 l/ min). For our bench study, we investigated the use of an open face mask (Atom Medical, Japan) in alleviating the risk of CO 2 rebreathing while still delivering a relatively high F I O 2 . The result showed that the open face mask mitigated this safety concern. It provided a 10 % higher of inspired oxygen (F I O 2 ) and a lower inspired carbon dioxide (F I CO 2 ) as 60-100 % reduction than an ordinary mask (IMJ, Japan). That result was presented in the congress of WFSICCM.
Objective We hypothesize that the use of an open face mask is better for our spontaneous breathing patients who need oxygen than an ordinary mask because it can give patients better oxygenation and CO 2 clearance. Methods This study was performed among 22 ICU patients who suffered from mild respiratory failure. We applied both masks (ordinary and open face mask) with various flow rates: 5, 4, 3, 2, 1 and 0.5 l/ min for three minutes, respectively. First, we tried ordinary masks with 5 l/min for 15 minutes and decreased the flow to 0.5 l/min every three minutes. The patients whose SpO 2 achieved 100 % with 5 l/min of oxygen were excluded. Respiratory parameters (SpO 2 , respiratory rate: RR; F I CO 2 , end-tidal CO 2 : EtCO 2 ) were recorded at the end of each flow rate. F I CO 2 and EtCO 2 were measured via Capnostream TM (Medtronic, US). Next, we investigated an open face mask in the same manner: applying 5 l/min of oxygen for 15 minutes. Finally, we checked patient satisfaction with each mask using a visual analogue scale (VAS: 0-best, 5-worst) at the end of each trial. We used the Wilcoxon matched-pairs signedranks test to detect significant differences in the two groups.
Results Data from 12 patients were analysed. The median age was 66 (range: 50-87). Most of the patents (92 %) underwent an operation (cardiovascular surgery: 67 %, orthopaedic surgery: 17 %, abdominal surgery: 8.3 %). The patient who did not receive an operation had congestive heart failure.
The group using open face masks showed higher SpO 2 (Mean: 97.8 ± 0.47 % vs 97.5 ± 0.71 %, p < 0.01) and lower F I CO 2 (0.76 ± 0.16 % vs 2.00 ± 0.77 %, p < 0.01) and EtCO 2 (35.5 ± 0.36 % vs 37.0 ± 0.78 %, p < 0.01). The respiratory rate did not reveal any significant difference (20.19 ± 0.75/min vs 20.85 ± 0.68/min, p = 0.15). Patient satisfaction with the open face mask was superior to an ordinary oxygen mask (VAS 2.42 ± 1.08 vs 3.25 ± 1.14, p < 0.01).
Conclusion Open face masks can provide better oxygenation and reduce CO 2 rebreathing for the ICU patients in comparison with ordinary masks.
Methods Prospective collected database was conducted of from December 2014 to April 2016. Weak cough was defined by PEF < 60 L/min. The PEF was measured with Cosmed Pony Graphic® spirometer v.4.0 S-CZ before extubation, for the patients mechanically ventilated > 24 h, and without tracheostomy, who passed successfully a sponyaneus breathing trial (SBT) at least of 30 min of pressure support at 5-8 cmH2O, CPAP, or T-T. The patients were then extubated regardless the PEF. The patients with PEF > 60 L/min conventional oxygen therapy was applied, and groups at risk of extubation failure (PEF < 60 L/min) was applied randomly prophylactic CPAP, noninvasive ventilation (VNI BiLevel), or humidified high flow nasal cannula (HFNC). Extubation failure was defined by the need of reintubation within 48 h following extubation. We compared both groups of patients according to the PEF, and prophylactic assistance on groups patients with weak cough, on outcome extubation. Continuous variables were expressed as mean ± SD or median (IRQ) and categorical variables as absolute value and percentage. The comparison of continuous variables was performed by Student t test and Mann-Whitney test and comparison between categorical variables was performed by Fisher's exact test and Chi-square test.
Results 137 patients were studied, 89 males (65 %). The two groups of patients according to the PEF, were similar regarding age, APACHE II, underlying chronic disease and duration of mechanical ventilation before extubation. Prophylatic assistance was effectively applied to 72,1 % of patients with PEF < 60 L/min and 87,2 % for PEF > 60 L/ min. VNI was applied at 51,2 % (CPAP 18,6 % and BiLevel 32,6 %), Optiflow® 48,8 %. No significant differences were found between the prophylactic devices of assistance at risk group of extubation failure.
In the patients with PEF > 60 L/min, extubation failure rate was 12,8 %. There were not differences between diagnosis and extubation failure. Not differences in total stay in ICU between both groups. Conclusions Prophylactic non invasive assistance at extubation could reduce the risk of extubation failure in patients with a weak cough strength without increasing length of stay. It's could be applied to any mode and device (HFNC, CPAP or VNI).
Introduction Numerous studies have shown that a weak cough strength, if evaluated objectively before extubation by the measure of peak cough expiratory flow (PCEF), is a strong predictor of extubation failure. However, reported cut-off values depend on the device used for the measure. Measuring PCEF on the screen of the ventilator by its flow sensor seems easy to perform, without disconnecting the patient from the ventilator, and could provide a method available everywhere at the bedside.
Objectives This prospective study aimed to compare the measure of PCEF on the screen of the ventilator Servo i (Maquet, Solna, Sweden) to the measure obtained with an electronic flowmeter, the Piko-1 (Ferraris Respiratory, Hertford, UK), whose accuracy to predict extubation outcome has been previously reported, with an optimal cut-off value of 35 l/min [1] .
Methods The PCEF was measured by the respiratory therapist just before extubation for the patients mechanically ventilated for more than 24 hours and who passed successfully a spontaneous breathing trial of 30 minutes of pressure support at 8 cm H2O. The order of the measures with the two devices was changed after inclusion of half of the patients. The best value obtained from two measures was kept for the analysis.
Over one year 87 patients were eligible for the study; the measure of PCEF was impossible to achieve because of lack of understanding in 14 patients (16 %). Among the 73 patients included for the analysis, there was a significant correlation between the measures obtained with the Piko-1 and the Servo i (r s = 0.831; p < 0.01) (Fig. 135) . The linear regression line obtained predicts a cut-off value of PCEF on the Servo i at 60 l/min, corresponding to the value at 35 l/min previously determined with the Piko-1 [1] .
Conclusions The measure of PCEF just before extubation on the screen of the ventilator Servo i is easy to perform and well correlated with the measure performed by an electronic flowmeter Piko-1. This allows to propose a cut-off value of 60 l/min with the ventilator, below which the cough strength may be judged as weak.
Objectives To compare HFNC vs. NIV induced changes in inspiratory work of breathing assessed by the thickening fraction of the diaphragm (TFdi), and breathing pattern, hemodynamics, dyspnea and comfort.
Methods CF patients with acute exacerbation requiring ventilator support were ventilated with HFNC and NIV for 30 minutes in random order. TFdi was measured using ultrasound at baseline and at 25 minutes with each device. Pulse oximetry (SpO 2 ), transcutaneous CO 2 (PtcCO 2 ) were continuously recorded and respiratory rate, tidal volume (V T ) and minute ventilation (MV) measured by bio-impedance techniques; hemodynamics, dyspnea and comfort assessed by visual analog scales were also recorded. Results were compared using a Mann Whitney, 2 tailed test, and are expressed as mean (SD) with each intervention compared to baseline conditions. Results 12 patients were enrolled (mean age 31.3 years, mean FEV 1 / FVC 49.9 %, mean FEV 1 28.4 % predicted). TFdi was similar with the two techniques, but HFNC, compared to NIV, resulted in a significant decrease in respiratory rate (-20.2 % (18.0) vs -0.2 % (18.7), p = 0.024) and a lower mean arterial pressure (0.3 % (5.6) vs 5.8 % (4.9), p = 0.017). No significant differences were found in heart rate, SpO 2 , PtcCO 2 , V T , MV, comfort and dyspnea (Table 111) .
Conclusions HFNC was not inferior to NIV with respect to diaphragmatic work in CF patients who had an indication for ventilator support. These preliminary data suggest that HFNC may confer physiological benefits by decreasing respiratory rate, and constitute an interesting alternative to NIV.
Introduction The washout effect of HFNC has not been well evaluated. Our prior study, presented at the ESICM congress 2014, evaluated the reduction of P ET CO 2 with HFNC using a tracheal intubation trainer and a test lung. Although we concluded that the washout effect is most effective with a relatively low flow, the model had a large upper airway dead space of 200 mL, which was thought to have influenced P ET CO 2 . We also were not able to measure PEEP, which is also thought to have interaction between HFNC flows. Therefore, we developed a more sophisticated artificial respiratory model using a 3D printer, and used a lung model equipped with a pressure sensor to quantitatively evaluate the washout effect of HFNC and the interaction with PEEP.
Objectives To quantitatively evaluate the washout effect and interaction with PEEP using different levels of HFNC flow. Methods The airway model was made by a 3D printer using the craniocervical CT data of a healthy 32-year-old male. The total anatomical dead space was adjusted to 180 mL (3 mL/kg). The model lung (LUNGOO : Air water safety service Inc., Kobe, Japan) had the following settings: normal (Compliance (C) 50 ml/cmH 2 O, resistance (R) 5 cmH 2 O/L/s, tidal volume (Vt) of 500 mL, respiratory rate (RR) 16 /min), obstructive (C 70, R 20, Vt 700, RR 10), restrictive (C 30, R 5, Vt 300, RR 30) with inspiratory time at 1 second, and residual volume of 1000 mL. CO 2 was infused into respiratory lung models to reach P ET CO 2 of 40 mmHg without HFNC. After setting P ET CO 2 with each lung model, HFNC with flows of 10 to 60 L/min were applied and the change in P ET CO 2 in the subglottic area and the inlet of the lung model was measured. PEEP inside the model was also recorded. Conclusions The washout effect of HFNC is thought to reduce the P ET CO 2 enough to have a clinical effect. Contrary to the relation of HFNC flow and generated PEEP, the HFNC reduced P ET CO 2 with a relatively low flow in open mouth models. HFNC required more flow to reduce P ET CO 2 with a closed mouth model, which is thought to be due to a less efficient washing out of the dead space than in the open model. Grant acknowledgment Nothing to Declare. Introduction Clinical frailty is increasingly used and recognised to predict mortality and functional dependence following critical admission 1 although less is known regarding its impact on specific patient groups. Bilevel noninvasive ventilation (NIV) is frequently used to treat acute respiratory failure (ARF) of various aetiologies. Whilst NIV is known to be beneficial in exacerbations of COPD 2 , acute cardiogenic pulmonary oedema 3 and other presentations of ARF, there is scarce data available on the impact frailty may have on the success of NIV in this patient group.
Objective We examined the impact of frailty score on outcomes in patients receiving NIV for mixed aetiology of ARF within our critical care (CC) unit.
Methods Case notes and electronic patient data records (Metavision,iMDsoft,MA,USA) were retrospectively reviewed for adult patients with ARF who received NIV between December 2011 and April 2013. Patients who received continuous positive airway pressure and those with a primary surgical problem were excluded. Patient frailty score was recorded on admission using the Rockwood frailty index in on 55 consecutive patients. Demographic data, body mass index (BMI), primary cause of ARF and hospital mortality were recorded.Patients were divided into two groups according to their frailty score: below 4 (very fit to vulnerable) and 5 and above (frail to severely frail).
Results 55 patients were identified. 44 % were male, mean age 63 years. Presenting diagnosis was pneumonia in 32 patients (58 %) and acute exacerbation of COPD in 13 patients (23 %). The overall CC survival rate was 84 % with 73 % surviving to hospital discharge. 31 patients had a frailty score of 5 or above (77 % male, mean age 66 years) and 24 patients had a frailty score of 4 or less (50 % male, mean age of 62 years). Patients with a lower frailty score had a higher overall survival rate (91 % on CC and 83 % to hospital discharge) compared to those with a higher frailty score (70 % on CC and 51 % to hospital discharge). The mean BMI for both groups was identical (30.5 kg/m 2 ). There were no differences in the mean length of stay in CC or in hospital or duration of NIV use between the two groups.
Conclusion Our data suggests that a Rockwood frailty score of 5 or above is associated with reduced CC and hospital survival in patients with ARF requiring NIV. Use of a frailty index may be a useful predictive marker in patients admitted to critical care and further work is warranted to define the prognostic value of frailty scoring.
Introduction The use of high flow therapy in the critical care units for adults is becoming more common from few years on. This therapy approaches the patient with acute respiratory failure from a new way of treatment.
Objectives Our goal is to analyze the impact and the results of the application of high flow therapy in an intensive care unit of a tertiary hospital. Evaluate if the use of such a therapy has avoided the use of mechanical ventilation in the patients.
The study has summarized all the patients that have been treated with the oxygen therapy treatment between May 2013-October 2015. The reviewed data has been: SOFA, APACHE II, SAPS II, tabulated diagnosis, etiology of the respiratory failure, length of stay, use of high flow before or after the intubation, evaluate if the intubation has been avoided, mortality and mortality in 30 days. Applying non parametrical test the group of patients that needs mechanical ventilation has a higher mortality (p < 0, 0001) Conclusions The use of high flow therapy has changed the attitude towards the patients with insufficiency respiratory diseases avoiding in many cases the use of mechanical ventilation. More controlled studies are needed showing which other patients can be beneficed by the high flow therapy to prevent the delays in the start of mechanical ventilation.
Introduction Complex factors in ICU survivors such as health literacy, socioeconomic status and social environment may be predictive of adverse outcomes following hospital discharge but are not well studied.
Objectives We hypothesized that Medicaid Insurance, a proxy for individual low socioeconomic status, would be associated with increased hospital readmission rates following hospital discharge.
Introduction Prolonged hospital stay prior to admission to the intensive care unit has been shown to be independently associated with poorer outcome (1, 2) . Even a few hour delay in transfer from emergency department to intensive care worsens outcome (3). This may relate to an ongoing deterioration of physiological function while in hospital, potentially influenced by the process or disease state that culminates in admission to critical care. We investigated whether common illness severity scores e.g. Acute Physiology and Chronic Health Evaluation II (APACHE II) or Intensive Care National Audit & Research Centre (ICNARC), are significantly different in patients admitted after a prolonged ward stay. We describe mortality and ICU / hospital length of stay in said patients, in an order to elucidate predictors for outcome.
Objectives Show higher length of stay before ICU admission as an independent predictor of outcome · Identify whether ICU scoring systems predict outcome in our population · Identify whether serum albumin or other surrogate marker of frailty (e.g. Creatinine) can help predict outcome? Methods Retrospective analysis of prospectively collected data of all admissions in ICNARC database to 44 bed adult critical care unit in University Associated London Major Trauma Centre over two-year period (1 st January 2013 -31 st December 2014). Demographic data, APACHE II, ICNARC score, ICU mortality, and length of stay on ward preceding ICU, within ICU and overall hospital length of stay were collected. Data was analyzed using ANOVA tests, according to preceding ward length of stay. RESULTS. n = 4340 Mean APACHE 2 score for all admissions was 14.88 (sd 7.0) P < 0.01 ANOVA comparing Length of ICU stay between 0-7 and >28 days. P < 0.01 ANOVA comparing APACHE2 across all ward LOS groups. P < 0.01 ANOVA comparing serum albumin across ward LOS 0-7 days vs >28 days, and non significant across other groups.
Conclusions Prolonged pre-ICU hospital admission is associated with longer ICU and hospital admission and generally higher ICU mortality. APACHE2 scoring and serum albumin predict outcome. were not significantly different between in-house and retrieved cases. Predicted hospital survival for SAVE score risk class IV (score -9 to -5) and class III (score -4 to 0) were 30 % and 18 % respectively. For in-house ECMO patients, higher proportions of non-infective aetiologies for VV-ECMO (RESP score) and post-MI cariogenic shock for VA-ECMO were observed. These conditions have poorer prognosis and lower reversibility, which may account for the poorer RESP/SAVE scores (though statistically insignificant) and higher predicted and observed mortality.
Conclusions Our findings did not show a statistically significant difference in ICU mortality rate between in-house and retrieval ECMO groups. Inter-hospital ECMO retrieval is feasible for further development. The RESP score and SAVE score systems provides a tool for monitoring of our centre´s performance in comparison to ECMO centres worldwide.
Introduction The outcome in critically ill patients regarded with prognosis has many background effects of risk factors. An aging population and chronic diseases may also result in an increased number of patients in intensive care unit (ICU). Clinical results have revealed the need for outcome examination and guidance on the effective use of ICU.
Objectives The aim of this study was to evaluate mortality among patients in Turkish ICUs. Regarding this, the present study analyzed APACHE II databases in critically ill patients at secondary and tertiary referral hospital ICUs in Turkey.
Methods During the study period, clinical data that were collected concurrently for each patient contained demographic details, diagnostic category leading to ICU admission and APACHE II scores following ICU admission. Patients were followed up during ICU stay. The equation coefficients for APACHE II were supplied by APACHE Medical Systems. The mortality in intensive care units was analyzed according to APACHE II scores. The other attempts performed during ICU stay were also recorded.
Results 13.313 patients were enrolled in this study. The 69.9 % of patients were > 60 years old and 53.8 % of them were male. The mean APACHE II score was 21.49. The ICU's mortality rate was 44.5 %. The mechanical ventilation was determined as the most performed attempt in ICU's with a ratio of 55.9 %. The ratio of central venous catheterization was found 53.5 %. The ratios of systemic infection and antibiotic administration were 63.6 % and 80.7 %, respectively. Conclusion In the present study, the patients hospitalized in ICU's of ministry, university, and private hospitals were analyzed all over Turkey. Early identification of patients at risk, both before admission and after discharge from ICU, may allow to prevent some of the physiologic abnormalities contributing to the APACHE II score. There was a wide difference in outcome for patients admitted to different ICU's by using risk adjustment methods. Introduction Growing interest in the long-term effects after critical care has formed investigator-led clinical research groups around the world. Work aiming at standardizing core outcome measures and instruments for randomized clinical trials is ongoing. Whether these outcome measures reflect the domains most valued by patients or if important issues are missing from the existing scales is unclear. Commonly used tools like SF-36 and EQ-5D are too unspecific.
Objectives To develop and validate a questionnaire for patient-reported outcome measures (PROM) after critical care.
Methods During a 24-months qualitative phase, 35 former ICU-patients were interviewed in a semi-structured way, providing detailed information on symptoms and difficulties in all areas of everyday life. Patients were recruited from the post-ICU clinic at Sahlgrenska University Hospital, covering both urban and rural areas. The interviews were recorded, transcribed, and issues were categorized into 13 hypothesized domains: cognitive, executive/fatigue, physical health, pain, mental health, daily activities, sleep, food/drink/smoking, sexuality, hearing/visual/dysphagia, intestinal and urinary problems, and return to work/financial situation. After searching the literature and commonly used assessment tools, additional issues were included. All issues were then rephrased into questions, with care taken to maintain only one conceptual entity per question, and with the recall period usually being the last month. Adequate scales for frequency, intensity and duration were used. All questions were validated face-to-face with another set of former ICUpatients and with non-ICU-treated controls to make sure the wording was easily understood and neither confusing nor upsetting.
The questionnaire contains 271 questions. It is currently being tested in a pilot study with 650 patients, recruited six months to three years after discharge from the ICU, and 200 controls, matched for age and gender. The questionnaire is sent by mail after an invitation letter followed by a phone call, and returned in a pre-stamped envelope. Returned questionnaires are being scanned and data digitally imported into SPSS, where additional clinical data will be added. After comparison with controls, item reduction will follow, resulting in an ICU-specific PROM questionnaire.
Conclusions A patient-centred, ICU-specific questionnaire will be available for long-term follow-up in the post-ICU clinic. Being a postal document, the patients do not have to return to the hospital to provide their information, making it and suitable for large-scale studies.
Introduction Approximately 2000 oesophagogasterectomies are performed each year, with a 5 year survival of 25 % and 30 day mortality of 10 % 1 . Secondary analysis of ICNARC data has shown the median length of stay to be 2.8 days, and a readmission rate of 12.2 % 2 . We conducted a retrospective review of all post Oesophagogastrectomies ICU admissions in our hospital between Jan 2014-15, as part of a quality improvement project to reduce morbidity and length of stay (LOS).
Objective To analyse the electronic record and chest Xray of every oesophagogastrectomy in order to compare our own LOS, patient characteristics and identify factors affecting LOS and unit morbidity. Conclusion Epidural disconnection rate was very high, contributing to a longer unit LOS than national average and higher pain scores. We have introduced a training package on epidural care for our nurses and encouraged the use of tunnelled epidurals in combination with paravertebral catheters. The incidence of CXR changes after surgery in this cohort has not been studied previously. A large proportion of our patients had radiologically apparent collapse and even consolidation on arrival on ICU. This may contribute to the development of pneumonia in this setting if analgesia is imperfect as CPAP is relatively contraindicated due to the oesophageal anastomosis. We now encourage a longer period in recovery, with lung toilet and recruitment manoeuvres at the end of one-lung ventilation.
Introduction Pancreatitis is a common precipitant of critical illness and intensive care admission. Mortality from pancreatitis overall should be under 10 % and in severe pancreatitis under 30 % (1). Mortality risk is mulit-factorial but those at high risk are co-morbid, elderly, develop SIRS or progress to pancreatic necrosis. We sought to look at all of our pancreatitis admissions to ICU over a 21 year period and identify the average demographics and difference between survivors and non survivors.
Objectives To identify patients admitted to ICU with a primary diagnosis of acute pancreatitis, and to compare predicted demographics and features of systemic inflammatory response between survivors and non survivors. We hypothesised that if you required Intensive Care for the management of severe pancreatitis, death is likely to occur at the beginning of your ICU stay due to overwhelming organ failure. If you were to survive the initial insult, it was hypothesised that you may survive to hospital discharge, although the length of hospital stay would be prolonged. We sought to test this theory with our patient group. Methods A retrospective audit of patients admitted to ICU in the Glasgow Victoria Infirmary, Southern General and Queen Elizabeth University hospital from 1994 to 2015. Patients were identified on Wardwatcher via a search of APACHE II diagnosis including pancreatitis. Data was collected from patient profiles on the Wardwatcher and TrakCare CIS.
Results 182 patients were identified with an admission diagnosis of pancreatitis from 12704 patients admitted giving an incidence of 1.4 % of all ICU admissions. Other results are as demonstrated below with with all data being presented as mean and 95 % confidence intervals with p-values from Student´s unpaired t-test where applicable.
Conclusions As could be predicted, pancreatitis is a diagnosis of the older male population in ICU, likely as a result of the concomitant problem of alcohol abuse in the West of Scotland. These patients have a higher than normal APACHE-II score and predicted mortality compared with unit averages. All SIRS criteria were met when looking at average data, hence why their likely admission to ICU. When comparing survivors to non-survivors, survivors were significantly more likely to be younger, with lower APACHE-II scores and predicted mortality. There was no difference in length of stay between groups nor degree of derangement of any of the SIRS criteria. Conclusions Though there were not many SCI patients admitted in the unit compared to other patients. SCI patients stayed longer by 5 days on average. Three main reasons were identified why they stayed longer; one was because of ISCoPE research, the other one was their dependency on advance organ support and lastly, the delayed discharges because of shortage of ward beds. The delayed discharges could indicate that the hospital needs to increase the bed capacity. The patients' outcome appears encouraging with their improved outcome. A further audit is necessary to see any changes.
Introduction Emergency laparotomy is associated with a high risk of mortality and morbidity, which leads to significant financial expenditures for the NHS. In a recent study, the Emergency Laparotomy Pathway Quality Improvement Care (ELPQUIC) program has shown that a set of sequential interventions have the potential to improve clinical outcome; however related costs or savings remain unknown.
Objective This economic evaluation aims to evaluate costs and the cost-effectiveness of a clinical pathway for patients undergoing emergency laparotomy, compared to a historical cohort receiving standard care.
Methods 299 consecutive patients in the control group were compared with 427 patients directed into a predefined pathway. To assess costs and cost-effectiveness, two decision models were constructed; the first model took hospitals management perspective, the second model took a societal perspective and evaluated lifetime costs and quality adjusted life years.
Results One time implementation costs of £23,406.7/hospital (£1,399.0-£31,793.0) for training, supervision, purchase of equipment and pharmaceuticals can be expected. However, these costs were offset after treating 26 patients, mainly due to reduced LOS and lower complication rates. The long-term model showed that the intervention is both more effective (2.4 month) and leads to lower costs to society (cost savings of £899.6/patient). The incremental cost-effectiveness ratio is £-4,015.9, meaning the new pathway is the dominant strategy and should be recommended to decision makers. Conclusion A bundled pathway to improve clinical care for patients undergoing emergency laparotomy has shown to reduce mortality, seems cost-effective and has the potential to improve clinical outcome and lower costs for society. Decision makers need to adopt a long-term vision and be prepared to make one off investments to lower future costs.
the ED with ICU mortality (OR = 1.01; p = 0.73). This result was not altered after adjusting for SAPSII, age, gender, trauma, acute kidney injury or year of admission. Of relevance, there was also no association with ICU mortality and an excess of 12 hours in the emergency department. Finally, there was no association between time spent in the ED and hospital mortality (OR = 1.2; p = 0.13), ventilation time (p = 0.6) or nosocomial infection (p = 0.8).
Conclusions Unnecessary time spent in the ED has the potential to adversely affect the care and to overwhelm crucial ED resources. In our single-center retrospective study we did not find any association between the absolute time spent in the ED and ICU mortality, and we cannot recommend any clinically relevant specific time frame. Meanwhile, patients should be transferred to the ICU from the emergency department as soon as possible and further research is needed to develop potential quality indicators.
Objectives Several studies have demonstrated a decrease of mortality under mechanical protective ventilation with low tidal volumes (6-8 ml per kilogram of predicted body weight) not only in patients with acute respiratory distress syndrome (ARDS), but also in ICU patients without criteria of pulmonary injury, The aim of this study is to evaluate the utility of a daily checklist applied to all the patients under mechanical ventilation (MV) admitted to an ICU as well as to identify the factors influencing the achievement of the goal to keep the tidal volume at 6-8 ml per kilogram of predicted body weight Methods A prospective study including all the patients admitted to an ICU during a four-months study period. A daily-based register was implemented for all the ICU patients under MV during the morning, the afternoon and the night shifts. We analyse the degree of compliance with the checklist, as well as the influence on the achievement of the goal for tidal volume of the following factors: height, sex, type of MV (Continuous Mandatory Ventilation-CMV, Pressure Control Ventilation-PCV, Bi-level positive airway pressure-BiPAP, Synchronized Intermittentmandatory Ventilation-SIMV, Pressure Support Ventilation-PSV), gaseous exchange (relation paO2/FiO2), pulmonary mechanics (plateau pressure).
Results We registered 883 measurements (36 % in the morning shifts, 31 % in the afternoon and 33 % in the night shift) for all the patients with MV (either with ARDS or without criteria of pulmonary injury). No patient developed ventilator induced lung injury (VILI). The percentage of measurements outside the established goal of tidal volume was 28,7 % (CI 95 % 23.9-33.9 %) without differences between the shifts. The average tidal volume was of 443.9 ml (range 431-457) that corresponds to 7.5 ml per kilogram of predicted body weight (IC 95 %: 7,35-7,66). In univariate analysis the factors associated to being outside of the goal for tidal volume were: female sex, height and the Pressure Support Ventilation-PSV as opposite to mandatory modes with no influence of the shifts of work, the relation paO2/FiO2 and the plateau pressure. The multivariate logistic regression analysis showed that the factors independently associated with being outside of the goal for tidal volume were female sex and the Pressure Support Ventilation-PSV.
Conclusions In almost 30 % of the ICU patients under MV the goal of low tidal volumes is not achieved, especially in female patients and in those under Pressure Support Ventilation. The establishment of a daily checklist for patients under VM is feasible and could influence in a low frequency of VILI in patients with ARDS and also in those without criteria of pulmonary injury.
Analysis of the serious adverse events reported at the heart surgery intensive care unit P. Introduction Fostering a safety culture is one of the most important landmarks when it comes to provide quality assistance in an Intensive Care Unit (ICU). The detection and analysis of the incidents and adverse events that affect our patients are the cornerstone for the development of programs and protocols leading to safe health assistance with high standards of quality.
Objectives Knowing the nature, casuistry and the underlying elements of adverse events (AE), rated as serious, according to the Protocol on Adverse Events Reporting established in our Unit.
Methods 266 notified EA, reaching 201 patients, were analysed through the Adverse Events Reporting System (AERS) established in the Heart Surgery Intensive Care Unit (HSICU) from January 2014 to January 2016. Among these, we rated as serious those that caused to the patients a temporary or permanent damage, extending their hospitalization, compromising their lives or needing surgery in order to save their lives and contributing or causing their demises. In our AERS, those rated as F-I according to the catalogue of the National Coordinating Council for Medication Error Reporting and Prevention (NCCMERP). Results 21 AE rated as serious were notified. Among these, 13 were rated H category (incident that compromised the patient's life and needed care to keep him alive) and 2 were rated I category (the incident contributed or caused the patient's demise). The last were related to surgery complications. All of them needed medical attention, being the majority of them discharged to ordinary ward hospitalization. There were not relevant differences as far as the urgency of the hospitalization, the clinical profile and the assistance needed in the moment of the AE. In 30 % of the AE, the equipment and available resources were pointed out as contributing factors; in 35 % of cases it was related to formation and training; in 40 % of cases it was due to elements related to the patient and in 45 % of the cases it was elements related to the performance. The most frequent serious safety issues were surgery complications or damages related to invasive procedures, three of them related to the handling of breathing devices and two of them with reaction after blood transfusions. In 75 % , according to professional advice, the AE was deemed avoidable.
Conclusions The AE rated as serious were 7.7 %. The most common feature ,was their avoidability and their relation with formation and training in the techniques used during the assistance. Beyond the cases of death, the serious AE involved an extension in the stay at the hospital and a rise in the morbidity and mortality rate. According to this, the intervention over factors capable of improvement, such as formation and training of all the professionals involved in the healing process, is compulsory.
Staff would generally discuss adverse incidents amongst themselves informally (85 %), and in many cases (63 %) implement a solution following this discussion. Feedback as a result of adverse event reports was highlighted as a deficiency with only 33 (31 %) staff feeling they received this, similarly 39 (37 %) of staff did not feel they were adequately informed about any errors that happened on the units. Conclusions Whilst our results indicate a positive work environment, there are areas for improvement, specifically feedback following adverse events. Designated nurses to attend morbidity and mortality meetings and subsequent publication of patient safety bulletins will improve feedback to nursing staff. We are going to instigate a designated patient safety board to publicise patient safety events and resultant changes in practice. Little is currently published regarding UK ICU safety surveys to allow benchmarking of our results. The authors feel UK ICUs should consider collection and publication of this data.
Introduction Clinical safety has become on one side a quality standard and on the other side an ethical obligation in the daily work of an Intensive Care Unit (ICU). The establishment of standardized protocols and appropriate training in the area of safety have become a must when it comes to its development. Also all professional categories have to be involved in this process.
Objectives Analysis of the incidents and adverse events (I/AE) reported after the establishment of a report protocol (RPIAE) in a Heart Surgery Intensive Care Unit (HSICU). Methods The Clinical Safety Group of the Intensive Care Service, responsible for the design of the RPIAE, was created in January 2014. Thus, the RPIAE was introduced in the HSICU in March 2014. This methodology reviews the adverse events (AE) detected in every single patient that was looked after in this unit between March 2014 and October 2015.AE: non-intentional damage caused during or as a consequence of the medical attention received and non-related to the evolution or eventual complications of the initial illness. The information was gathered in an Excel data base and the statistical analysis was performed through the SPSS and Epidat programs.
Results 254 AE's were reported on 189 patients, 67 % of which were males. 2.7 % of them were admitted to hospital as a result of an AE. 90.9 % were discharged and 23 patients passed away. 50 % of them were reported by the nursing staff; 39.8 % by doctors. 88.9 % took place in the Intensive Care Unit., 44.9 % of which during the morning shift. 79.9 % while the Unit was holding 100 % occupancy. 24 % of the AE affected the patient in a way that they needed further monitoring and/or intervention in order to check that no damage had been caused. 7.1 % compromised the patient's life and 1.6 % contributed or caused the demise of the patient. 57.9 % of them were doubtlessly avoidable. 22.8 % had their origin in the unplugging/removal of accesses/probes/catheters/sensors/tubes and 7.9 % had their origin in the handling of breathing devices and mechanical ventilation. In 43.75 % of the cases the lack of training and formation had direct effect on the I/AE. The mean duration of hospitalization stay before the AE was 7.68 days (statistic standard deviation, SSD, 30.1); the mean duration of hospitalisation was 16.45 days (SSD 25.26) and the mean stay in the Intensive Care Unit 8.69 days (SSD 13.48), (p < 0.05).
Conclusions The majority of the AE were deemed evitable and neither had they important effects on the evolution of the patient nor extended the patient's stay in the ICU. A longer stay in the ICU was related to a bigger incidence of AE. (p < 0.05). Formation and training are key elements in order to avoid AE and they are part in the measures currently established in our ICU in order to avoid these I/AE.
for nurses (0.429 & 0.739; p < 0.001), for optimisations and errors respectively. Conclusions Over one hundred common prescribing errors and optimisations had modal clinical impact grades recorded for potential application in clinical practice and research. The inter-professional variability highlights the importance of multidisciplinary perspectives in assessment of medication errors and optimisations in clinical practice and research.
Introduction Intercostal chest drain (ICD) insertion is a relatively common procedure but can be associated with significant complications including bleeding and organ perforation. Indications for insertion include management of hemothorax, pneumothorax and pleural effusions. The "triangle of safety (TOS)" is an often quoted site as being appropriate for ICD insertion; including in trauma patients by ATLS. The space is delineated by lateral border of the pectoralis major, lateral border of the latismus dorsi, line of the 5th intercostal space and the base of the axillaintercostal space. Although ultrasound (US) guidance has been recommended to aid insertion, its use is far from established practice and landmark techniques and the TOS is still widely practiced.
Objectives To establish the safety profile of the TOS through the use of US to delineate underlying anatomy including the position of intercostal vessels. Methods 50 consecutive patients on a general ICU underwent bilateral US examination of their TOS. The position of liver, spleen and heart in the respective TOS was noted. Doppler ultrasound was used to identify intercostal vessels within the TOS.
Results Overall, the heart, liver and spleen were visible in 60 % of patients within the TOS. This percentage increased in the intubated and ventilated patient population. Intercostal vessels where visible in the minority of patients.
Conclusions The British Thoracic Society and the National Patient Safety Agency UK has recommended ultrasound before inserting a drain for fluid. Our study found that the TOS is a misnomer exposing the patient to the risk of underlying organ perforation especially in the patient who is intubated and ventilated. It is therefore not safe and the practice should be abandoned. The routine use of real-time US to guide ICD insertion should be recommended to improve procedural safety.
began. Data about total noradrenaline dose in mg, length of stay, mechanical ventilation length and mortality was recorded.
Results MBP increased progressively first 6 hours after methylene blue infusion in A Group 22 % and C Group 9.2 % (p:< 0.05), steadily until 72 hour follow up. Noradrenaline dose decreased in the first 6 hours, on A Group an 86 %, C Group was 56 % (p:< 0.05). Lactate clearance first 6 hours was 62 % in A Group, in contrast with C Group with 33 % clearance (p:< 0.05). Mortality at ICU discharge on A Group was 20.0 % and C Group was 36.6 % (p: < 0.05) without variation at 21 days.
Conclusions Methylene blue is effective as contributory in septic shock treatment.
Note: This abstract has been previously published and is available at [2] . It is included here as a complete record of the abstracts from the conference.
Introduction Septic shock induced by gram-negative bacteria infection is a serious condition in intensive care unit (ICU), and endotoxin plays an important role in their pathogenesis. oXiris filter is a polyacrylonitrile haemofiltration membrane treated with polyethyleneimine, which provide a positive charged surface to enhance the absorption of endotoxins and cytokines.
Objectives case series to determine oXiris haemodiafiltration could improve the haemodynamic status in patients with gram-negative bacteria related septic shock.
Methods Patients admitted to regional ICU with intra-abdominal sepsis that required intervention, who developed severe septic shock required inotropic support and acute renal failure required renal support, was assigned to receive oXiris haemodiafiltration for 72 hours. Matched patients with similar pathology and severity, who received ordinary haemodiafiltration for acute renal failure, were identified for comparison. Primary outcome was the percentage of reduction of inotrope dose within 96 hours after the start of renal replacement therapy, which was calculated according to equivalent Noradrenaline dose (ug/ hr). Second outcomes including duration of MV, duration of CRRT, ICU length of stay, and ICU mortality.
Results Three patients were assigned to receive oXiris haemodiafiltration, and five matched patients were identified for comparison. ICU mortality for patient receiving oXiris haemodiafiltration was 33 %, compare to 60 % for patient with ordinary haemodiafiltration. Patient received oXiris haemodiafiltration shown a rapid reversal of inotrope dose compare to the control, and the effect became obvious after 24 hours of treatment 2.67 days in oXiris group vs 11.67 +/-3.06 days in control group), duration of CRRT (4.55 +/-1.7 days in oXiris group vs 5.72 +/-2.55 days in control group), and ICU length of stay (15.17 +/-6.96 days in oXiris group vs 14.49 +/-2.33 days in control group).
Conclusions oXiris haemodiafiltration shown a rapid reversal of shock and lower mortality in patient with intra-abdominal sepsis and septic shock, while there was no difference in terms of duration of MV, duration of CRRT, and ICU length of stay.
Introduction In recent decades, more and more studies have reported that treatment with polymyxin B-immobilized hemoperfusion cartridge may have beneficial effects on hemodynamics and mortality in patients with severe sepsis or septic shock.(1, 2) Premature cartridge clotting is a common problem during polymyxin B hemoperfusion, and it may decrease therapeutic efficacy and increase cost of therapy. However, excessive anticoagulation in patients with severe disseminated intravascular coagulation or in intra-abdominal infection patients after operation may increase the risk of bleeding. Currently, nafamostat mesilate is used dominantly in Japan,(2) but the experience of using heparin for anticoagulation for polymyxin B hemoperfusion therapy in other countries is less and need further investigation.
Objectives We aimed to investigate the effectiveness and safety of a heparin dosing score protocol for anticoagulation during polymyxin B-immobilized cartridge hemoperfusion.
Methods This was a retrospective study in 6 ICUs in National Taiwan In contrast the TEG-R time shows a greater variability of their values and a more severe patient anticoagulation than reported by aPTT sampling. This suggests that lower ARG doses could be sufficient to ensure an adequate anticoagulation. Nevertheless no adverse events were recorded. The duration of ARG anticoagulation effect appears to be longer than described by pharmaceutical company, always exceeding 4 hours. Further investigations are necessary to introduce ARG in clinical practice as anticoagulant during PMB hemoperfusion.
Introduction Recent clinical studies have shown that the reduction of toxic levels of cytokines from blood with the use of a new extracorporeal sorbent, Cytosorb (Cytosorbents), could be useful to regain control during a complicated inflammatory condition in patients with sepsis and septic shock [1] .
Objectives The aim of this observational study was to evaluate the course of patients with septic shock admitted to our ICU and treated with the new sorbent, Cytosorb. Primary outcomes were the influence of this new sorbent in hemodynamics, evaluating mean arterial pressure (MAP) and vasopressors need, whereas secondary outcomes were the improvement in inflammatory condition and renal function, studying procalcitonin (PCT) and creatinine.
Methods We enrolled 8 patients until now (4 f, 4 m): 2 severe sepsis and 6 septic shock. Patients data are reported in the table (median, lower and upper quartile). All patients were non-responding to the Standard of Care for the treatment of sepsis/septic shock. Therefore, Cytosorb was used as adjunctive therapy in combination with continuous renal replace therapy (CRRT), in order to control the cytokines storm and improve the hemodynamic stability of patients, and it was installed in series connection after the dialyser in the CRRT circuit for 24 h. Clinical parameters were collected before, during and at the end of Cytosorb treatment. Introduction Platelets play a pivotal role in the host immune response, and antiplatelet therapy is associated with a beneficial outcome in sepsis patients 1 . Antiplatelet therapy may therefore, besides prevention of cardiovascular disease, also affect inflammatory processes and outcome in infections. Theoretically, modulation of prostaglandin production, adenosine metabolism, and attenuation of platelet reactivity may account for these effects 2 .
Objectives To evaluate the effects of clinically relevant doses and combinations of antiplatelet therapy on the innate immune response in a human model of systemic inflammation and to evaluate putative mechanisms of immunomodulation by these antiplatelet agents.
Methods We performed a parallel randomized controlled study in 40 healthy male volunteers, who were randomized to a seven day treatment course with either placebo (P), placebo with acetylsalicylic acid (ASA) (PA), ticagrelor and ASA (TA), or clopidogrel and ASA (CA), n = 10 per group. On the seventh day, a systemic inflammatory response was elicited by intravenous administration of a bolus of 1 ng/kg purified E. Coli endotoxin, followed by 1 ng/kg/h for 3 hours in all subjects. We evaluated plasma levels of cytokines, prostaglandins, and adenosine, and measured platelet reactivity during endotoxemia.
Results Treatment with ASA resulted in a profound augmentation of plasma levels of the pro-inflammatory cytokines TNFα, IL6, and IL8 during endotoxemia (Fig. 140) , but did not affect anti-inflammatory cytokines IL-10 and IL-1RA. Although the addition of ticagrelor, but not clopidogrel, attenuated the ASA-induced increase in TNFα, these P2Y12 antagonists did not affect the concentration of other proinflammatory cytokines (Fig. 140) . There was no difference in cytokine response between ticagrelor-and clopidogrel-treated subjects. Treatment with ASA lowered plasma levels of thromboxane B2. Plasma adenosine increased during endotoxemia, without differences between groups. Platelet reactivity was reduced in ticagrelor and clopidogrel treated subjects, without any correlation with cytokine responses.
Conclusions A seven day course with low dose ASA resulted in a profoundly enhanced pro-inflammatory immune response in an in vivo model of systemic inflammation in humans. Although addition of ticagrelor but not clopidogrel significantly attenuated the TNFα response, ticagrelor or clopidogrel did not affect IL6, IL8, IL10, and IL1RA responses. Conclusions Compared to high-flux dialyzers, HCO filters offer significantly higher removal rates for middle molecules such as cytokines and other target molecules with similar molar mass. Therefore, HCO filters should be preferred in extracorporeal therapies for the supportive treatment of systemic inflammatory syndromes.