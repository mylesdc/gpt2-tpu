As infectious disease outbreaks emerge, public health agencies often enact vaccination and social distancing measures to slow transmission. Their success depends on not only strategies and resources, but also public adherence. Individual willingness to take precautions may be influenced by global factors, such as news media, or local factors, such as infected family members or friends. Here, we compare three modes of epidemiological decisionmaking in the midst of a growing outbreak using network-based mathematical models that capture plausible heterogeneity in human contact patterns. Individuals decide whether to adopt a recommended intervention based on overall disease prevalence, the proportion of social contacts infected, or the number of social contacts infected. While all strategies can substantially mitigate transmission, vaccinating (or self isolating) based on the number of infected acquaintances is expected to prevent the most infections while requiring the fewest intervention resources. Unlike the other strategies, it has a substantial herd effect, providing indirect protection to a large fraction of the population. misinformation from the "anti-vaxxer" movement [8, [11] [12] [13] . Recently, there have been calls for a special government commission on vaccine safety, despite overwhelming scientific consensus that vaccines are both safe and effective [12, [14] [15] [16] .
As outbreaks emerge, public health agencies often implement a variety of pharmaceutical and non-pharmaceutical interventions to prevent epidemic expansion, including vaccination and medical prophylaxis, school closures and other social distancing measures, and information campaigns to promote awareness, hygienic precautions and voluntary isolation [1] [2] [3] [4] . However, such measures require population adherence and are often hindered by failure to take recommended actions [5] . Around the globe, for example, seasonal influenza vaccine coverage falls significantly below the 75% baseline recommended by the World Health Organization, but varies widely between countries and across age groups [6] . In the USA, 2015-2016 uptake was only 59.3% in children and 41.7% in adults [7] . For measles, routine childhood vaccination is declining in Texas and other areas of the United States where personal belief and other nonmedical vaccination exemptions are allowed [8] [9] [10] . Parental decision-making regarding childhood vaccines is complex and context dependent [11] , but likely influenced by false claims regarding vaccine safety, low perceived risks of infectious diseases, and other forms of a1111111111 a1111111111 a1111111111 a1111111111 a1111111111
We simulate the spread of an infectious disease in a network (population) with an exponential degree distribution-as estimated for typical urban populations [46, 52] -using a susceptibleinfected-recovered (SIR) chain-binomial model [41, 53] with an additional immunized state. At each time step, individuals decide whether or not to take an instantaneously protective action to avoid infection, based on their perceived risk of infection, as defined by the given local or global decision model. We assume that there are sufficient resources to immediately protect any willing individuals.
We model contact patterns in the population using an exponential network with N = 10000 nodes and mean number of contacts μ = 10 [54] , generated according to the configuration model [55] , unless otherwise is specified. We assume that this network constrains both disease transmission and local risk perceptions, when individuals monitor infected social contacts. To evaluate the impact of network topology, we also analyze the SIR-intervention dynamics on a homogeneous random graph (all nodes have same degree) and Barabási-Albert scale-free network [56] , with degree distributions constrained to achieve the same epidemic threshold as the focal exponential network. All three networks share T c ¼ hki hk 2 iÀ hki ¼ 0:056 where hki and hk 2 i are the average degree and squared degree in the network, respectively.
We model SIR transmission dynamics of a flu-like disease using chain-binomial stochastic simulations [41, 53] . Epidemics begin at time t = 0 by infecting a single randomly chosen node in an otherwise completely susceptible population and terminate when there are no remaining infected individuals. Individuals remain infectious for l = 7 days before recovering with full immunity to future infection [57, 58] . Infected individuals transmit disease to each susceptible contact at a rate β. Immunized and recovered individuals are assumed to be fully resistant to infection. Results are averages over 500 simulations.
The basic reproduction number (R 0 ) is the expected number of secondary cases when a single case of disease is introduced into a naive population, and is related to the epidemic growth rate. To study the impact of transmission rate on the vaccination-epidemiological dynamics, we consider R 0 values ranging between one and ten, which spans the range for many common human pathogens, including influenza, Ebola, SARS, Pertussis, HIV/AIDS, Mumps, Rubella, Polio, Smallpox, Diphtheria, etc [52, [59] [60] [61] [62] [63] [64] [65] [66] . For each value of R 0 , we determine the corresponding β using [45] 
where T = 1 − (1 − β) l is the transmissibility over the entire infectious period, also known as the secondary attack rate [67] .
We assume that individuals make daily decisions regarding whether or not to take precautionary measures based on their perceived risk (Fig 1) . In other words, they have a general sense of the contagiousness of a given disease based on past experience or conventional wisdom. We use T as a rough proxy for perceived risk. If and when they choose to take action, they instantly gain full resistance to infection for the remainder of the simulation. Although these models apply to any transmission preventing measure, we henceforth refer to the interventions as vaccinations.
We model three different individual decision strategies in which individuals consider either the disease states of their direct social contacts or the global situation, perhaps gleaned through news or social media. Let v X (t) denote the willingness of a individual to vaccinate under strategy X at time t.
Local decision strategies. In the first model, local prevalence, individuals assess infection risk by tracking the fraction of their social contacts that are currently infected. The probability that a susceptible individual i vaccinates at time t is given by
where η i (t) is the number of neighbors of i that are infected at time t, k i is the total number of neighbors (degree) of i, and hki is the average degree of the network. In the second model, local count, individuals track their number rather than proportion of infected neighbors, and decide to vaccinate according to v lc ði; tÞ ¼ 1 À ð1 À TÞ
Local prevalence is arguably a less plausible strategy than local count, given that the decisions require the additional knowledge of total number of contacts (degree) of each individual. 
where I(t) is the total number of infected individuals in the population at time t and N is the size of the population. This assumes general knowledge of the evolving dynamics of the epidemic, perhaps through news, social media or public health messaging. The mean degree (hki) appears in the global prevalence and local prevalence as a normalizer. If node i has the average degree (k i = hki) and its local prevalence mirrors global prevalence ( Z i ðtÞ hki ¼ IðtÞ N ), then it will have the same probability of vaccinating across all three models. In all three models, we assume that individuals will vaccinate with a probability equal to their perceived real-time probability of being infected. For example, if an individual's perception of infection in the immediate future is 25%, then a precautionary measure will be taken with probability 0.25. The local count model comes closest to estimating actual risk of infection. Specifically, v lc is the probability that any currently infected contact will transmit disease to the focal node at some point during his or her infections period. This exactly estimates risk if all infected contacts were just infected and at the beginning of their infectious period, but overestimates risk if some are nearing recovery. (S1 Fig illustrates how vaccination decisions change under each of these models as disease prevalence increases.).
To assess the indirect and direct protection afforded by a given decision strategy D at a given R 0 , we calculate a quantity we call the herd effect, given by
where hC 0 (R 0 )i and hC D (R 0 )i are the expected total number infections in epidemics without vaccination and with vaccination decision strategy D, respectively, and hV D (R 0 )i is the expected total number of individuals vaccinated under D. We estimate these expected values by averaging over 500 simulations with the specified R 0 and decision model. Barring extreme stochasticity, we expect H > 0 for any reasonably protective vaccine strategy. When H is between zero and one, more vaccines are given than infections averted, suggesting that vaccines may be mistimed or misplaced. This could happen, for example, if risk is underestimated early in the epidemic and overestimated late in the epidemic. An H near one indicates that approximately one infection is averted for every vaccine given. Note that this is an average, and does not necessarily mean that every vaccination prevents infection of the recipient. If each vaccine averts, on average, greater than one infection (H > 1), then the value of H corresponds to the level of indirect protection achieved by the decision strategy.
The decision models yield distinct vaccine adoption and disease transmission dynamics ( Fig  2) . As disease begins to spread, individuals perceive increasing risks and vaccinate according to the decision model, thereby protecting themselves and interrupting potential chains of transmission to others. While all three strategies reduce the total number of infections, the local count strategy affords the greatest and most efficient protection of the three. Under the global prevalence strategy, perceived risk is homogeneous. As cases mount, the vaccination rate rises synchronously throughout the population, arguably resulting in too much too late vaccine coverage. The local strategies avert more infections with fewer vaccinations than the global strategy. As epidemics unfold, risk is both heterogeneous and dynamic, with some portions of the network experiencing greater forces of infection than others. Local decision-making allows earlier detection and response to increasing personal risk, and prevents unnecessary vaccination in lower risk settings, both prior to and following epidemic waves. The local count strategy is more protective than the local prevalence strategy. By tracking the number rather than proportion of infected contacts, individuals more accurately assess the local force of infection. For example, compare a solitary individual with just two social contacts and a gregarious individual with 20. If they both have two infected contacts, then their risk of infection will be similar (assuming that time spent with each contact is sufficient for transmission). Under local count, their perceived risk and consequent vaccination probability will be identical; under local prevalence, the solitary individual will perceive higher risk (i.e., 100% of contacts infected) than the gregarious individual. Under all models, overall vaccine coverage increases as R 0 increases, with the global prevalence achieving near universal coverage by R 0 = 5.
The relative and absolute impacts of each strategy are remarkably robust to the transmissibility of the pathogen (Fig 3) . Without vaccines, the expected epidemic size increases non-linearly with R 0 , reaching almost 100% by R 0 = 10 ( Fig 3A) . All of the vaccine strategies avert a large and increasing fraction of cases, as R 0 increases. In fact, the total epidemic size is nonmonotonic, with slightly more expected infections around R 0 = 4 than around R 0 = 10. The local count strategy consistently yields the greatest protection, followed by local prevalence.
The decision models result in dramatically different vaccination rates, with the global prevalence strategy leading to near universal vaccination, consistently more than double the coverage produced by the local count strategy (Fig 3B) . The population-level protection afforded by the local count strategy exhibits a non-trivial trend with R 0 (Fig 3C) . Between R 0 = 1 and R 0 = 2, its impact grows logarithmically from less than one infection averted per vaccinator to nearly two infections averted per vaccinator. Thereafter, the indirect benefits continue to grow slowly, reaching three infections averted per vaccinator when R 0 = 9.
To explore the dynamic interactions between behavior and epidemiology in the three models, we consider individual nodes based on their degree (number of contacts). In general, the higher the degree of a node, the higher their risk for becoming infected and infecting others, and the greater the number of local infections they could potentially perceive when making vaccination decisions. Indeed, across all decision models, higher degree individuals vaccinate earlier, in terms of the fraction of the population infected at time of vaccination (Fig 4A, bottom) . However, the fraction of individuals vaccinated in each degree class does not necessarily increase with degree (Fig 4A, top) . Local count is the only strategy under which vaccination coverage monotonically increases with degree. Under global decision-making, coverage is inversely related to degree, and under local prevalence, coverage peaks for moderately connected individuals. By the time individuals choose to vaccinate under either of the two suboptimal strategies, their local risk of infection is already quite high (Fig 4A, middle) , particularly for more gregarious individuals. Although the vaccinating individuals are immediately protected, comparable individuals (of the same degree class and local risk) who stochastically fail to make the same low probability vaccination decision are likely to become infected. Consequently, the risk of infection increases steeply with degree under all models except local count (Fig 4B) . In a sensitivity analysis, we find that these qualitative results are robust to our assumptions about the efficacy of the vaccine, the time lag between an individual deciding to vaccinate and becoming protected against infection, the size of the network and the duration of the infectious period (S3 Fig). Finally, we consider the impact of the underlying contact network on the interplay between transmission and vaccination dynamics (Fig 5) . We compare our focal exponential network to a uniform random network in which all nodes have the same degree and a Barabási-Albert scale-free network. The local count strategy robustly affords the most efficient population-level protection, averting the maximum number of infections (or nearly maximum in the case of the scale-free network and low R 0 ) with the fewest vaccines. 
Public health interventions and individual-level adherence decisions can profoundly influence the fate of unfolding epidemics. In this study, we assume that individuals have access to a fully protective measure, such as self-isolation, medical prophylaxis, or an immediately and completely efficacious vaccine. They continuously make real-time risk assessments and thereby decide whether or not to adopt the intervention, based on either direct knowledge of infected friends and family (number or fraction of infected social contacts) or indirect information about population-level prevalence, perhaps gleaned through news media.
Of the three decision models, global risk assessments prove least effective across a large range of disease scenarios (R 0 ranging from one to ten). Nearly all non-infected individuals eventually vaccinate, yet the total cases more than double those occurring under the alternative strategies. There is a mismatch between risk and action. Risk is highly variable in time and space, given the heterogeneity of the underlying contact network and branching nature of transmission. Yet, the global model assumes that perceived risk and the consequent likelihood of adherence is homogeneous throughout the network, though variable in time. By the time Local risk perception enhances epidemic control global prevalence triggers wide-spread action, the highest risk individuals have already been exposed and the lowest risk individuals may still not, and might never, require protection.
In contrast, when individuals make decisions based on local risk assessments, the intervention efforts more closely track the epidemiological dynamics. Tallying infected contacts rather than estimating the fraction of infected contacts provides a more accurate indication of realtime risk and results in more efficient intervention. Assuming that all social contacts are equally likely to transmit disease, two out of three infected contacts carries the same immediate risk as two out of ten. The advantage of local risk assessment stems from two sources of variation in risk. First, disease transmission is an inherently local process in which risk aggregates around currently infected individuals. Second, this is magnified in realistically heterogeneous networks, by the concentration of risk around the center (most connected individuals) of the network.
Although several prior studies have also explored the epidemiological impacts of local and globally-informed vaccination decisions [48] [49] [50] [51] , ours is the first to consider a decision-model based on counts rather than fractions of infected contacts and to systematically compare three different decision paradigms across a range of network structures. Massaro et al. model two networks-the epidemiological contact network through which disease spreads and the social network through which risk information spreads. The more similar the two networks, the greater the individual and population-level protection achieved by vaccination [49] . This is consistent with our finding that locally-sourced decisions provide greater protection than globally-sourced decisions. Bagnoli et al. compare the local fraction strategy across contact networks with different degree distributions, and likewise found that the herd effect is magnified by heterogeneity in degree. [48] .
Given infinite resources, all three of the decision paradigms would markedly diminish an emerging outbreak. However, interventions may be constrained by limited supplies or lack of population access to medical countermeasures, such as vaccines or antimicrobials. Even social distancing measures, such as self-isolation, may be limited by economic necessity-the need to go to work, school or daycare-or care-giving obligations for extended family. While such limitations should be formally analyzed, our simple analysis suggests that the best paradigm for averting infections also requires the fewest resources. For example, for a flu-like R 0 of two, compare the local count strategy, where individuals protect themselves as their number of infected friends and family climb, to the global strategy, where decisions are based on population prevalence. For every individual that takes action, almost two infections are averted under the local strategy whereas less than one infection is averted under the global strategy. Local counting results in far fewer total infections (3% versus 13%) while requiring far less intervention resources (23% versus 60% of individuals taking protective action).
Several studies suggest that immunizing or isolating interventions should target the most connected individuals in a population [42] [43] [44] 52] . However, we rarely know the full contact network of a population. As proxies, we can target populations subgroups that tend to have high numbers of potentially disease-spreading contacts, such as young and school-aged children or health-care workers. We can also use biased sampling to identify highly connected individuals, such as the random acquaintance strategy in which random individuals are asked to name one of their social contact; individuals with more contacts are more likely to be named [68] [69] [70] [71] . In a sense, the winning paradigm of our study-counting infected contactssimilarly biases interventions efforts towards more connected parts of the network. The more connected one is, the more likely one is to have several infected contacts.
The model is intentionally simplistic, providing a best case scenario for each of the three strategies. We assume that resources are unlimited, protection is immediate and complete, and adherence probabilities perfectly mirror perceived risks. Furthermore, depending on the decision paradigm, individuals fairly accurately estimate the infectiousness of the disease, their number or fraction of infected social contacts, or the population average risk of infection. The model also assumes that individuals are short-sighted and make reactive decisions to avert immediate threat. We conjecture that the qualitative results of our analysis-the optimality of assessing risk based on the numbers of infected friends and family-are robust for a large class of 'on-the-fly' interventions that afford relatively rapid protection in the heat of an epidemic, but may not apply to preventative measures taken early in an outbreak or those with long efficacy lags. (For example, see alternative models presented in S1 and S2 Figs).
As a final caveat, we highlight our assumption that all edges (contacts) in our networks are equally likely to transmit disease. In reality, contacts can be highly heterogeneous, with household and health care contacts far more likely to transmit disease than casual social acquaintances. Our results should be robust when such heterogeneity is distributed randomly throughout the network. However, if individuals with more contacts tend to spend less time with each one, then epidemiological risk may be more homogeneous throughout the network and the advantage of the local decision strategies reduced. Although we do not model this scenario directly, we considered a homogeneous network where all individuals have the same number of contacts. This is roughly equivalent to mass action models that assume homogeneous contact rates and complete mixing [54] . The local strategies still prevail, but their relative efficiency is reduced, with far more vaccines required to achieve the same benefit ( Fig 5) . Conversely, in a network with greater heterogeneity (scale-free), the advantages of the local strategies are magnified.
This study prompts two practical questions. First, how do people actually make intervention decisions? Perhaps individuals fall nicely into one of these three decision-making camps. More likely, individual risk assessments are constrained by historical inertia [21, 24, 34, 46, 72] , influenced by decisions of friends and family [1, 3, 10, 26, 28, 46] , and integrate information from a combination of local and global data sources of variable reliability. Realistic decision models, driven by sociological survey data, can elucidate vaccine campaign failures and identify key pressure points for increasing uptake. Second, how can we streamline intervention campaigns to achieve efficient, rather than universal, adherence? This study reminds us that more intervention is not necessarily better intervention. The decision paradigm that most reduced transmission also required the least resources. Given the simplicity of our model, we do not suggest that public health agencies should promote 'infection-counting'. Rather, we conclude that public health agencies should prioritize local disease surveillance and risk communications efforts and believe that data-driven models can be instrumental in designing effective outbreak information campaigns.
Assuming R 0 = 5, an individual with k = 65 in our exponential network, we plot the probability of vaccination versus the proportion infected, which indicates either the fraction of neighbors infected (local prevalence and local count) or the overall fraction of the population infected (global prevalence). The behavior of the strategies that use prevalence is similar (blue); however, during the curse of a simulation, they have different values. 