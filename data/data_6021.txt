negatives, and false-negatives, respectively. Prevalence is the relative frequency of the positive class (i.e., prevalence = P/(P + N)). Unless mentioned otherwise, positives and negatives refer to patients with bacterial and viral infections, respectively.
We also used the area under the receiver operating curve (AUC) to perform cutoff independent comparisons of different diagnostic methods. For details on formulation and confidence interval (CI) computation of the AUC see Hanley and McNeil [1] . We report 95% CIs of the accuracy measures throughout this document.
The primary study objective was to obtain the performance of the signature for classifying patients with viral and bacterial etiologies. We estimate the sample size required to reject the null hypothesis that the sensitivity over the entire population, P, is lower than P 0 =75% (H 0 : P ≤ P 0 , H 1 : P > P 0 ) with significance level of 1% (α = 0.01), power of 90% (=1-β) for a difference of 15% (P 1 -P 0 ≥ 0.15), where P 1 is the empirical sensitivity. This yielded 394 patients (197 viral and 197 bacterial) . Additionally we anticipated that roughly 15% of the patients will have an indeterminate source of infection, 10% would be excluded for technical reasons and 10% will be healthy or non-infectious controls. Taken together, the study required the recruitment of at least 607 patients. This requirement was fulfilled because 1002 patients were recruited.
Systematic literature and bioinformatics screening was applied to identify 600 proteins candidates that had the potential to be differentially expressed in response to infection. The literature review included collection of proteins with a known role in immunity and inflammation both in humans and in animals. The bioinformatics screening included proteins that were differentially expressed on the RNA level across different infections and inflammatory conditions when measured using high throughput sequencing techniques such as microarrays.
We applied a feature selection process to identify the optimal combination of proteins. We used two feature selection schemes: mutual-information min-max [2] and forward greedy wrapper [3] , which use a series of iterations to add or remove features. The process was terminated when the increase in performance on the training set was no longer statistically significant (P>0.05). Both processes converged to the same final set of three proteins. To integrate the protein levels into a single score, we examined multiple computational models. Their performances were not significantly different (P>0.1 Supplementary Materials). We chose to a Multinomial Logistic Regression (MLR) model because it provides a probabilistic interpretation by assigning a likelihood score to a patient's diagnosis [4] . The signature uses this property to flag patients whose probability of bacterial infection is intermediate: between 0.35 and 0.55. We use the term 'marginal immune response' to describe these patients because their profile borders between bacterial and viral host-responses.
To integrate the protein levels into a single predictive score, we examined multiple computational models including Artificial Neural Networks (ANN), Support Vector Machines (SVM), Bayesian Networks (BN), K-Nearest Neighbor (KNN) and Multinomial Logistic Regression (MLR) [4, 5] . The AUCs for distinguishing between bacterial and viral infections obtained on the entire study cohort using a leave-10%-out cross validation were 0. . We did not observe significant difference in the performances of ANN, SVM and MLR models (P>0.1 when comparing their AUCs). We therefore chose to use MLR because it provides a probabilistic interpretation by assigning a likelihood score to a patient's diagnosis.
We trained and tested the MLR signature for distinguishing between bacterial, viral and non-infectious etiologies. Since the prevalence of underlying etiologies varies across different clinical settings, the model priors were adjusted to reflect a nonbacterial prevalence of 60% and bacterial prevalence of 40%. Within the non-bacterial group the priors were adjusted to 55% viral and 5% non-infectious, to reflect the anticipated higher prevalence of viral versus non-infectious patients among subjects with suspicious for acute infection. The MLR weights and their respective 95% confidence intervals, as well as the p-values associated with each coefficient are summarized in Tables S1-S2. In the bacterial versus viral infection analysis the probabilities were adjusted to sum up to 1 (P b_adjusted = P b /[P b + P v ] and P b_adjusted = P v /[P b + P v ], where P b and P v correspond to the probability of bacterial and viral infections respectively). 
In order to assess the validity of the MLR model we compared the estimated predicted probabilities with the actually observed outcomes (Fig. S1) . The predicted probabilities are highly compatible with the observed ones, further demonstrating the model validity. 
Non-linear MLR models have the potential to capture more subtle trends in the data compared to linear models, while retaining a probabilistic framework that allows meaningful interpretation of the model results. We examined multiple non-linear MLR models and applied feature selection process to identify the optimal feature combination (Section 2.4). The resulting model is depicted in Table S3 : 
Signature performance was further examined on the Study Cohort when excluding the following two subgroups: (i) patients whose blood sample was taken after more than 3 days of antibiotic treatment in the hospital and (ii) patients with a suspected gastroenteritis. The first group is likely to include patients at convalescence, which are responding to treatment and therefore their immune response at time of sampling is already non-bacterial. The second group showed slightly reduced performance ( Table S5 . 