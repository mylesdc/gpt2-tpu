We recall the utility function of individual i defined in the Methods section below,
for any σ i ∈ {0, 1} n → ([0, 1]) where σ * N i := {σ * j : j ∈ N i }. From the existence of a mixed Nash equilibrium in games with continuous payoffs, we know that a mixed MMPE exists for the game with payoffs (S1).
In the following we constructively show that in the stochastic disease network game with payoffs in (S1), a degenerate (pure) MMPE strategy profile σ * := {σ * i : {0, 1} n → [0, 1]} that satisfies the above relation in (S2) exists. Note that a degenerate distribution puts weight one on a single action value, that is, the strategy profile corresponds to a single action profile for any state.
Since in the stochastic game population response is determined by the current state of the disease only, i.e., equilibrium is stationary, it suffices to show the existence of a pure Nash equilibrium strategy for the stage game with state s ∈ {0, 1} n . A pure Nash equilibrium (NE) strategy profile σ * : {0, 1} n → [0, 1] n of the stage game with payoffs (S1) and state s satisfies
for any σ i ∈ {0, 1} n → ([0, 1]). We define the corresponding equilibrium action profile as a * := σ * (s) for a given state s. For a given individual i with state s i ∈ {0, 1}, neighbors' state s N i := {s j } j∈N i , and neighbor action profile a N i we have the best response of individual i as follows,
where 1(·) is the indicator function. Since the payoffs are linear in self-actions, the actions that maximize the payoffs are in the extremes -a i = 1 or a i = 0 -depending on the states and actions of their neighbors. We can equivalently represent the NE definition in (S3) as a fixed point equation by using the best response definition,
In the following we define the concept of strictly dominated action which will be a useful in finding the Nash equilibrium. . Since all individuals have singleton non-dominated action spaces, i.e., N \ (n(1) n(2)) = / 0, the process ends. Furthermore, the corresponding action profile is a Nash equilibrium of the stage game in (S1) by Lemma 2.
If an action a i is strictly dominated then there exists a more preferable action a i for any circumstance. It is clear that if an action is strictly dominated then it cannot be a rational action from (S6). In a game we can iteratively remove the strictly dominated actions, this process is called the iterated elimination of strictly dominated strategies and is defined below.
Definition 2 (Iterated elimination of strictly dominated actions) Set the initial set of actions A 0 i = [0, 1] for all i, and for any k ∈ N set
We denote the set of actions of individual i that survive the iterated elimination by A ∞ i := ∞ k=0 A k i . When A ∞ i has a single element, we say A ∞ i is a singleton. We formally state an iterated elimination process for the game in (S1).
Definition 3 (An iterated elimination process for the epidemic game) Begin with action spaces A 0 i = [0, 1] for all i ∈ N . Fix s ∈ {0, 1} n . Iterate k = 1, 2, . . .
If n(k) = / 0 then stop iteration of k.
Our next result shows that the process described above eliminates all strictly dominated strategies in finite time.
Lemma 1 Consider the process described in Definition 3. There exists an iteration step k ≤ n such that {A k i } i∈N are the set of actions that are not strictly dominated for the game with payoffs (S1) and state s ∈ {0, 1} n .
Proof: First consider the odd iteration steps, k = odd. If the condition inside the bracket in (S9) holds then for any action that individual j ∈ N i \ l=even n(l) takes, a i = 1 dominates any other action a i ∈ [0, 1] \ {1} by Definition 1. To see this first 2/14 recall the best response of individual i (S5). Note that by the even steps, individuals j ∈ l=even n(l) have a j = 0 as the only not dominated action. Hence the best response of individual i can be rewritten as
where we remove neighbors that only have zero as the not dominated action. If the inequality inside the indicator function is true even when the remaining neighbors of i take action 1, then a i = 1 dominates all the other actions [0, 1) of i, that is, for all a j ∈ [0, 1] for j ∈ N \ i,
Assuming the left hand side of the above inequality is one then by the definition of strictly dominated action in Definition 1, a i = 1 is the only action that is not dominated. Next, we consider the even iteration steps, k = even. If the condition inside the bracket in (S10) holds then for any action that individual j ∈ N i \ l=odd n(l) takes, a i = 0 dominates a i ∈ [0, 1] \ {0} by Definition 1. To see this first recall the best response of individual i (S5). Note that by the odd steps, individuals j ∈ l=odd n(l) have a j = 1 as the only not dominated action. Hence the best response of individual i can be rewritten as
where we separate neighbors j ∈ N i l=odd n(l) that only have a j = 1 as the not dominated action from the other neighbors j ∈ N i \ l=odd n(l). If the inequality inside the indicator function is false even when the remaining neighbors of i take action 0, then a i = 0 dominates all the other actions (0, 1] of i, that is, for any a j ∈ [0, 1] for j ∈ N i \ l=odd n(l)
Assuming the left hand side of the above inequality is one then by the definition of strictly dominated action in Definition 1, a i = 0 is the only action that is not dominated. Further if no individual can eliminate a dominated strategy n(k) = / 0 at an iteration k then at following iterations k + 1, k + 2, . . . there won't be any individuals that eliminate any actions as strictly dominated. To see this, assume the opposite is true, that is, n(k + 1) = / 0. Since n(k) = / 0 then the condition in n(k + 1) is identical to the conditions inside (S9) or (S10) for n(k − 1) depending on whether k + 1 is odd or even, respectively. There cannot be an individual that satisfies the conditions at iteration k + 1 because n(k + 1) is selected among individuals that have not been previously in any set, i.e., i ∈ N \ k l=1 n(l). This contradicts n(k + 1) = / 0. As a result, at each iteration k the number of individuals in n(k) has to be positive until an iteration step n(k) at which either there is no individual left N \ k l=1 n(l) = / 0 or there is no individual that satisfies the condition after the colon in (S9) or (S10).
Suppose now that the process stops at iteration k, i.e., n(k) = / 0, but there exists an individual i ∈ N \ k−1 l=1 n(l) with strictly dominated action (S7) a i ∈ A k i . Suppose k is odd then by (S12), any action a i ∈ A k i \ {1} must be dominated by a i = 1. Suppose k is even, then by (S14) any action a i ∈ A k i \ {0} must be dominated by a i = 0. Then n(k) = / 0 which is a contradiction. This
together with the fact that if n(k) = / 0 then n(l) = / 0 for l > k implies that if the process in Definition 3 stops all the strictly dominated strategies are eliminated.
Finally, the fact that the number of elements of n(k) is positive at every iteration except the last iteration in Definition 3 implies that the iteration ends in at most n iterations.
The following Lemma shows that once all the strictly dominated strategies are eliminated, the action profile that assigns socialize to susceptible individuals and do not socialize to infected individuals is a pure Nash equilibrium strategy profile.
Lemma 2 Consider the game defined by the payoffs in (S1) given state s ∈ {0, 1} n and the iterated elimination process in Definition 3. Denote the action space of i ∈ N that is not strictly dominated by
is not a singleton then let a * i = 1 for s i = 0 and a * i = 0 for s i = 1. The resulting action profile a * is a pure Nash equilibrium of the game.
Proof: We will use the following equivalent definition in (S6) of Nash equilibrium for the stage game in (S1),
Note that at the end of the elimination process in Definition 3, the action space of an individual i is either a singleton or is equal to A * i = [0, 1]. A strictly dominated action cannot satisfy the above equation, hence the equilibrium action of an individual with a singleton non-dominated action space is given by a
is not a Nash equilibrium action. Then individual i can deviate and by the above equation it must be that a * i = 0 is a Nash equilibrium action because
Note that by our assumption a * j = 0 for all the infected individuals (s j = 1) at which 0 is not a strictly dominated action, i.e., when A j = [0, 1]. Hence in the right hand side of the above inequality only individuals that do not have 0 in their not dominated action set will matter. Furthermore, if 0 is a strictly dominated action, socialize action 1 is the only remaining not strictly dominated action. Hence, we can write the above inequality as follows,
Now note that if the above inequality is true then 1 should be strictly dominated by action 0 for individual i. Hence, it is a contradiction to the fact that the action space is not a singleton, A * i ∈ [0, 1]. A similar contradiction argument can be made for the infected individuals (s i = 1) and the equilibrium action a * i = 0. Therefore, the action profile described in the statement must be a pure Nash equilibrium of the game.
Lemma 1 shows that the process in Definition 3 eliminates all dominated actions in finite time. Furthermore, if all individuals are included in the process, i.e., if N = n k=1 n(k) then we end up with a singleton action profile that is not strictly dominated. This means the game has an unique pure Nash equilibrium by definition of strictly dominated action. If at the end of the process in Definition 3, if all individuals are not included in the process, i.e., N \ n k=1 n(k) = / 0 then the set of not strictly dominated actions is not a singleton. Lemma 2 proposes a pure strategy profile that is a Nash equilibrium of the game in (S1) for the case that action spaces of individuals that survive strict elimination process are not all singleton.
Lemmas 1 and 2 considered the stage game with payoffs (S1) given state s ∈ {0, 1} n . An MMPE strategy profile σ is a mapping from any state to the action space. We can obtain a pure MMPE strategy profile using Lemma 2 for all possible states s ∈ {0, 1} n . That is, we use the elimination process in Definition 3 and the action assignment given in Lemma 2 for all the states to construct an MMPE strategy profile. In our simulations, in this paper, we construct the MMPE equilibrium strategy profiles following this process -see Fig. S1 for an example.
In this section, we consider the sub-optimality of the decisions of individuals that play according to an MMPE strategy profile. By the definition of MMPE strategy, individuals consider current payoffs and play according Nash equilibrium strategy of that stage game. In the following we show the worst stage game Nash equilibrium strategy can be n fold worse than the optimal action profile given a network and state.
Define the stage game Γ(s, G , c) with payoffs in (S1) parametrized by the disease state s, contact network G and utility constants c := {c 0 , c 1 , c 2 }. The welfare value of the action profile a in this game is the sum of utilities of the individuals,
(S18)
Note that the first summation is over all the individuals and the second summation is over all the edges E in the network G . We define the optimum action profile as the maximizer of the welfare function above, i.e., a opt = argmax a W (a, s(t)). We denote the set of Nash equilibrium action profiles by A * and define the price of anarchy (PoA) as the ratio of the worst possible Nash action profile to the optimum action profile,
.
(S19)
Obviously, PoA ≤ 1. In the following we provide a lower bound on the price of anarchy.
Proposition 1 For a game Γ(s, G , c), the price of anarchy (S19) has the following lower bound
where |N i | is the degree connectivity of i.
Proof: Consider the derivatives of u i in (S1) and W in (S18) with respect to a i , respectively,
First note that ∂ u i ∂ a i ≥ ∂W ∂ a i for any s and a −i because
Therefore, given actions of others a −i and state s, it could be that ∂ u i ∂ a i > 0 while ∂W ∂ a i < 0. Consider the optimal and equilibrium action profiles where a opt j = a * j for j ∈ N \ i, and a opt i = 0 but a * i = 1. That is, we have ∂ u j ∂ a j < 0 and ∂W ∂ a j < 0 for all j = i but ∂ u i ∂ a i > 0 while ∂W ∂ a i < 0. Then, the difference between the equilibrium profile welfare W (a * , s) and optimal action profile welfare W (a opt , s) is equal to (S23), that is,
We divide the difference above by W (a opt , s) to get
A trivial lower bound on the term for the numerator above is − max(c 1 , c 2 )|N i | for any state s. Furthermore a trivial upper bound for W (a opt , s) is nc 0 . Using these bounds we obtain a bound for the above equality, Now note that the choice of the individual i is arbitrary. When this individual is the individual with the largest number of neighbors we get a lower bound on the right hand side of the above inequality which is the worst case lower bound on the price of anarchy in (S20). Note that this upper bound can be arbitrarily bad, i.e., in the order of 1/n. In the discussion following Figure 2 (d) in the main text we show that this bound is tight. We repeat this example below. The first Nash equilibrium is also the optimal action profile a opt yielding a welfare of (n − 1)c 0 . The second Nash equilibrium a * obtains a welfare of c 0 resulting in a PoA of 1 n−1 . Another example on a star network follows.
Example 2 Consider the star network shown in Figure S2 . The center individual 1 has n − 1 neighbors and is the only infected individual. Constants are such that c 0 = c 1 + ρ 1 and c 0 = (n − 1)c 2 + ρ 2 for arbitrarily small positive constants ρ 1 > 0 and ρ 2 > 0, so that c 0 < (n − 1)(c 1 + c 2 ). The unique NE action profile is that all individuals are social, a * i = 1 for all i ∈ N . The welfare for the NE is W (a * ) = nc 0 − (n − 1)(c 1 + c 2 ) = (n − 1)ρ 1 + ρ 2 . The optimal action profile is that only the susceptible nodes are social a opt i = 1 for i = 1 and a opt 1 = 0. The welfare for the a opt is W (a opt ) = (n − 1)c 0 . Then PoA ≈ ρ 1 /c 0 for large n.
Here, we see that PoA is determined by the closeness of c 1 to c 0 . Note that in this example, equilibrium is unique and, unlike Example 1, the optimal action profile is not a Nash equilibrium.
Another notion that enables us to gauge the optimality of equilibria is the Price of Stability (PoS). PoS is the ratio of the best possible Nash action profile to the optimum action profile,
Note that PoS ≤ 1 by definition of a opt . We remark that in Example 2, the equilibrium is unique, meaning PoS = PoA. Therefore, not only the PoA but also the PoS can be arbitrarily bad.
We formally define the reproductive ratio R 0 in the following.
Definition 4 Let the initial state of the population be given by s(1) where s i (1) = 1, otherwise s j (1) = 0 for all j = i for some randomly selected individual i. Then R 0 is the expected number of individuals that contract the disease from the randomly selected individual i until i heals,
where 1(s j (t + 1) − s j (t) = 1, i → j) is the indicator function that is one if individual j transitions to an infected state at time t and i is the one infecting j, and 1 (s i (l) = 1 for l < t) is the indicator function that is one if individual i has not healed yet. The outside expectation is with respect to the uniform distribution that selects the initial infected individual, and the inside expectation is with respect to the transition probabilities of the Markov chain.
In the following, we derive bounds for R 0 given that individuals act according to an MMPE strategy profile and we select the initial infected individual randomly from the network.
Theorem 1 Consider a network with degree distribution P(k). Assume the infected individual is chosen from the population uniformly at random. Scale c 0 with β for convenience, i.e., c 0 := β c 0 , and assume c 0 > c 1 .Assume c 0 > c 1 . Then R 0 defined in (S29) has the following upper bound,
where K := min( c 0 /c 2 , n).
Proof: We start by moving the second expectation inside the sum in the definition of R 0 (S29) to get the following,
Now consider the conditional expectation inside the summation which we can equivalently represent as the following conditional probability E[1(s j (t + 1) − s j (t) = 1, i → j)1 (s i (l) = 1 for l < t) s(1)]
= P s j (t + 1) − s j (t) = 1, i → j, s i (l) = 1 for l < t s(1) .
Note that the above conditional probability is the probability that j is infected by i at time t and i remained infected until time t given i is infected at t = 0. Using the chain rule and law of total probability, we can write the above conditional probability as follows P(s j (t + 1) − s j (t) = 1, i → j, s i (l) = 1 for l < t s(1)) = P s j (t + 1) − s j (t) = 1, i → j s i (t) = 1, s j (t) = 0, s(1) P(s i (t) = 1, s j (t) = 0 s i (l) = 1 for l < t, s(1))
Note that the first four lines on the right hand side equal to the probability that i infects j at time t given that i remained infected until t − 1 by law of total probability. The last line is the probability that i remained infected given that i started infected since s i (1) = 1. Observe that the probability that i infects j is zero if individual i is susceptible at time t or individual j is infected, i.e., P s j (t + 1) − s j (t) = 1, i → j s i (t) = 0 = 0 or P s j (t + 1) − s j (t) = 1, i → j s j (t) = 1 = 0. Hence only the first line of the four line expression is nonzero which simplifies the identity above as follows P(s j (t + 1) − s j (t) = 1, i → j, s i (l) = 1 for l < t s(1)) = P s j (t + 1) − s j (t) = 1, i → j s i (t) = 1, s j (t) = 0, s(1) P(s i (t) = 1, s j (t) = 0 s i (l) = 1 for l < t, s(1)) P s i (l) = 1 for l < t s(1) (S34)
The probability of healing at each step is independent, hence the last conditional probability is equal to (1 − δ ) t−1 . The conditional probability that i remains infected and j is infected at time t given that i is infected until time t is less than 1 − δ by the argument below, P(s i (t) = 1, s j (t) = 0 s i (l) = 1 for l < t, s(1)) = P(s j (t) = 0 s i (t) = 1, s i (l) = 1 for l < t, s(1))P(s i (t) = 1 s i (l) = 1 for l < t, s(1)) (S35)
(S37)
The first equality above follows by chain rule. The inequality follows by the fact that the probability is less than one. The second equality is true by the transition probability of individual i from an infected state. Substituting these identities inside the equation (S34) we obtain the following
Now consider the conditional probability on the right hand side of (S38), the probability that j is infected at time t + 1 by i given that j is susceptible and i is infected at time t. We have the following upper bound,
The first equality is by the fact that s j (t + 1) = 1 if s j (t) = 0 and s j (t + 1) − s j (t) = 1. The second equality above is by the law of total probability and by the fact that if i or j takes an action to self-isolate, i.e., a j (t) = 0 or a i (t) = 0, then i cannot infect j. The inequality follows by the fact that P a i (t) = 1, a j (t) = 1 s i (t) = 1, s j (t) = 0 ≤ P a i (t) = 1 s i (t) = 1, s j (t) = 0 . The last equality follows because if both agents socialize at normal levels then the infection probability is β when agent j and i are connected, j ∈ N i . Now we consider a * i (t). We know that the MMPE action of individual i is a best response to best response actions of neighbors from (S6) where best response function is given by (S5). Specifically from the perspective of an infected individual i, the best response action is given by the following
. Also note that if a * i (1) = 1 then a * i (t) = 1 for all t > 1. Moreover, if a * i (1) = 0 then i never infects another node if it is the only initially infected individual. Hence, we have a * i (t) = a * i (1) for all t. That is, the action of agent i at time t is determined by the initial action and is independent of the state at time t. Therefore, we can write
Substituting the above identity in (S39) and using (S39) in (S38), which then we substitute to (S32), we get the following upper bound for R 0 in (S31),
Now note the indicator function terms depend on the network of individual i but they do not depend on the identities of the neighbors. In fact, ∑ n j=1 1( j ∈ N i ) is equal to the number of neighbors of i, i.e., |N i |. In addition, we have ∑ ∞ t=1 (1 − δ ) t = 1/δ . Using these identities, we can write the above bound as follows,
Individual i is chosen uniformly random and it has k neighbors with probability P(k), therefore, the expectation on the right hand side is equal to the following,
Bound in (S30) follows.
Corollary 1 Consider a random scale free network where the degree distribution follows P(k) ∼ k −γ for γ = 2. Then R 0 defined in (S29) has the following upper bound,
Proof: We directly use the bound in (S30) and substitute in P(k) = L(−2, n)k −2 where L(−2, n) = (∑ n k=1 k −2 ) −1 is the normalization constant for the scale-free distribution
We first upper bound the normalization constant L(−2, n) by the fact that ∑ n k=1 k −2 > 2 − 1 n . Hence, L(−2, n) ≤ n 2n−1 . Next we note that the summation behaves logarithmically which yields the desired bound in (S45).
We formally define the reproductive ratio R * in the following.
Definition 5 Let the initial state of the population be given by s(1) where s i (1) = 1, otherwise s j (1) = 0 for all j = i for some randomly selected individual i. The probability that we select an initial sick individual with degree k is given by Q(k) := kP(k) ∑ k kP(k) . Then R * is the expected number of individuals that contract the disease from a randomly selected individual i until i heals,
is the indicator function that is one if individual j transitions to an infected state at time t and i is the one infecting j, and 1 (s i (l) = 1 for l < t) is the indicator function that is one if individual i has not healed yet. The outside expectation is with respect to the probability distribution Q(k), and the inside expectation is with respect to the transition probabilities of the Markov chain.
Below we present a bound for R * for a generic network. Proof: First note that the only difference between the R 0 definition and R * is the difference in probability distributions of selecting the initial infected individual. Hence, the bound in (S43) applies to R * which we repeat here for convenience,
where now the expectation is with respect to the distribution Q(k). Therefore, the expectation on the right hand side is equal to the following,
Bound in (S48) follows by using the definition of Q(k) = kP(k) ∑ k kP(k) .
Corollary 2 Consider a random scale free network where the degree distribution follows P(k) ∼ k −γ for γ = 2. Then R * given by Definition 5 has the following upper bound,
Proof: We directly use the bound in (S48) and substitute in P(k) = L(−2, n)k −2 where L(−2, n) = (∑ n k=1 k −2 ) −1 is the normalization constant for the scale-free distribution
The bound in (S51) follows by noting that ∑ n l=1 l −1 ≈ log(n).
See Figure S3 for the effect of parameters c 1 , c 2 , β on eradication time.
See Figure S4 for the effect of parameters c 1 , c 2 , β on infectivity level. 
In the preferential attachment model, used in Figures 4-6 of the main text, a node is added at each step and is connected to an existing node selected randomly proportional to their degree-see the Barabasi-Albert algorithm 1 . A modification to this algorithm is when each added node is connected to two existing nodes selected randomly proportional to their degree. This modified algorithm generates scale-free networks with an expected scaling degree of γ = 2.3 while the non-modified preferential attachment algorithm generates an expected scaling degree of γ = 2.
In Figure S5 , we test the accuracy of the bounds for R 0 and R * in equations (S30) and (S48) (equations (1) and (4) in the main text) for scale-free networks generated according to the modified preferential attachment algorithm. Using these inequalities and substituting for P(k) = L(−2.3, n)k −2.3 where L(−2.3, n) is a normalizing constant, we solve for empathy constant values c 2 that make the right hand side of equations (1) and (4) less than one -see the caption of Fig. S5 for the critical empathy values. We note that the closed form critical thresholds of the empathy constant c 2 in equations (S45) and (S51) (equations (3) and (6) of main text) are obtained when the network is scale-free with scaling degree γ = 2. The critical empathy values obtained for γ = 2.3 are greater than the critical empathy values when γ = 2. Numerical experiments show that the critical empathy constants that make R * < 1 are still good indicators of fast disease eradication.
We assess the robustness of the critical empathy threshold to initial conditions by considering initial infectivity levels of {5%, 20%, 50%} in Figure S6 . Besides the difference in initial conditions, the numerical setup is identical to Figure 6 in main text. The numerical experiments confirm that the critical empathy threshold for R * in (S51) is a good indicator for disease eradication. There are only a few runs which fail to eradicate the disease within 200 time steps when the critical empathy for R * < 1 is exceeded -refer to the caption of Figure S6 (S53)
That is, the infected will socialize normally at all times and a susceptible agent will socialize if the number infected around is less than c 0 c 1 . Given the MMPE profile above, the infection probability of a susceptible individual i is given by . The rate of disease eradication is above 95% among 50 trials when the value of the empathy constant is above the threshold that makes R * < 1. That is, for c 2 that make R * < 1 there are only a few trials that fail to eradicate the disease within 200 steps which are observed when β = 0.1 and 20% initially infected, and when β = {0.2, 0.3}.