Background: The 2009 influenza A (H1N1) pandemic caused surges of patients in intensive care units (ICUs) in resource-limited settings. Several Ministries of Health requested clinical management guidance from the World Health Organization (WHO), which had not previously developed guidance regarding critically ill patients.
In low-and middle-income countries (LMICs), as defined and classified by the World Bank on the basis of gross national income per capita, 1 the burden of critical illness is high, with a significant proportion attributable to acute infections. 2 In particular, lower respiratory infections are the third leading cause of disability-adjusted life years lost and disproportionately affect Africa and the Eastern Mediterranean and South East Asian regions. 3 Thus, improving the care of critically ill patients with acute respiratory infections is of public health importance.
A major challenge to meeting this objective is the global variation in the quantity and quality of critical care delivery. 2, 4 LMICs may have limited access to basic hospital infrastructure, 5 essential health technologies (oxygen, medicines), 6 intensive care units (ICUs) and other resources (including evidence-based practice protocols). 5, [7] [8] [9] [10] [11] Even in ICUs with life support technologies, healthcare staff may not be adequately trained. 12 The need to strengthen healthcare systems to improve care for patients with acute respiratory infections was emphasized by the global experience with severe acute respiratory syndrome (SARS), 13 avian influenza A (H5N1), 14 the 2009 influenza A (H1N1) pandemic, 15, 16 Middle East respiratory syndrome coronavirus (MERS-CoV) 17, 18 and avian influenza A (H7N9). 19, 20 Many patients with these emerging pathogens developed respiratory failure or other organ dysfunction, creating a surge of critically ill hospital admissions in constrained healthcare systems. Therefore, outbreaks of infectious diseases causing critical illness could potentially be detected in hospital settings that care for such patients, such as the ICU and emergency department, which therefore become logical targets for health system strengthening.
During the 2003 SARS epidemic, the WHO formed a core clinical advisory network. In response to human infections with avian influenza A (H5N1) and the 2009 influenza A (H1N1) pandemic, this network produced clinical management guidance, 21 
Phases in the development of the Critical Care Training Short Course are described in Table 1 . In both the pilot and implementation phases,
we assessed participants' satisfaction (using self-administered surveys) and content knowledge (using a written multiple-choice test) before and after the course.
We did not seek research ethics board approval because this course and its evaluation were designed and conducted as part of routine WHO activities. 
Over the next few months, 35 international experts (Appendix S1) contributed feedback or materials to the course. Experts had spe- Participants reported the technical content to be pertinent and up to date, but recommended that the presentations be transformed into a more interactive, practical and adult-learner friendly format.
In response, the WHO partnered with Agence de Médecine
Préventive (a non-profit organization for preventive medicine and public health with instructional design expertise, Paris, France)
to transform the materials into a 3-day integrated and interactive training course with fourteen learning units ( After each pilot course, revisions were made to materials based on feedback from participants (Table S1 ).
We developed a self-administered participant satisfaction survey with questions regarding learning environment, teaching materials and methods, and facilitators. Response frames used a Likert scale (range, 1-5, very poor to very good) with space for free-text comments. We also developed a multiple-choice single best answer test 
We report descriptive data as percentages (categorical data) and means and standard deviations (continuous data, which were all normally distributed). At each course, (i) mean scores on the pre-test and post-test were compared using unpaired t tests (because participants' names were not consistently recorded), (ii) a mean overall satisfaction score for each participant was calculated for each of 14 learning units and for the introduction (possible range, 1-5, with 1 denoting very poor and 5 denoting very good). For each workshop, we report the mean of these mean scores and the range of the means.
We report the results for pilot courses by country because the content was iteratively modified after each course. For the implementation in Central Asia, the courses were delivered over 4 months, with the materials unchanged, and we therefore reported results from all participants together. In addition, we report qualitative comments from course participants and facilitators.
The Appendix S1. Learners in all 3 pilots rated the learning units as good to very good (range of mean Likert scores 3.9 to 4.9), with significant improvement in test scores after training (P < .001, Table 3 ).
In 2013, the Critical Care Training Short Course conducted inaugural implementation courses upon request of the WHO EURO Regional (Table S3) .
Participants rated the learning units as good to very good (range of mean Likert scores 4.6-4.8, and test scores showed significant improvement after training (P < .001, Table 3 ). On written comments, participants requested more time for the course, additional courses using a train-the-trainers model, and more comprehensive materials on mechanical ventilation, in addition to those provided on ARDS.
Facilitators noted that many international critical care guidelines, such as those of the Surviving Sepsis Campaign, were not readily available to participants; therefore, this course introduced some core concepts.
The It can be deployed rapidly to assist clinicians during public health emergencies caused by novel respiratory virus infections, but can also be incorporated into continuing medical education using a train-the-trainers model. TA B L E 3 Critical Care Training Short Courses: participants' evaluation and test performance Our work has important strengths. Development of the materials was publicly financed, free of commercial influence and included input from a broad spectrum of experts with experience in resourcelimited settings. This intervention addressed the challenge of bringing evidence-based care to the bedside of patients by adapting materials to the needs of clinicians who may not be formally trained in critical care, emphasizing the provision of safe care and using an interactive teaching approach. The teaching materials were developed in a process of peer review, refinement and pilot testing and were designed by collaboration between critical care and instructional design experts. The participants rated the course's content, structure and teaching methods highly. International facilitators delivered the course and mentored local clinicians to conduct future trainings. We also observed that the course provided a forum for local, national, regional and global networking that was valued by many clinicians.
Our approach also has limitations. First, the timeline was long, 