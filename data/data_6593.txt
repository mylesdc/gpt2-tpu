Here we present technical and mathematical results supporting the main paper.
1 Solution of the linear compartmental model 1 
Consider the continuous-time Markov chain X = (X(t)|t ∈ R + ) with state space S = {i} m i=1 , m ∈ N, and rates γ = (γ 1 , . . . , γ m−1 ), γ i ∈ R + , ∀ i ∈ S \ {m}. For convenience we will set γ m = 0.
This has the following m × m generator matrix
which in component form reads
X has an absorbing state at i = m, a unique stationary distribution π * such that [π * ] i = δ i,m , but it is not irreducible, ergodic or reversible (since p ij (t) = 0, ∀ i ≤ j ∈ S).
We now try to solve the system dπ dt = Mπ, π i (0) = δ i1 ,
for different relationships between the rates γ.
The solution to (3) is simpler if all of the rates are distinct, i.e. if γ i = γ j ∀ i = j ∈ S \ {m}. We will use two different methods to solve this system.
Here we start by finding the eigenvalues of M, we solve the characteristic equation
By noting that the matrix M − λ½ is lower triangular, we see that its determinant is the product of its diagonal entries and so 
The eigenvectors equation can then be written in component form as
Now define a matrix A whose i-th column is the i-th right eigenvector of M so that M = AΛA −1 , where Λ is a diagonal matrix with i-th diagonal element equal to γ i . Substituting for M ij as in (2) and rearranging, we have
and so since γ i−1 = 0, A ij = 0 for i < j. If we set A ii = 1, then by induction we have
and so the matrix A is also lower triangular. We then write the solution to (3) as π(t) = e Mt π(0) = Ae Λt A −1 π(0) = Ae Λt c ,
where c is a vector obeying Ac = π(0). Clearly, c 1 = 1 and for i = 1
Let us consider the possible solution
Then for i = 1, (10) becomes
and so
Now we can show that expression (13) holds for all γ i = γ j ∈ R, i = j.
Proof. Let there be a set {γ i } n i=1 s.t. γ i ∈ C, n ∈ N and γ i = γ j ∀ i = j. Now consider the expression
Using the formula for partial fraction decomposition
Combining this with the eigenvectors/values of M we can substitute into (9) to give
For the more general case, there are benefits to a Laplace transform approach, which we will introduce here. We define the Laplace transform of a function f :
Laplace transforming (3) then gives sπ − π(0) = Qπ .
If s is not an eigenvalue of Q, then the matrix s½ − Q is invertible and
We can then calculate the inverse Laplace transform using the residue theorem. Considering the explicit form of (17) for our model, if we let B(s) = s½ − Q, where s = −γ i ∀ i ∈ S, then B is invertible and we need to find B −1 π(0) where [π(0)] i = δ i1 , or in component form
Using BB −1 = ½, and noting that B is lower triangular, we have that
For i = 1:
and so
Then finding π i (t) reduces to calculatingL
all the poles s = −γ i off are order 1, and so using the residue theorem we havê
and so finally
which is equivalent to (14).
Lets now take derivatives with respect to the model parameters {γ i }. This can be most easily done in the Laplace domain since we can use the fact that
and so
Using the convolution theorem for Laplace transforms, we havê
which can be checked by computing the derivative directly from (14).
Consider a general, pure birth chain with m = N + 1 states {I} N +1 I=1 , and M distinct parameters
Let us find solutions to (3) using the Laplace transform method. Again defining
. . , M }, and following the same procedure in §1.2.2, we can write down
where m I ∈ {1, 2, . . . , M } and k I ∈ {1, 2, . . . , n m I } are counting variables defined by the relationship
Then to calculate π I (t), we notice thatf (s) = (s + γ m I ) −k I m I −1 j=1 (s + γ j ) −n j has poles at s = −γ 1 , . . . , −γ m I −1 , −γ m I , of order n = n 1 , . . . , n m I −1 , k I respectively, and sô
Now consider function g(s) such that
and using a simplified form of Faá di Bruno's formula d p ds p e g(s) = e g(s) B p g ′ (s), g ′′ (s), . . . , g (p) (s) ,
where
then we can use the identity
and so finallŷ
Here
This gives the overall solution
where we define γ 0 := 1, γ M +1 := 0, n M +1 := 1, m N +1 := M + 2 and k N +1 := 0 for simplicity of notation.
An analytic expression also allows us to calculate derivatives in a similar way to §1.2.3. Taking a derivative of the Laplace transform, we get
otherwise.
So we need to calculate expressions of the formL −1 {(s+γ r ) −1π j (s)}. Rather than use the convolution theorem as before, here we apply the residue theorem multiple times. The first application giveŝ
whereK I,r (t) is a n r × n r matrix with components 
The second application of the residue theorem giveŝ
This gives the full final expression as
2 Metric for the shedding models
We first note the straightforwardly-obtained result that if φ is the pdf of a normal distribution with mean µ(θ) and standard deviation σ(θ), then the Fisher-Rao metric will contain terms like
We now consider how this metric is calculated for the four different shedding models considered in the main paper.
For the simple SIR model defined in the main paper (Eq. (14)) we have
The derivatives are therefore
Substituting into (41) gives the Fisher-Rao metric as having the following form:
This has the issue that there is full unidentifiability, reflected in the fact that this metric attributes zero distance to travel along constant-τ e −γ curves. Our solution to this problem is to add an amount of distance in these directions to give full metric
where α is a constant parameterising the amount of distance added.
While it was not necessary to do this for any of our other models, we suggest that as a general methodological point if an initial metric took a form similar to (45), but for very small α that caused potential numerical issues with forming its inverse, then it may be advisable to increase the value of α by hand.
Here our likelihood is given by a product of normal probability density functions
where
π i (t, γ) =: τ π(t) , σ(t) = σ t is given in data.
Given the results above for π i (t), we can then write down that for influenza the metric has components
For Ebola, we have to consider both high-and low-viraemic pathways of infection separately, but otherwise the metric is
Our norovirus model has the same form as (46) except that σ(t) = σ is a model parameter.
Since for these data we have a large number of approximately uniformly-distributed time points, we use integrals rather than sums over time for computational efficiency leading to expressions
which can be straightforwardly computed from the results above.
We can include the contribution of a rate-ρ a exponential prior on θ a through performing calculations for uniform / improper priors and then making the transformation
For SMMALA the metrics we have considered so far are all that is required, and have the primary benefit of introducing local second-order derivative information into the MCMC algorithm, but for WLMC we make additional use of the possibilities for reduction of global distances possible in a geometric approach.
3 The WLMC algorithm
The 'HMC' dynamics introduced in the main paper can be generalised to a geometric approach in two ways. The 'RMHMC' approach of [2] involves Hamiltonian dynamics with a discretized integrator, the generalized leapfrog method [6, 2] , which requires significant numerical effort, in particular fixed-point iterations, to solve implicit equations. This step is potentially computational intensive (repeated matrix inversion of G(θ) involves O(D 2.373 ) operations in dimension D), and can sometimes be numerically unstable [3] .
To address this issue, Lan et al. [4] propose an explicit integrator for geometric MCMC by using the following Lagrangian dynamics:
where v(0) := G(θ(0)) −1 p(0) ∼ N (0, G(θ(0)) −1 ), and Γ(θ) are Christoffel Symbol of the second kind whose (i, j, k)-th element is Γ k ij = 1 2 g km (∂ i g mj + ∂ j g im − ∂ m g ij ) with g km being the (k, m)-th element of G(θ) −1 .
The following explicit integrator can then be derived for these dynamics:
where Ω(θ (ℓ) , v (ℓ) )) kj := (v (ℓ) ) i Γ(θ (ℓ) ) k ij . Such an integrator is time reversible but not volume preserving. The acceptance probability is adjusted to have the detailed balance condition hold [4] :
where the Jacobian determinant is
and E(z) is the energy for the Lagrangian dynamics defined as:
The resulting algorithm, Lagrangian Monte Carlo (LMC) is a valid exact sampler and has the same strength in exploring complex geometry as RHMC does. LMC is sometimes more efficient and stable than RHMC -for more details see [3, 4] .
When the target distribution is multi-modal, derivative-based and geometric algorithms tend to fail as they are easily trapped in some of the modes without visiting all of them. Making proposals by numerically simulating Hamiltonian dynamics, the sampler has difficulty in passing through low probability regions [7] . Compared to HMC, the geometric RHMC and LMC methods perform even worse in relation to this issue because they are more adapted to the local geometry and more likely to be trapped in one mode.
To overcome this issue, some kind of global knowledge of the distribution needs to learned and incorporated. Lan et al. [5] proposed the idea of using wormholes for these geometric algorithms (HMC/RHMC/LMC) to work on multi-modal distributions. The proposed method comes in 2 parts: a distance-shortening metric and a mode-jumping mechanism.
Letθ 1 andθ 2 be two modes of the target distribution. We define a straight line segment, v W :=θ 2 −θ 1 , and refer to a small neighborhood (tube) of the line segment as a wormhole. Next, we define a wormhole metric, G W (θ), in the vicinity of the wormhole. For a pair of tangent vectors u, w at θ, wormhole metric G W is defined as follows
where v * W = v W / v W , and 0 < ε ≪ 1 is a small positive number. To see that G W in fact shortens the distance betweenθ 1 andθ 2 , consider a simple case of a straight line: θ(t) =θ 1 + v W t, t ∈ [0, 1]. In this case, the distance under G W is
which is much smaller than the Euclidean distance.
Next, we define the overall metric, G, for the whole parameter space of θ as a weighted sum of the base metric G 0 and the wormhole metric G W ,
where m(θ) ∈ (0, 1) is a mollifying function designed to make the wormhole metric G W influential in the vicinity of the wormhole only.
For more than two modes, the above method alone could suffer from two potential shortcomings in higher dimensions. First, the effect of wormhole metric could diminish quickly as the sampler leaves one mode and moves towards another mode. Secondly, such a mechanism, which modifies the dynamics in the existing parameter space, could interfere with the native dynamics in the neighborhood of a wormhole, possibly preventing the sampler from properly exploring areas around the modes as well as some low probability regions.
To address the first issue, we add an external vector field to enforce the movement between modes. More specifically, we define a vector field, f (θ, v), in terms of the position parameter θ and the velocity vector v = G(θ) −1 p as follows:
with mollifier m(θ) := exp{−V (θ)/(DF )}, where D is the dimension, F > 0 is the influence factor, and V (θ) is a vicinity function indicating the Euclidean distance from the line segment v W ,
After adding the vector field, we modify the Hamiltonian/Lagrangian dynamics governing the evolution of θ as follows:
To address the second issue, we allow the wormholes to pass through an extra auxiliary dimension to avoid their interference with the existing dynamics in the given parameter space. In particular we introduce an auxiliary variable θ D+1 ∼ N (0, 1) corresponding to an auxiliary dimension. We usẽ θ := (θ, θ D+1 ) to denote the position parameters in the resulting D + 1 dimensional space M D × R. θ D+1 can be viewed as random noise independent of θ and contributes 1 2 θ 2 D+1 to the total potential energy. Correspondingly, we augment velocity v with one extra dimension, denoted asṽ := (v, v D+1 ). At the end of the sampling, we projectθ to the original parameter space and discard θ D+1 .
We refer to M D × {−h} as the real world, and call M D × {+h} the mirror world. Here, h is half of the distance between the two worlds, and it should be in the same scale as the average distance between the modes. For most of the examples discussed here, we set h = 1. Figure S1 illustrates how the two worlds are connected by networks of wormholes.
One can refer to [5] for full algorithmic details of Wormhole HMC/LMC, including the case where the modes are initially unknown. Figure S1: Illustrating a wormhole network connecting the real world to the mirror world (h = 1). As an example, the cylinder shows a wormhole connecting mode 5 in the real world to its mirror image. The dashed lines show two sets of wormholes. The red lines shows the wormholes when the sampler is close to mode 1 in the real world, and the magenta lines show the wormholes when the sampler is close to mode 5 in the mirror world.
We provide the following code sample provides as an example of how closed-form expressions for quantities of interest for the influenza model can be obtained using computer algebra. 