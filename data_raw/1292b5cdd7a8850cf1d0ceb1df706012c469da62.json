{
    "paper_id": "1292b5cdd7a8850cf1d0ceb1df706012c469da62",
    "metadata": {
        "title": "Bayesian uncertainty quantification for transmissibility of influenza, norovirus and Ebola using information geometry: Supplementary Material",
        "authors": [
            {
                "first": "Thomas",
                "middle": [],
                "last": "House",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Ashley",
                "middle": [],
                "last": "Ford",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Shiwei",
                "middle": [],
                "last": "Lan",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Samuel",
                "middle": [],
                "last": "Bilson",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Elizabeth",
                "middle": [],
                "last": "Buckingham-Jeffery",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Mark",
                "middle": [],
                "last": "Girolami",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Here we present technical and mathematical results supporting the main paper.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "1 Solution of the linear compartmental model 1 ",
            "cite_spans": [
                {
                    "start": 45,
                    "end": 46,
                    "text": "1",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "Consider the continuous-time Markov chain X = (X(t)|t \u2208 R + ) with state space S = {i} m i=1 , m \u2208 N, and rates \u03b3 = (\u03b3 1 , . . . , \u03b3 m\u22121 ), \u03b3 i \u2208 R + , \u2200 i \u2208 S \\ {m}. For convenience we will set \u03b3 m = 0.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ".1 Model definition"
        },
        {
            "text": "This has the following m \u00d7 m generator matrix",
            "cite_spans": [],
            "ref_spans": [],
            "section": ".1 Model definition"
        },
        {
            "text": "which in component form reads",
            "cite_spans": [],
            "ref_spans": [],
            "section": ".1 Model definition"
        },
        {
            "text": "X has an absorbing state at i = m, a unique stationary distribution \u03c0 * such that [\u03c0 * ] i = \u03b4 i,m , but it is not irreducible, ergodic or reversible (since p ij (t) = 0, \u2200 i \u2264 j \u2208 S).",
            "cite_spans": [],
            "ref_spans": [],
            "section": ".1 Model definition"
        },
        {
            "text": "We now try to solve the system d\u03c0 dt = M\u03c0, \u03c0 i (0) = \u03b4 i1 ,",
            "cite_spans": [],
            "ref_spans": [],
            "section": ".1 Model definition"
        },
        {
            "text": "for different relationships between the rates \u03b3.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ".1 Model definition"
        },
        {
            "text": "The solution to (3) is simpler if all of the rates are distinct, i.e. if \u03b3 i = \u03b3 j \u2200 i = j \u2208 S \\ {m}. We will use two different methods to solve this system.",
            "cite_spans": [
                {
                    "start": 16,
                    "end": 19,
                    "text": "(3)",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "Distinct rates"
        },
        {
            "text": "Here we start by finding the eigenvalues of M, we solve the characteristic equation",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via eigenvalue decomposition"
        },
        {
            "text": "By noting that the matrix M \u2212 \u03bb\u00bd is lower triangular, we see that its determinant is the product of its diagonal entries and so ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via eigenvalue decomposition"
        },
        {
            "text": "The eigenvectors equation can then be written in component form as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via eigenvalue decomposition"
        },
        {
            "text": "Now define a matrix A whose i-th column is the i-th right eigenvector of M so that M = A\u039bA \u22121 , where \u039b is a diagonal matrix with i-th diagonal element equal to \u03b3 i . Substituting for M ij as in (2) and rearranging, we have",
            "cite_spans": [
                {
                    "start": 195,
                    "end": 198,
                    "text": "(2)",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Solution via eigenvalue decomposition"
        },
        {
            "text": "and so since \u03b3 i\u22121 = 0, A ij = 0 for i < j. If we set A ii = 1, then by induction we have",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via eigenvalue decomposition"
        },
        {
            "text": "and so the matrix A is also lower triangular. We then write the solution to (3) as \u03c0(t) = e Mt \u03c0(0) = Ae \u039bt A \u22121 \u03c0(0) = Ae \u039bt c ,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via eigenvalue decomposition"
        },
        {
            "text": "where c is a vector obeying Ac = \u03c0(0). Clearly, c 1 = 1 and for i = 1",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via eigenvalue decomposition"
        },
        {
            "text": "Let us consider the possible solution",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via eigenvalue decomposition"
        },
        {
            "text": "Then for i = 1, (10) becomes",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via eigenvalue decomposition"
        },
        {
            "text": "and so",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via eigenvalue decomposition"
        },
        {
            "text": "Now we can show that expression (13) holds for all \u03b3 i = \u03b3 j \u2208 R, i = j.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via eigenvalue decomposition"
        },
        {
            "text": "Proof. Let there be a set {\u03b3 i } n i=1 s.t. \u03b3 i \u2208 C, n \u2208 N and \u03b3 i = \u03b3 j \u2200 i = j. Now consider the expression",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via eigenvalue decomposition"
        },
        {
            "text": "Using the formula for partial fraction decomposition",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via eigenvalue decomposition"
        },
        {
            "text": "Combining this with the eigenvectors/values of M we can substitute into (9) to give",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via eigenvalue decomposition"
        },
        {
            "text": "For the more general case, there are benefits to a Laplace transform approach, which we will introduce here. We define the Laplace transform of a function f :",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via Laplace transform"
        },
        {
            "text": "Laplace transforming (3) then gives s\u03c0 \u2212 \u03c0(0) = Q\u03c0 .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via Laplace transform"
        },
        {
            "text": "If s is not an eigenvalue of Q, then the matrix s\u00bd \u2212 Q is invertible and",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via Laplace transform"
        },
        {
            "text": "We can then calculate the inverse Laplace transform using the residue theorem. Considering the explicit form of (17) for our model, if we let B(s) = s\u00bd \u2212 Q, where s = \u2212\u03b3 i \u2200 i \u2208 S, then B is invertible and we need to find B \u22121 \u03c0(0) where [\u03c0(0)] i = \u03b4 i1 , or in component form",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via Laplace transform"
        },
        {
            "text": "Using BB \u22121 = \u00bd, and noting that B is lower triangular, we have that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via Laplace transform"
        },
        {
            "text": "For i = 1:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via Laplace transform"
        },
        {
            "text": "and so",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via Laplace transform"
        },
        {
            "text": "Then finding \u03c0 i (t) reduces to calculatingL",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via Laplace transform"
        },
        {
            "text": "all the poles s = \u2212\u03b3 i off are order 1, and so using the residue theorem we hav\u00ea",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via Laplace transform"
        },
        {
            "text": "and so finally",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via Laplace transform"
        },
        {
            "text": "which is equivalent to (14).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution via Laplace transform"
        },
        {
            "text": "Lets now take derivatives with respect to the model parameters {\u03b3 i }. This can be most easily done in the Laplace domain since we can use the fact that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Derivatives"
        },
        {
            "text": "and so",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Derivatives"
        },
        {
            "text": "Using the convolution theorem for Laplace transforms, we hav\u00ea",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Derivatives"
        },
        {
            "text": "which can be checked by computing the derivative directly from (14).",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Derivatives"
        },
        {
            "text": "Consider a general, pure birth chain with m = N + 1 states {I} N +1 I=1 , and M distinct parameters",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Arbitrary rates"
        },
        {
            "text": "Let us find solutions to (3) using the Laplace transform method. Again defining",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution"
        },
        {
            "text": ". . , M }, and following the same procedure in \u00a71.2.2, we can write down",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution"
        },
        {
            "text": "where m I \u2208 {1, 2, . . . , M } and k I \u2208 {1, 2, . . . , n m I } are counting variables defined by the relationship",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution"
        },
        {
            "text": "Then to calculate \u03c0 I (t), we notice thatf (s) = (s + \u03b3 m I ) \u2212k I m I \u22121 j=1 (s + \u03b3 j ) \u2212n j has poles at s = \u2212\u03b3 1 , . . . , \u2212\u03b3 m I \u22121 , \u2212\u03b3 m I , of order n = n 1 , . . . , n m I \u22121 , k I respectively, and s\u00f4",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution"
        },
        {
            "text": "Now consider function g(s) such that",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution"
        },
        {
            "text": "and using a simplified form of Fa\u00e1 di Bruno's formula d p ds p e g(s) = e g(s) B p g \u2032 (s), g \u2032\u2032 (s), . . . , g (p) (s) ,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution"
        },
        {
            "text": "where",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution"
        },
        {
            "text": "then we can use the identity",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution"
        },
        {
            "text": "and so finall\u0177",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution"
        },
        {
            "text": "Here",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution"
        },
        {
            "text": "This gives the overall solution",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution"
        },
        {
            "text": "where we define \u03b3 0 := 1, \u03b3 M +1 := 0, n M +1 := 1, m N +1 := M + 2 and k N +1 := 0 for simplicity of notation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Solution"
        },
        {
            "text": "An analytic expression also allows us to calculate derivatives in a similar way to \u00a71.2.3. Taking a derivative of the Laplace transform, we get",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Derivatives"
        },
        {
            "text": "otherwise.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Derivatives"
        },
        {
            "text": "So we need to calculate expressions of the formL \u22121 {(s+\u03b3 r ) \u22121\u03c0 j (s)}. Rather than use the convolution theorem as before, here we apply the residue theorem multiple times. The first application give\u015d",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Derivatives"
        },
        {
            "text": "whereK I,r (t) is a n r \u00d7 n r matrix with components ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Derivatives"
        },
        {
            "text": "The second application of the residue theorem give\u015d",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Derivatives"
        },
        {
            "text": "This gives the full final expression as",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Derivatives"
        },
        {
            "text": "2 Metric for the shedding models",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Derivatives"
        },
        {
            "text": "We first note the straightforwardly-obtained result that if \u03c6 is the pdf of a normal distribution with mean \u00b5(\u03b8) and standard deviation \u03c3(\u03b8), then the Fisher-Rao metric will contain terms like",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Underlying Fisher-Rao metric"
        },
        {
            "text": "We now consider how this metric is calculated for the four different shedding models considered in the main paper.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Underlying Fisher-Rao metric"
        },
        {
            "text": "For the simple SIR model defined in the main paper (Eq. (14)) we have",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The SIR model"
        },
        {
            "text": "The derivatives are therefore",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The SIR model"
        },
        {
            "text": "Substituting into (41) gives the Fisher-Rao metric as having the following form:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The SIR model"
        },
        {
            "text": "This has the issue that there is full unidentifiability, reflected in the fact that this metric attributes zero distance to travel along constant-\u03c4 e \u2212\u03b3 curves. Our solution to this problem is to add an amount of distance in these directions to give full metric",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The SIR model"
        },
        {
            "text": "where \u03b1 is a constant parameterising the amount of distance added.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The SIR model"
        },
        {
            "text": "While it was not necessary to do this for any of our other models, we suggest that as a general methodological point if an initial metric took a form similar to (45), but for very small \u03b1 that caused potential numerical issues with forming its inverse, then it may be advisable to increase the value of \u03b1 by hand.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "The SIR model"
        },
        {
            "text": "Here our likelihood is given by a product of normal probability density functions",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Influenza and Ebola"
        },
        {
            "text": "where",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Influenza and Ebola"
        },
        {
            "text": "\u03c0 i (t, \u03b3) =: \u03c4 \u03c0(t) , \u03c3(t) = \u03c3 t is given in data.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Influenza and Ebola"
        },
        {
            "text": "Given the results above for \u03c0 i (t), we can then write down that for influenza the metric has components",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Influenza and Ebola"
        },
        {
            "text": "For Ebola, we have to consider both high-and low-viraemic pathways of infection separately, but otherwise the metric is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Influenza and Ebola"
        },
        {
            "text": "Our norovirus model has the same form as (46) except that \u03c3(t) = \u03c3 is a model parameter.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Norovirus"
        },
        {
            "text": "Since for these data we have a large number of approximately uniformly-distributed time points, we use integrals rather than sums over time for computational efficiency leading to expressions",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Norovirus"
        },
        {
            "text": "which can be straightforwardly computed from the results above.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Norovirus"
        },
        {
            "text": "We can include the contribution of a rate-\u03c1 a exponential prior on \u03b8 a through performing calculations for uniform / improper priors and then making the transformation",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Other contributions to the metric"
        },
        {
            "text": "For SMMALA the metrics we have considered so far are all that is required, and have the primary benefit of introducing local second-order derivative information into the MCMC algorithm, but for WLMC we make additional use of the possibilities for reduction of global distances possible in a geometric approach.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Other contributions to the metric"
        },
        {
            "text": "3 The WLMC algorithm",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Other contributions to the metric"
        },
        {
            "text": "The 'HMC' dynamics introduced in the main paper can be generalised to a geometric approach in two ways. The 'RMHMC' approach of [2] involves Hamiltonian dynamics with a discretized integrator, the generalized leapfrog method [6, 2] , which requires significant numerical effort, in particular fixed-point iterations, to solve implicit equations. This step is potentially computational intensive (repeated matrix inversion of G(\u03b8) involves O(D 2.373 ) operations in dimension D), and can sometimes be numerically unstable [3] .",
            "cite_spans": [
                {
                    "start": 128,
                    "end": 131,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 225,
                    "end": 228,
                    "text": "[6,",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 229,
                    "end": 231,
                    "text": "2]",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 521,
                    "end": 524,
                    "text": "[3]",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "Lagrangian Monte Carlo (LMC)"
        },
        {
            "text": "To address this issue, Lan et al. [4] propose an explicit integrator for geometric MCMC by using the following Lagrangian dynamics:",
            "cite_spans": [
                {
                    "start": 34,
                    "end": 37,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": "Lagrangian Monte Carlo (LMC)"
        },
        {
            "text": "where v(0) := G(\u03b8(0)) \u22121 p(0) \u223c N (0, G(\u03b8(0)) \u22121 ), and \u0393(\u03b8) are Christoffel Symbol of the second kind whose (i, j, k)-th element is \u0393 k ij = 1 2 g km (\u2202 i g mj + \u2202 j g im \u2212 \u2202 m g ij ) with g km being the (k, m)-th element of G(\u03b8) \u22121 .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Lagrangian Monte Carlo (LMC)"
        },
        {
            "text": "The following explicit integrator can then be derived for these dynamics:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Lagrangian Monte Carlo (LMC)"
        },
        {
            "text": "where \u2126(\u03b8 (\u2113) , v (\u2113) )) kj := (v (\u2113) ) i \u0393(\u03b8 (\u2113) ) k ij . Such an integrator is time reversible but not volume preserving. The acceptance probability is adjusted to have the detailed balance condition hold [4] :",
            "cite_spans": [
                {
                    "start": 207,
                    "end": 210,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": "Lagrangian Monte Carlo (LMC)"
        },
        {
            "text": "where the Jacobian determinant is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Lagrangian Monte Carlo (LMC)"
        },
        {
            "text": "and E(z) is the energy for the Lagrangian dynamics defined as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Lagrangian Monte Carlo (LMC)"
        },
        {
            "text": "The resulting algorithm, Lagrangian Monte Carlo (LMC) is a valid exact sampler and has the same strength in exploring complex geometry as RHMC does. LMC is sometimes more efficient and stable than RHMC -for more details see [3, 4] .",
            "cite_spans": [
                {
                    "start": 224,
                    "end": 227,
                    "text": "[3,",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 228,
                    "end": 230,
                    "text": "4]",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": "Lagrangian Monte Carlo (LMC)"
        },
        {
            "text": "When the target distribution is multi-modal, derivative-based and geometric algorithms tend to fail as they are easily trapped in some of the modes without visiting all of them. Making proposals by numerically simulating Hamiltonian dynamics, the sampler has difficulty in passing through low probability regions [7] . Compared to HMC, the geometric RHMC and LMC methods perform even worse in relation to this issue because they are more adapted to the local geometry and more likely to be trapped in one mode.",
            "cite_spans": [
                {
                    "start": 313,
                    "end": 316,
                    "text": "[7]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "WLMC"
        },
        {
            "text": "To overcome this issue, some kind of global knowledge of the distribution needs to learned and incorporated. Lan et al. [5] proposed the idea of using wormholes for these geometric algorithms (HMC/RHMC/LMC) to work on multi-modal distributions. The proposed method comes in 2 parts: a distance-shortening metric and a mode-jumping mechanism.",
            "cite_spans": [
                {
                    "start": 120,
                    "end": 123,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "WLMC"
        },
        {
            "text": "Let\u03b8 1 and\u03b8 2 be two modes of the target distribution. We define a straight line segment, v W :=\u03b8 2 \u2212\u03b8 1 , and refer to a small neighborhood (tube) of the line segment as a wormhole. Next, we define a wormhole metric, G W (\u03b8), in the vicinity of the wormhole. For a pair of tangent vectors u, w at \u03b8, wormhole metric G W is defined as follows",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Wormhole Metric"
        },
        {
            "text": "where v * W = v W / v W , and 0 < \u03b5 \u226a 1 is a small positive number. To see that G W in fact shortens the distance between\u03b8 1 and\u03b8 2 , consider a simple case of a straight line: \u03b8(t) =\u03b8 1 + v W t, t \u2208 [0, 1]. In this case, the distance under G W is",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Wormhole Metric"
        },
        {
            "text": "which is much smaller than the Euclidean distance.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Wormhole Metric"
        },
        {
            "text": "Next, we define the overall metric, G, for the whole parameter space of \u03b8 as a weighted sum of the base metric G 0 and the wormhole metric G W ,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Wormhole Metric"
        },
        {
            "text": "where m(\u03b8) \u2208 (0, 1) is a mollifying function designed to make the wormhole metric G W influential in the vicinity of the wormhole only.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Wormhole Metric"
        },
        {
            "text": "For more than two modes, the above method alone could suffer from two potential shortcomings in higher dimensions. First, the effect of wormhole metric could diminish quickly as the sampler leaves one mode and moves towards another mode. Secondly, such a mechanism, which modifies the dynamics in the existing parameter space, could interfere with the native dynamics in the neighborhood of a wormhole, possibly preventing the sampler from properly exploring areas around the modes as well as some low probability regions.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Wormhole Network"
        },
        {
            "text": "To address the first issue, we add an external vector field to enforce the movement between modes. More specifically, we define a vector field, f (\u03b8, v), in terms of the position parameter \u03b8 and the velocity vector v = G(\u03b8) \u22121 p as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Wormhole Network"
        },
        {
            "text": "with mollifier m(\u03b8) := exp{\u2212V (\u03b8)/(DF )}, where D is the dimension, F > 0 is the influence factor, and V (\u03b8) is a vicinity function indicating the Euclidean distance from the line segment v W ,",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Wormhole Network"
        },
        {
            "text": "After adding the vector field, we modify the Hamiltonian/Lagrangian dynamics governing the evolution of \u03b8 as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Wormhole Network"
        },
        {
            "text": "To address the second issue, we allow the wormholes to pass through an extra auxiliary dimension to avoid their interference with the existing dynamics in the given parameter space. In particular we introduce an auxiliary variable \u03b8 D+1 \u223c N (0, 1) corresponding to an auxiliary dimension. We us\u1ebd \u03b8 := (\u03b8, \u03b8 D+1 ) to denote the position parameters in the resulting D + 1 dimensional space M D \u00d7 R. \u03b8 D+1 can be viewed as random noise independent of \u03b8 and contributes 1 2 \u03b8 2 D+1 to the total potential energy. Correspondingly, we augment velocity v with one extra dimension, denoted as\u1e7d := (v, v D+1 ). At the end of the sampling, we project\u03b8 to the original parameter space and discard \u03b8 D+1 .",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Wormhole Network"
        },
        {
            "text": "We refer to M D \u00d7 {\u2212h} as the real world, and call M D \u00d7 {+h} the mirror world. Here, h is half of the distance between the two worlds, and it should be in the same scale as the average distance between the modes. For most of the examples discussed here, we set h = 1. Figure S1 illustrates how the two worlds are connected by networks of wormholes.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 269,
                    "end": 278,
                    "text": "Figure S1",
                    "ref_id": null
                }
            ],
            "section": "Wormhole Network"
        },
        {
            "text": "One can refer to [5] for full algorithmic details of Wormhole HMC/LMC, including the case where the modes are initially unknown. Figure S1: Illustrating a wormhole network connecting the real world to the mirror world (h = 1). As an example, the cylinder shows a wormhole connecting mode 5 in the real world to its mirror image. The dashed lines show two sets of wormholes. The red lines shows the wormholes when the sampler is close to mode 1 in the real world, and the magenta lines show the wormholes when the sampler is close to mode 5 in the mirror world.",
            "cite_spans": [
                {
                    "start": 17,
                    "end": 20,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "Wormhole Network"
        },
        {
            "text": "We provide the following code sample provides as an example of how closed-form expressions for quantities of interest for the influenza model can be obtained using computer algebra. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Mathematica code"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Hybrid Monte Carlo on Hilbert spaces",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Beskos",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [
                        "J"
                    ],
                    "last": "Pinski",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "M"
                    ],
                    "last": "Sanz-Serna",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "M"
                    ],
                    "last": "Stuart",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Stochastic Processes and their Applications",
            "volume": "121",
            "issn": "",
            "pages": "2201--2230",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Riemann manifold Langevin and Hamiltonian Monte Carlo methods",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Girolami",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Calderhead",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Journal of the Royal Statistical Society, Series B",
            "volume": "73",
            "issn": "2",
            "pages": "123--214",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Advanced Bayesian computational methods through geometric techniques",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lan",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Markov chain Monte Carlo from Lagrangian dynamics",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lan",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Stathopoulos",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Shahbaba",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Girolami",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Journal of Computational and Graphical Statistics",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1080/10618600.2014.902764"
                ]
            }
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Wormhole Hamiltonian Monte Carlo. AAAI Conference on Artificial Intelligence",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lan",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Streets",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Shahbaba",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Simulating Hamiltonian Dynamics",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Leimkuhler",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Reich",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Semi-Supervised Learning for Visual Content Analysis and Understanding",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Sminchisescu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Welling",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Pattern Recognition",
            "volume": "44",
            "issn": "",
            "pages": "2738--2748",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "\u2212\u03b3 i \u2212 \u03bb) = 0, =\u21d2 \u03bb = 0, \u2212\u03b3 1 , \u2212\u03b3 2 , . . . , \u2212\u03b3 m\u22121 .",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "(* Set up the SEEIIR equations *)seeiirEqs = { e1'[t] ==-2p[3] e1[t], e2'[t] ==2p[3](e1[t]-e2[t]), i1'[t] ==2p[3] e2[t]-2p[2] i1[t], i2'[t] ==2p[2](i1[t]-i2[t]), Rt'[t]==i1[t]+i2[t], (* Find a solution, the force of infection and its derivatives *) sol = DSolve[seeiirEqs,{e1[t],e2[t],i1[t],i2[t],Rt[t]},t]; la = FullSimplify[p[1] (i1[t]+i2[t])/.sol[[1]]] dla = Table[FullSimplify[D[la,p[k]]],{k,1,3}] ddla = Table[FullSimplify[D[dla[[l]],p[k]]],{k,1,3},{l,1,3}]",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}