{
    "paper_id": "441421494c2a4ed45a8d6b711842ed8ee43ec038",
    "metadata": {
        "title": "Free-Form Deformation Approach for Registration of Visible and Infrared Facial Images in Fever Screening \u2020",
        "authors": [
            {
                "first": "Yedukondala",
                "middle": [],
                "last": "Narendra",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Dwith",
                "middle": [],
                "last": "Chenna",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "U.S. Food and Drug Administration",
                    "location": {
                        "postCode": "20993",
                        "settlement": "Silver Spring",
                        "region": "MD",
                        "country": "USA"
                    }
                },
                "email": ""
            },
            {
                "first": "Pejhman",
                "middle": [],
                "last": "Ghassemi",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "U.S. Food and Drug Administration",
                    "location": {
                        "postCode": "20993",
                        "settlement": "Silver Spring",
                        "region": "MD",
                        "country": "USA"
                    }
                },
                "email": "pejhman.ghassemi@fda.hhs.govp.g."
            },
            {
                "first": "T",
                "middle": [
                    "Joshua"
                ],
                "last": "Pfefer",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "U.S. Food and Drug Administration",
                    "location": {
                        "postCode": "20993",
                        "settlement": "Silver Spring",
                        "region": "MD",
                        "country": "USA"
                    }
                },
                "email": ""
            },
            {
                "first": "Jon",
                "middle": [],
                "last": "Casamento",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "U.S. Food and Drug Administration",
                    "location": {
                        "postCode": "20993",
                        "settlement": "Silver Spring",
                        "region": "MD",
                        "country": "USA"
                    }
                },
                "email": "jon.casamento@fda.hhs.govj.c."
            },
            {
                "first": "Quanzeng",
                "middle": [],
                "last": "Wang",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "U.S. Food and Drug Administration",
                    "location": {
                        "postCode": "20993",
                        "settlement": "Silver Spring",
                        "region": "MD",
                        "country": "USA"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Fever screening based on infrared (IR) thermographs (IRTs) is an approach that has been implemented during infectious disease pandemics, such as Ebola and Severe Acute Respiratory Syndrome. A recently published international standard indicates that regions medially adjacent to the inner canthi provide accurate estimates of core body temperature and are preferred sites for fever screening. Therefore, rapid, automated identification of the canthi regions within facial IR images may greatly facilitate rapid fever screening of asymptomatic travelers. However, it is more difficult to accurately identify the canthi regions from IR images than from visible images that are rich with exploitable features. In this study, we developed and evaluated techniques for multi-modality image registration (MMIR) of simultaneously captured visible and IR facial images for fever screening. We used free form deformation (FFD) models based on edge maps to improve registration accuracy after an affine transformation. Two widely used FFD models in medical image registration based on the Demons and cubic B-spline algorithms were qualitatively compared. The results showed that the Demons algorithm outperformed the cubic B-spline algorithm, likely due to overfitting of outliers by the latter method. The quantitative measure of registration accuracy, obtained through selected control point correspondence, was within 2.8 \u00b1 1.2 mm, which enables accurate and automatic localization of canthi regions in the IR images for temperature measurement.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Mitigation of the threat of infectious pandemics such as the Ebola virus disease may be possible through mass screening in the field or at public transportation centers such as airports. Fever screening based on non-contact infrared (IR) thermometers (NCITs) and IR thermographs (IRTs) represents the only currently viable approaches. While NCITs are more commonly used for fever screening, IRTs may be more effective if implemented according to the recommendations of a recently published standard [1] . For example, this standard indicates that IRT measurements should be performed with an accurate blackbody in the image as a reference and that the preferred tissue sites for imaging-regions medially adjacent to the inner canthi (termed as canthi regions)-provide the most accurate estimates of core body temperature. However, it is more difficult to accurately identify canthi regions from IR images than from visible images, as the latter provides a greater number of exploitable features. Therefore, in development of rapid, automated devices for identification of the canthi regions within facial IR images, the use of multi-modality image registration (MMIR) of simultaneously captured visible and IR images will likely produce optimal results. MMIR of visible and IR images is well studied in the literature for facial recognition, image fusion and other applications [2] [3] [4] [5] [6] [7] [8] [9] . However, fever screening requires high registration accuracy at the canthi regions, instead of the whole face. To the best of our knowledge, no MMIR study focused on the canthi regions has been performed. In the case of visible and IR facial images, intensity-based similarity metrics-which are widely used in medical imaging-cannot be directly applied because these two image types do not exhibit correlation in pixel intensities. However, certain common features like high curvature, line intersections, strong edges, and structure contours within the images are consistent in both visible and IR images and therefore can be used to obtain edge maps for improving the registration. The relationship between these images can be modeled using an affine transformation. Constrained by bones and muscles, human faces are non-planar and non-rigid, which limits the accuracy of affine transformations. Accuracy of affine transformation can be improved through free form deformation (FFD) transformation since FFD can generate smooth transform and avoid unnatural deformation.",
            "cite_spans": [
                {
                    "start": 499,
                    "end": 502,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 1378,
                    "end": 1381,
                    "text": "[2]",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1382,
                    "end": 1385,
                    "text": "[3]",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1386,
                    "end": 1389,
                    "text": "[4]",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1390,
                    "end": 1393,
                    "text": "[5]",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1394,
                    "end": 1397,
                    "text": "[6]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1398,
                    "end": 1401,
                    "text": "[7]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 1402,
                    "end": 1405,
                    "text": "[8]",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1406,
                    "end": 1409,
                    "text": "[9]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "In this paper, we studied the methods for MMIR of visible and IR facial images to enable the accurate detection of the canthi regions. We used a two-step coarse-fine registration method for visible and IR images. The coarse registration step used the affine transformation, and the fine registration step was based on an FFD model using the edge maps. The edge maps near the eyes are significant common features preserved in both the visible and the IR facial images [5, 6, 10] . These features served as the reference for estimating the FFD transformation. Two FFD models widely used in medical image registration based on the Demons and cubic B-spline algorithms were qualitatively compared.",
            "cite_spans": [
                {
                    "start": 467,
                    "end": 470,
                    "text": "[5,",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 471,
                    "end": 473,
                    "text": "6,",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 474,
                    "end": 477,
                    "text": "10]",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Image registration involves spatial alignment of images through transformations and can be formulated as a spatial transformation that defines correspondence between two images. Depending on the application, a registration algorithm can be decomposed into three components: a similarity metric [11] , a transformation model [12] [13] [14] , and an optimization method [14] [15] [16] .",
            "cite_spans": [
                {
                    "start": 294,
                    "end": 298,
                    "text": "[11]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 324,
                    "end": 328,
                    "text": "[12]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 329,
                    "end": 333,
                    "text": "[13]",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 334,
                    "end": 338,
                    "text": "[14]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 368,
                    "end": 372,
                    "text": "[14]",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 373,
                    "end": 377,
                    "text": "[15]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 378,
                    "end": 382,
                    "text": "[16]",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "Image Registration"
        },
        {
            "text": "Similarity Metrics determine the accuracy, robustness, and flexibility of a registration algorithm. They can be broadly classified into landmark-based and intensity-based metrics [11] . A landmark-based metric can be used to find transformation using unique landmarks in the reference and moving images. An intensity-based metric works directly with pixel intensity levels and offers flexibility and robustness [15] , which makes it suitable for most image registration applications. In the case of different modalities, the intensity-based similarity metric based on correlation (e.g., normalize cross correlation (NCC)) or statistic measures (e.g., entropy-based mutual information (MI)) of pixel values are well suited for MMIR. Intensity-based metrics widely used for medical image registration, include sum of squared difference (SSD), NCC, and MI [11] . The SSD similarity metric is the simplest similarity metric for image registration. It can be calculated as: (1) where I SSD is a measure of the SSD metric, I re f , and I reg are the intensity matrices of the reference image and the transformed moving image (i.e., the registered image), respectively. I SSD is often used for images with similar modality, which gives an optimal solution if the images are aligned with white Gaussian noise. The NCC similarity metric is a more general similarity metric. It assumes a linear intensity relationship between images I re f and I reg and can be expressed as:",
            "cite_spans": [
                {
                    "start": 179,
                    "end": 183,
                    "text": "[11]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 411,
                    "end": 415,
                    "text": "[15]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 853,
                    "end": 857,
                    "text": "[11]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 969,
                    "end": 972,
                    "text": "(1)",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [],
            "section": "Image Registration"
        },
        {
            "text": "\u2211 I re f (x, y) \u2212 \u00b5 re f I reg (x, y) \u2212 \u00b5 reg \u2211 (I re f (x, y) \u2212 \u00b5 re f ) 2 \u2211 (I reg (x, y) \u2212 \u00b5 reg ) 2 (2) where \u00b5 re f and \u00b5 reg . are the mean image intensities of the reference and registered images, respectively. The MI similarity metric for image registration was first proposed by Woods et al. [17] . In the case of MMIR, regions with different intensity levels in an image would correspond to similar regions in another image that also contain similar number of intensity levels (maybe of different values). Ideally, the correspondence between these intensity levels might not change significantly across either of these images. Hill et al. [18] proposed a registration method by constructing a joint histogram, which is defined as a two-dimensional plot showing combinations of intensity levels ( Figure 1 ). The value at location (i, j) in a joint histogram represents the number of pixels whose intensity level is i in one image and j in the other. A joint histogram shows decreased dispersion as registration accuracy increases. Shannon entropy (referred as entropy) is used as a metric to measure the dispersion in a joint histogram. If X = {x 1 , x 2 , . . . , x n } is a finite discrete set and each element has probability p i , the entropy of X is given by:",
            "cite_spans": [
                {
                    "start": 104,
                    "end": 107,
                    "text": "(2)",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 301,
                    "end": 305,
                    "text": "[17]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 649,
                    "end": 653,
                    "text": "[18]",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [
                {
                    "start": 806,
                    "end": 814,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Image Registration"
        },
        {
            "text": "Entropy only depends on the distribution of the random variables. This definition of entropy can be extended to images, where the probability distribution function is constructed using the histogram distribution of the pixel values in the image. Entropy of a joint histogram decreases as the alignment of images increases as shown in Figure 1 . The MI metric I MI (A; B) can be defined as [11] :",
            "cite_spans": [
                {
                    "start": 389,
                    "end": 393,
                    "text": "[11]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [
                {
                    "start": 334,
                    "end": 342,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Image Registration"
        },
        {
            "text": "where H(A), H(B), and H(A, B) are entropies of image A, image B, and joint histogram, respectively. The maximization of I MI can be achieved by minimizing the entropy of the joint histogram. Hence, the problem of registration is converted into an optimization problem involving maximization of the MI metric using different transformations. The MI metric is widely used for MMIR. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Image Registration"
        },
        {
            "text": "where \u03bc and \u03bc are the mean image intensities of the reference and registered images, respectively. The MI similarity metric for image registration was first proposed by Woods et al. [17] . In the case of MMIR, regions with different intensity levels in an image would correspond to similar regions in another image that also contain similar number of intensity levels (maybe of different values). Ideally, the correspondence between these intensity levels might not change significantly across either of these images. Hill et al. [18] proposed a registration method by constructing a joint histogram, which is defined as a two-dimensional plot showing combinations of intensity levels ( Figure 1 ). The value at location (i, j) in a joint histogram represents the number of pixels whose intensity level is i in one image and j in the other. A joint histogram shows decreased dispersion as registration accuracy increases. Shannon entropy (referred as entropy) is used as a metric to measure the dispersion in a joint histogram. If X = {x1, x2, \u2026, xn} is a finite discrete set and each element has probability pi, the entropy of X is given by:",
            "cite_spans": [
                {
                    "start": 182,
                    "end": 186,
                    "text": "[17]",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 530,
                    "end": 534,
                    "text": "[18]",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [
                {
                    "start": 687,
                    "end": 695,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Image Registration"
        },
        {
            "text": "Entropy only depends on the distribution of the random variables. This definition of entropy can be extended to images, where the probability distribution function is constructed using the histogram distribution of the pixel values in the image. Entropy of a joint histogram decreases as the alignment of images increases as shown in Figure 1 . The MI metric IMI (A; B) can be defined as [11] :",
            "cite_spans": [
                {
                    "start": 388,
                    "end": 392,
                    "text": "[11]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [
                {
                    "start": 334,
                    "end": 342,
                    "text": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Image Registration"
        },
        {
            "text": "where",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Image Registration"
        },
        {
            "text": ", and ( , ) are entropies of image A, image B, and joint histogram, respectively. The maximization of IMI can be achieved by minimizing the entropy of the joint histogram. Hence, the problem of registration is converted into an optimization problem involving maximization of the MI metric using different transformations. The MI metric is widely used for MMIR. A Transformation Model defines the relationship between the coordinates of two images. Let Iref, Imov, and Ireg denote the reference, moving, and registered images, respectively, the goal is to find a transformation matrix T(x, y) (or equivalently its inverse) which provides a mapping from Imov(x, y) to Ireg(x, y) so that Iref and Ireg have sufficient similarity. Transformation models can be classified as linear transformations (e.g., rigid, affine, projective) and non-linear transformations (e.g., curved (or elastic), FFD) [20, 21] . Linear transformations are global (i.e., warping the whole image) [20] and may include translation, rotation, scaling, reflection, shear, and projection. Simple planar surfaces can be modeled through translation, rotation, scaling, and shear, which together define an affine transformation. Affine transformation preserves the parallelism of lines, but not their lengths or angles. It extends the degrees of freedom for the rigid transformation with scaling factor and shear.",
            "cite_spans": [
                {
                    "start": 891,
                    "end": 895,
                    "text": "[20,",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 896,
                    "end": 899,
                    "text": "21]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 968,
                    "end": 972,
                    "text": "[20]",
                    "ref_id": "BIBREF21"
                }
            ],
            "ref_spans": [],
            "section": "Image Registration"
        },
        {
            "text": "In many cases, MMIR uses a non-linear transformation by locally displacing a moving image. FFD transformation algorithms are widely used for MMIR. They can be broadly classified into A Transformation Model defines the relationship between the coordinates of two images. Let I ref , I mov , and I reg denote the reference, moving, and registered images, respectively, the goal is to find a transformation matrix T(x, y) (or equivalently its inverse) which provides a mapping from I mov (x, y) to I reg (x, y) so that I ref and I reg have sufficient similarity. Transformation models can be classified as linear transformations (e.g., rigid, affine, projective) and non-linear transformations (e.g., curved (or elastic), FFD) [20, 21] . Linear transformations are global (i.e., warping the whole image) [20] and may include translation, rotation, scaling, reflection, shear, and projection. Simple planar surfaces can be modeled through translation, rotation, scaling, and shear, which together define an affine transformation. Affine transformation preserves the parallelism of lines, but not their lengths or angles. It extends the degrees of freedom for the rigid transformation with scaling factor and shear.",
            "cite_spans": [
                {
                    "start": 724,
                    "end": 728,
                    "text": "[20,",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 729,
                    "end": 732,
                    "text": "21]",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 801,
                    "end": 805,
                    "text": "[20]",
                    "ref_id": "BIBREF21"
                }
            ],
            "ref_spans": [],
            "section": "Image Registration"
        },
        {
            "text": "In many cases, MMIR uses a non-linear transformation by locally displacing a moving image. FFD transformation algorithms are widely used for MMIR. They can be broadly classified into parametric and non-parametric algorithms. The parametric algorithms (e.g., B-spline algorithms [15] ) are defined on a coarse grid of control points and contrast with non-parametric algorithms (e.g., Demons algorithm [12] ) where a displacement vector is associated with every pixel in the moving image. Both the parametric and non-parametric transformations have many parameters and are computationally intense, which can be handled through a registration strategy based on a hierarchical Gaussian pyramid. In the case of parametric transforms, the displacement field at every pixel (x, y), T(x, y), is defined as a function of displacement vectors (u, v) in the neighborhood of coarse grid control points.",
            "cite_spans": [
                {
                    "start": 278,
                    "end": 282,
                    "text": "[15]",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 400,
                    "end": 404,
                    "text": "[12]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "Image Registration"
        },
        {
            "text": "where u and v are vertical and horizontal displacement fields, and f is the weight of basis function used to define the transformation. Given a pair of images I ref and I mov , we wish to simultaneously recover u and v. The parametric algorithms use a combination of vectors to define the displacement at a general location in the image with nearer vectors having a greater influence. The inherent smoothness of cubic B-spline functions also defines smooth displacement vectors without the need for external smoothness constraints. In the case of non-parametric algorithms, an additional smoothness constraint on the transformation based on a weighted Gaussian function can be included. This smoothness constraint eliminates un-natural deformations in the transformation. An Optimization method tries to minimize (or maximize) the specified similarity metric over the search space of possible parameters for the transformation model. An effective optimization method must be reliable and quick to find the best possible parameters of the transformation model. Selection of an optimization method depends on the application, transformation model, time constraints, and required accuracy of the registration. In non-linear registration applications, the optimizer is more complicated as a non-linear transformation model has more parameters than a linear one. Many registration problems can be solved using a gradient-descent-based optimization method, with existing numerical solvers [15, 16] .",
            "cite_spans": [
                {
                    "start": 1483,
                    "end": 1487,
                    "text": "[15,",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 1488,
                    "end": 1491,
                    "text": "16]",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "Image Registration"
        },
        {
            "text": "To implement an automated temperature measurement, accurate IR-visible face registration for localization of the canthi regions is essential. We used a two-step registration strategy with coarse and fine registrations ( Figure 2 ). The visible images were used as the reference images and the IR images were used as the moving images. The coarse registration was used for alignment and detection of facial images. The fine registration was used to improve the registration accuracy for accurate detection of the canthi regions. The coarse and fine registrations shared the same principle as shown in Figure 3 . The registration algorithm was an iterative process, where we selected the transformation type and started with some initial estimate to transform the moving image. Interpolation was used during the transformation to estimate the pixel values at non-integer grid locations. The transformed image was compared with the reference image to generate the similarity metric. The regular step gradient descent optimizer in MATLAB (MathWorks, Natick, MA, USA) was used to adjust the variables for the transformation to minimize (or maximize) the similarity metric.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 220,
                    "end": 228,
                    "text": "Figure 2",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 600,
                    "end": 608,
                    "text": "Figure 3",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "Implementation"
        },
        {
            "text": "The images of volunteers were captured using a visible camera (HD Pro Webcam C920, Logitech International S.A., Lausanne, Switzerland) and an IRT (8640 P-series, Infrared Cameras Inc., Beaumont, TX, USA). The IRT has 512 \u00d7 640 pixels. While the visible camera has 1920 \u00d7 1080 pixels, the compressed images only have 640 \u00d7 480 pixels. The field of view values were measured [22] to be 62 \u2022 and 48 \u2022 for the visible camera and 50 \u2022 and 60 \u2022 for the IRT, in vertical and horizontal directions respectively. The visible camera and IRT were placed at closest possible locations with the center-to-center distance of their optical lenses being 3 cm. An IR image was always taken simultaneously with a visible image to form an image pair. The image pairs from the visible camera and IRT were used to develop the registration method and quantitatively measure the registration accuracy. The accuracy of automatic temperature reading from the canthi regions with the two-step registration method described above was compared with the accuracy of temperature reading from the manually selected canthi regions. ",
            "cite_spans": [
                {
                    "start": 373,
                    "end": 377,
                    "text": "[22]",
                    "ref_id": "BIBREF24"
                }
            ],
            "ref_spans": [],
            "section": "Implementation"
        },
        {
            "text": "The coarse registration was based on an affine transformation with a MI similarity matric, followed by face detection. The face detection algorithm was based on work by Viola and Jones [23] , a cascade boosted classifier using Haar-like digital image features trained with positive and negative examples. The pre-trained frontal face classifier available with the MATLAB computer vision library was used to obtain the location and size of the face region [24] . The coarse registration algorithm was implemented in MATLAB using the Mattes MI algorithm [11] . In this algorithm, single intensity pixel/sample was drawn from images. The marginal and joint probability density function (PDF) was evaluated at discrete positions using samples of pixel intensities. The regular step gradient descent optimizer [25] was used for implementation of this algorithm.",
            "cite_spans": [
                {
                    "start": 185,
                    "end": 189,
                    "text": "[23]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 455,
                    "end": 459,
                    "text": "[24]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 552,
                    "end": 556,
                    "text": "[11]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 805,
                    "end": 809,
                    "text": "[25]",
                    "ref_id": "BIBREF27"
                }
            ],
            "ref_spans": [],
            "section": "Coarse Registration"
        },
        {
            "text": "We used fine registration to improve registration accuracy of IR-visible image pairs and to enable accurate localization of the canthi regions. Unlike the affine transformation [24, 26] used for coarse registration, the fine registration uses FFD and needs to define a vector field for each pixel in the image. To model the local deformations of a face that are difficult to describe via affine transformations, we evaluated both the Demons and the cubic B-spline algorithms, which are widely used in medical imaging as an FFD model.",
            "cite_spans": [
                {
                    "start": 177,
                    "end": 181,
                    "text": "[24,",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 182,
                    "end": 185,
                    "text": "26]",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "Fine Registration"
        },
        {
            "text": "The Demons Algorithm [12] proposes non-linear registration as a diffusion process, which introduces entities called Demons that exert forces according to local image characteristics. These forces are inspired from optical flow equations [13] . The basic idea of Demons algorithm for non-linear registration is that the reference image acts as a local force which moves pixels in the moving image to match the reference image. During each iteration, the moving image is transformed using the moving vector dV = (dx, dy) for each pixel as follows:",
            "cite_spans": [
                {
                    "start": 21,
                    "end": 25,
                    "text": "[12]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 237,
                    "end": 241,
                    "text": "[13]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": "Fine Registration"
        },
        {
            "text": "where is computed only once during the iterations. Moreover, Demons algorithm assumes that the displacement vector is reasonably small or local. In some cases, such an assumption might be violated, which can be mitigated through a multi-scale approach that reduces the magnitude of these displacement vectors. For instance, the reference and moving images can be down-sampled to ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Fine Registration"
        },
        {
            "text": "The coarse registration was based on an affine transformation with a MI similarity matric, followed by face detection. The face detection algorithm was based on work by Viola and Jones [23] , a cascade boosted classifier using Haar-like digital image features trained with positive and negative examples. The pre-trained frontal face classifier available with the MATLAB computer vision library was used to obtain the location and size of the face region [24] . The coarse registration algorithm was implemented in MATLAB using the Mattes MI algorithm [11] . In this algorithm, single intensity pixel/sample was drawn from images. The marginal and joint probability density function (PDF) was evaluated at discrete positions using samples of pixel intensities. The regular step gradient descent optimizer [25] was used for implementation of this algorithm.",
            "cite_spans": [
                {
                    "start": 185,
                    "end": 189,
                    "text": "[23]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 455,
                    "end": 459,
                    "text": "[24]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 552,
                    "end": 556,
                    "text": "[11]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 805,
                    "end": 809,
                    "text": "[25]",
                    "ref_id": "BIBREF27"
                }
            ],
            "ref_spans": [],
            "section": "Coarse Registration"
        },
        {
            "text": "We used fine registration to improve registration accuracy of IR-visible image pairs and to enable accurate localization of the canthi regions. Unlike the affine transformation [24, 26] used for coarse registration, the fine registration uses FFD and needs to define a vector field for each pixel in the image. To model the local deformations of a face that are difficult to describe via affine transformations, we evaluated both the Demons and the cubic B-spline algorithms, which are widely used in medical imaging as an FFD model.",
            "cite_spans": [
                {
                    "start": 177,
                    "end": 181,
                    "text": "[24,",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 182,
                    "end": 185,
                    "text": "26]",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "Fine Registration"
        },
        {
            "text": "The Demons Algorithm [12] proposes non-linear registration as a diffusion process, which introduces entities called Demons that exert forces according to local image characteristics. These forces are inspired from optical flow equations [13] . The basic idea of Demons algorithm for non-linear registration is that the reference image acts as a local force which moves pixels in the moving image to match the reference image. During each iteration, the moving image is transformed using the moving vector dV = (dx, dy) for each pixel as follows:",
            "cite_spans": [
                {
                    "start": 21,
                    "end": 25,
                    "text": "[12]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 237,
                    "end": 241,
                    "text": "[13]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": "Fine Registration"
        },
        {
            "text": "where is computed only once during the iterations. Moreover, Demons algorithm assumes that the displacement vector is reasonably small or local. In some cases, such an assumption might be violated, which can be mitigated through a multi-scale approach that reduces the magnitude of these ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Fine Registration"
        },
        {
            "text": "The coarse registration was based on an affine transformation with a MI similarity matric, followed by face detection. The face detection algorithm was based on work by Viola and Jones [23] , a cascade boosted classifier using Haar-like digital image features trained with positive and negative examples. The pre-trained frontal face classifier available with the MATLAB computer vision library was used to obtain the location and size of the face region [24] . The coarse registration algorithm was implemented in MATLAB using the Mattes MI algorithm [11] . In this algorithm, single intensity pixel/sample was drawn from images. The marginal and joint probability density function (PDF) was evaluated at discrete positions using samples of pixel intensities. The regular step gradient descent optimizer [25] was used for implementation of this algorithm.",
            "cite_spans": [
                {
                    "start": 185,
                    "end": 189,
                    "text": "[23]",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 455,
                    "end": 459,
                    "text": "[24]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 552,
                    "end": 556,
                    "text": "[11]",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 805,
                    "end": 809,
                    "text": "[25]",
                    "ref_id": "BIBREF27"
                }
            ],
            "ref_spans": [],
            "section": "Coarse Registration"
        },
        {
            "text": "We used fine registration to improve registration accuracy of IR-visible image pairs and to enable accurate localization of the canthi regions. Unlike the affine transformation [24, 26] used for coarse registration, the fine registration uses FFD and needs to define a vector field for each pixel in the image. To model the local deformations of a face that are difficult to describe via affine transformations, we evaluated both the Demons and the cubic B-spline algorithms, which are widely used in medical imaging as an FFD model.",
            "cite_spans": [
                {
                    "start": 177,
                    "end": 181,
                    "text": "[24,",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 182,
                    "end": 185,
                    "text": "26]",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "Fine Registration"
        },
        {
            "text": "The Demons Algorithm [12] proposes non-linear registration as a diffusion process, which introduces entities called Demons that exert forces according to local image characteristics. These forces are inspired from optical flow equations [13] . The basic idea of Demons algorithm for non-linear registration is that the reference image acts as a local force which moves pixels in the moving image to match the reference image. During each iteration, the moving image is transformed using the moving vector dV = (dx, dy) for each pixel as follows:",
            "cite_spans": [
                {
                    "start": 21,
                    "end": 25,
                    "text": "[12]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 237,
                    "end": 241,
                    "text": "[13]",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": "Fine Registration"
        },
        {
            "text": "where I re f represents the intensity of reference image, and I Gaussian filter is used to smooth the displacement fields, which enables noise suppression and preserves geometric continuity of the deformed image. The gradient of the reference image \u2207I re f is computed only once during the iterations. Moreover, Demons algorithm assumes that the displacement vector is reasonably small or local. In some cases, such an assumption might be violated, which can be mitigated through a multi-scale approach that reduces the magnitude of these displacement vectors. For instance, the reference and moving images can be down-sampled to low-resolution images and the displacement fields at each stage can be up-sampled to a finer scale. Such a multi-scale approach also enables a large computational advantage for large image sizes. The Demons algorithm is widely used for similar modality images using the SSD error as the similarity metric [15, 16] . We tried to reduce the differences between modalities by using common features in visible and IR images. We generated edge maps for visible and IR images using the canny edge detector for non-linear transformation. These edge maps emphasize the contour edges of face and show good similarity between visible and IR images [5, 7] . The eye regions were used to predict the FFD for fine registration. As an iterative optimization method, effective stopping criteria needed to be defined. We used a tolerance criterion that stops the iterations if the mean square error (MSE) increases with the iterations or the threshold decreases for each iteration within a convergence tolerance.",
            "cite_spans": [
                {
                    "start": 935,
                    "end": 939,
                    "text": "[15,",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 940,
                    "end": 943,
                    "text": "16]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 1268,
                    "end": 1271,
                    "text": "[5,",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1272,
                    "end": 1274,
                    "text": "7]",
                    "ref_id": "BIBREF7"
                }
            ],
            "ref_spans": [],
            "section": "Fine Registration"
        },
        {
            "text": "Spline-based algorithms are among the most common and important transformation models used for non-linear registration in medical imaging. Spline-based registration algorithms use control points in the moving image and a spline function that defines the transformation away from these points. They can be broadly divided into two types based on thin-plate splines and B-splines. Thin-plate splines have global influence on the transformation. In contrast, B-splines are only defined near the control points. Any perturbation in the control points influences only the neighborhood of that point and the deformation is defined by manipulating the underlying mesh of the control points. This makes B-spline-based registration a computationally efficient alternative to other non-linear registrations. Implementation of B-spline uses a uniform mesh of the control points such that each set of m \u00d7 m pixels correspond to a single spline patch defined by four control points. The resolution of the control points defines the degrees of freedom and consequently the computational complexity. A large spacing of the control points allows modeling of global non-linear deformations, while a small spacing of control points allows modeling of highly local deformations. The displacement fields are estimated using two dimensional splines controlled by a small number of control points in the moving image. The B-spline basis function imposes an implicit smoothness on the motion field, without the need for additional smoothness constraints. The u i and v i defines the displacement vectors at each pixel in the x and y directions, respectively.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Fine Registration"
        },
        {
            "text": "where w ij are called basis functions and are non-zero over a small interval. It emphasizes that the (u, v) are a known linear combination of (U j , V j ) control points. We used this hierarchical registration with different control point mesh resolutions. The spacing between control points decreased at each level, which increases the resolution of the control point mesh. The horizontal and vertical control points halved in every step. The control point mesh at one level was refined by inserting new control points to create the control point mesh at the next level. Each control point mesh and associated spline-based FFD defined the transformation at each level of resolution. To avoid the overhead of calculating several B-spline FFDs separately, we represented the transformation by a single B-spline FFD whose control point mesh was progressively refined. Based on the order of basis function, the B-spline can be further classified into linear, quadratic, cubic, or higher-order B-spline registrations. The higher-order basis functions improve the registration accuracy at the cost of longer computation time. Cubic B-spline is quite widely used in medical image registration as it offers balanced tradeoff between registration accuracy and computation time [15, 24] . Therefore, cubic B-Spline was used in this paper. Similarity metrics of SSD and NCC were evaluated for the Demons and cubic B-spline algorithms, and the preliminary data (not listed in the paper to limit the paper length) showed that the SSD metrics was better than the NCC metrics. Therefore, all the fine registration data shown in this paper were based on the SSD metrics.",
            "cite_spans": [
                {
                    "start": 1269,
                    "end": 1273,
                    "text": "[15,",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 1274,
                    "end": 1277,
                    "text": "24]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "Fine Registration"
        },
        {
            "text": "We recruited 52 subjects for the study. We evaluated the registration accuracy in two approaches based on circular aluminum foil markers on 6 subjects and manually selected landmarks on 10 subjects. We also compared the temperature reading results on 36 subjects based on manual canthi selection and automatic canthi detection, respectively. Different subjects were used for different evaluation approaches and temperature reading study to avoid reduplicative information.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Results"
        },
        {
            "text": "The two-step coarse-fine registration strategy of visible and IR images was qualitatively evaluated. Figure 4 shows a pair of visible and IR images before and after the coarse registration. After coarse registration, the original images were cropped and only the face region in each image was used for the fine registration step. Figure 5 shows the registration results of the edge map pairs using coarse and coarse-fine registration methods. The edge maps were extracted from the Canny edge detector. The fine registration can be based on the Demons or the cubic B-spline algorithm. For simplicity, we call the two-step coarse-fine registration methods the coarse-Demons and coarse-spline methods, respectively. From Figure 5 , prominent edge features like eyes, nose, and mouth with the coarse-Demons and coarse-spline methods have been better aligned compared to the coarse registration alone. We recruited 52 subjects for the study. We evaluated the registration accuracy in two approaches based on circular aluminum foil markers on 6 subjects and manually selected landmarks on 10 subjects. We also compared the temperature reading results on 36 subjects based on manual canthi selection and automatic canthi detection, respectively. Different subjects were used for different evaluation approaches and temperature reading study to avoid reduplicative information.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 101,
                    "end": 109,
                    "text": "Figure 4",
                    "ref_id": "FIGREF16"
                },
                {
                    "start": 330,
                    "end": 338,
                    "text": "Figure 5",
                    "ref_id": "FIGREF18"
                },
                {
                    "start": 718,
                    "end": 726,
                    "text": "Figure 5",
                    "ref_id": "FIGREF18"
                }
            ],
            "section": "Registration Accuracy"
        },
        {
            "text": "The two-step coarse-fine registration strategy of visible and IR images was qualitatively evaluated. Figure 4 shows a pair of visible and IR images before and after the coarse registration. After coarse registration, the original images were cropped and only the face region in each image was used for the fine registration step. Figure 5 shows the registration results of the edge map pairs using coarse and coarse-fine registration methods. The edge maps were extracted from the Canny edge detector. The fine registration can be based on the Demons or the cubic B-spline algorithm. For simplicity, we call the two-step coarse-fine registration methods the coarse-Demons and coarse-spline methods, respectively. From Figure 5 , prominent edge features like eyes, nose, and mouth with the coarse-Demons and coarse-spline methods have been better aligned compared to the coarse registration alone. Figure 6 shows corresponding image registration results viewed through superimposed checkerboard pattern of visible and IR images in gray scale. It can be observed that the eyes and nose are not accurately aligned with the coarse registration, whereas the coarse-Demons and coarse-spline methods show better alignment. This demonstrates that applying a non-linear registration algorithm improves accurate matching of face images compared to the coarse registration alone. We recruited 52 subjects for the study. We evaluated the registration accuracy in two approaches based on circular aluminum foil markers on 6 subjects and manually selected landmarks on 10 subjects. We also compared the temperature reading results on 36 subjects based on manual canthi selection and automatic canthi detection, respectively. Different subjects were used for different evaluation approaches and temperature reading study to avoid reduplicative information.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 101,
                    "end": 109,
                    "text": "Figure 4",
                    "ref_id": "FIGREF16"
                },
                {
                    "start": 330,
                    "end": 338,
                    "text": "Figure 5",
                    "ref_id": "FIGREF18"
                },
                {
                    "start": 718,
                    "end": 726,
                    "text": "Figure 5",
                    "ref_id": "FIGREF18"
                },
                {
                    "start": 897,
                    "end": 905,
                    "text": "Figure 6",
                    "ref_id": "FIGREF19"
                }
            ],
            "section": "Registration Accuracy"
        },
        {
            "text": "The two-step coarse-fine registration strategy of visible and IR images was qualitatively evaluated. Figure 4 shows a pair of visible and IR images before and after the coarse registration. After coarse registration, the original images were cropped and only the face region in each image was used for the fine registration step. Figure 5 shows the registration results of the edge map pairs using coarse and coarse-fine registration methods. The edge maps were extracted from the Canny edge detector. The fine registration can be based on the Demons or the cubic B-spline algorithm. For simplicity, we call the two-step coarse-fine registration methods the coarse-Demons and coarse-spline methods, respectively. From Figure 5 , prominent edge features like eyes, nose, and mouth with the coarse-Demons and coarse-spline methods have been better aligned compared to the coarse registration alone. Figure 6 shows corresponding image registration results viewed through superimposed checkerboard pattern of visible and IR images in gray scale. It can be observed that the eyes and nose are not accurately aligned with the coarse registration, whereas the coarse-Demons and coarse-spline methods show better alignment. This demonstrates that applying a non-linear registration algorithm improves accurate matching of face images compared to the coarse registration alone. We quantitatively evaluated the two-step coarse-fine registration strategy of visible and IR images with markers attached to the subjects. Circular aluminum foil markers with a diameter of 7 mm were attached to different locations around the canthi regions of 6 volunteers to evaluate the registration accuracy. The markers and their correspondence in each set of visible and IR images (Figure 7) were manually selected to define control points. They were removed using the Spot Healing Brush Tool in Adobe Photoshop \u00ae before the image registration process to avoid any registration bias caused by them. After the image registration, the spatial transformation obtained was applied to the control points for a direct registration without further optimization. The distances between the transformed marker locations on the moving image and their corresponding locations on the reference image were used for registration accuracy analysis. The registration accuracy was analyzed with both MSE and recall [7, 26] values. After image registration, the MSE of distances between each pair of transformed markers in the visible and IR images was calculated as a qualitative performance metric. We used Medical Image Registration Toolbox (MIRT) [24] for the cubic B-spline registration, to compare the coarse-spline method with the coarse and coarse-Demons methods. The registration MSE based on markers (Table 1) for the coarse registration was 5.0 \u00b1 1.6 pixels on 6 subjects. It improved to 3.6 \u00b1 1.5 pixels with the coarse-Demons method. The coarse-spline method only slightly improved the accuracy than the coarse method. The scale factor of images was measured to be~0.8 mm/pixel. Therefore, error in localizing the canthi regions with the coarse-Demons method was converted to 2.8 \u00b1 1.2 mm. We evaluated the uncertainty in manual selection of aluminum markers by repeating the manual selection process for 30 times on the same set of images. This gave us a statistical measure of standard deviation in manual selection to be 0.5 mm. We quantitatively evaluated the two-step coarse-fine registration strategy of visible and IR images with markers attached to the subjects. Circular aluminum foil markers with a diameter of 7 mm were attached to different locations around the canthi regions of 6 volunteers to evaluate the registration accuracy. The markers and their correspondence in each set of visible and IR images (Figure 7) were manually selected to define control points. They were removed using the Spot Healing Brush Tool in Adobe Photoshop \u00ae before the image registration process to avoid any registration bias caused by them. After the image registration, the spatial transformation obtained was applied to the control points for a direct registration without further optimization. The distances between the transformed marker locations on the moving image and their corresponding locations on the reference image were used for registration accuracy analysis. The registration accuracy was analyzed with both MSE and recall [7, 26] values. After image registration, the MSE of distances between each pair of transformed markers in the visible and IR images was calculated as a qualitative performance metric. We used Medical Image Registration Toolbox (MIRT) [24] for the cubic B-spline registration, to compare the coarse-spline method with the coarse and coarse-Demons methods. The registration MSE based on markers (Table 1) for the coarse registration was 5.0 \u00b1 1.6 pixels on 6 subjects. It improved to 3.6 \u00b1 1.5 pixels with the coarse-Demons method. The coarse-spline method only slightly improved the accuracy than the coarse method. The scale factor of images was measured to be ~0.8 mm/pixel. Therefore, error in localizing the canthi regions with the coarse-Demons method was converted to 2.8 \u00b1 1.2 mm. We evaluated the uncertainty in manual selection of aluminum markers by repeating the manual selection process for 30 times on the same set of images. This gave us a statistical measure of standard deviation in manual selection to be 0.5 mm.",
            "cite_spans": [
                {
                    "start": 2371,
                    "end": 2374,
                    "text": "[7,",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 2375,
                    "end": 2378,
                    "text": "26]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 2606,
                    "end": 2610,
                    "text": "[24]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 4402,
                    "end": 4405,
                    "text": "[7,",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 4406,
                    "end": 4409,
                    "text": "26]",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 4637,
                    "end": 4641,
                    "text": "[24]",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [
                {
                    "start": 101,
                    "end": 109,
                    "text": "Figure 4",
                    "ref_id": "FIGREF16"
                },
                {
                    "start": 330,
                    "end": 338,
                    "text": "Figure 5",
                    "ref_id": "FIGREF18"
                },
                {
                    "start": 718,
                    "end": 726,
                    "text": "Figure 5",
                    "ref_id": "FIGREF18"
                },
                {
                    "start": 897,
                    "end": 905,
                    "text": "Figure 6",
                    "ref_id": "FIGREF19"
                },
                {
                    "start": 1755,
                    "end": 1765,
                    "text": "(Figure 7)",
                    "ref_id": "FIGREF23"
                },
                {
                    "start": 2765,
                    "end": 2774,
                    "text": "(Table 1)",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 3786,
                    "end": 3796,
                    "text": "(Figure 7)",
                    "ref_id": "FIGREF23"
                },
                {
                    "start": 4796,
                    "end": 4805,
                    "text": "(Table 1)",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "Registration Accuracy"
        },
        {
            "text": "The registration accuracy was also analyzed with the recall parameter that is defined as a fraction of the true positive correspondences to the ground truth. The recall values on all marker pairs were computed (Figure 8 ). The true positive correspondence was counted when the pair falls within a given accuracy threshold of the Euclidean distance between points in the registered image and the corresponding points in the reference image. The recall graphs plot the recall values against different threshold values, where the recall values are defined as the ratio of the number of markers within a threshold to the total number of markers. Figure 8a reports the recall values against the threshold values using registration methods of coarse, coarse-Demons, and coarse-spline, and with markers in the face region as the control points. The recall curves were based on average values from the subjects in Table 1 . From Figure 8a , the algorithms using the coarse-Demons method outperforms the other methods. The registration accuracy was also analyzed with the recall parameter that is defined as a fraction of the true positive correspondences to the ground truth. The recall values on all marker pairs were computed (Figure 8 ). The true positive correspondence was counted when the pair falls within a given accuracy threshold of the Euclidean distance between points in the registered image and the corresponding points in the reference image. The recall graphs plot the recall values against different threshold values, where the recall values are defined as the ratio of the number of markers within a threshold to the total number of markers. Figure 8a reports the recall values against the threshold values using registration methods of coarse, coarse-Demons, and coarse-spline, and with markers in the face region as the control points. The recall curves were based on average values from the subjects in Table 1 . From Figure 8a , the algorithms using the coarse-Demons method outperforms the other methods. Table 1 ; (b) Landmarks around the eye region as the control points based on the subjects in Table 2 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 210,
                    "end": 219,
                    "text": "(Figure 8",
                    "ref_id": "FIGREF25"
                },
                {
                    "start": 642,
                    "end": 651,
                    "text": "Figure 8a",
                    "ref_id": "FIGREF25"
                },
                {
                    "start": 906,
                    "end": 913,
                    "text": "Table 1",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 921,
                    "end": 930,
                    "text": "Figure 8a",
                    "ref_id": "FIGREF25"
                },
                {
                    "start": 1220,
                    "end": 1229,
                    "text": "(Figure 8",
                    "ref_id": "FIGREF25"
                },
                {
                    "start": 1652,
                    "end": 1661,
                    "text": "Figure 8a",
                    "ref_id": "FIGREF25"
                },
                {
                    "start": 1916,
                    "end": 1923,
                    "text": "Table 1",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 1931,
                    "end": 1940,
                    "text": "Figure 8a",
                    "ref_id": "FIGREF25"
                },
                {
                    "start": 2020,
                    "end": 2027,
                    "text": "Table 1",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 2113,
                    "end": 2120,
                    "text": "Table 2",
                    "ref_id": "TABREF4"
                }
            ],
            "section": "Registration Accuracy"
        },
        {
            "text": "We also evaluated the registration accuracy for canthi localization using manually selected landmarks in the eye region as the control points ( Figure 9 ). The point correspondence on contours around eye region like eyes corners, eye brows, and pupil as ground truth, were identifiable in both the visible and IR images. The registration accuracy was analyzed with both MSE (Table 2 ) and recall (Figure 8b) values. The MSE of distance between each pair of landmarks in visible and IR images was 5.1 \u00b1 1.9 pixels for the coarse registration on 10 individuals. It was improved to 3.2 \u00b1 1.6 pixels after the Demons registration with the coarse-Demons method. The coarse-spline method showed slightly better accuracy than the coarse method. Figure 8b reports the recall values against the threshold values using registration methods of coarse, coarse-Demons, and coarse-spline. The recall curves were based on average values from the subjects in Table 2 . As shown in Figure 8b , the recall plots for the course-Demons method (green plot) were consistently better than the recall plots for other methods for different threshold values. The coarse and coarse-spline methods had similar accuracy. Comparison of Figure 8a with Figure 8b showed that the marker and landmark methods agree with each other. Table 1 ; (b) Landmarks around the eye region as the control points based on the subjects in Table 2 . We also evaluated the registration accuracy for canthi localization using manually selected landmarks in the eye region as the control points ( Figure 9 ). The point correspondence on contours around eye region like eyes corners, eye brows, and pupil as ground truth, were identifiable in both the visible and IR images. The registration accuracy was analyzed with both MSE (Table 2 ) and recall (Figure 8b) values. The MSE of distance between each pair of landmarks in visible and IR images was 5.1 \u00b1 1.9 pixels for the coarse registration on 10 individuals. It was improved to 3.2 \u00b1 1.6 pixels after the Demons registration with the coarse-Demons method. The coarse-spline method showed slightly better accuracy than the coarse method. Figure 8b reports the recall values against the threshold values using registration methods of coarse, coarse-Demons, and coarse-spline. The recall curves were based on average values from the subjects in Table 2 . As shown in Figure 8b , the recall plots for the course-Demons method (green plot) were consistently better than the recall plots for other methods for different threshold values. The coarse and coarse-spline methods had similar accuracy. Comparison of Figure 8a with Figure 8b showed that the marker and landmark methods agree with each other. the visible and IR images. The registration accuracy was analyzed with both MSE (Table 2 ) and recall (Figure 8b) values. The MSE of distance between each pair of landmarks in visible and IR images was 5.1 \u00b1 1.9 pixels for the coarse registration on 10 individuals. It was improved to 3.2 \u00b1 1.6 pixels after the Demons registration with the coarse-Demons method. The coarse-spline method showed slightly better accuracy than the coarse method. Figure 8b reports the recall values against the threshold values using registration methods of coarse, coarse-Demons, and coarse-spline. The recall curves were based on average values from the subjects in Table 2 . As shown in Figure 8b , the recall plots for the course-Demons method (green plot) were consistently better than the recall plots for other methods for different threshold values. The coarse and coarse-spline methods had similar accuracy. Comparison of Figure 8a with Figure 8b showed that the marker and landmark methods agree with each other. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 144,
                    "end": 152,
                    "text": "Figure 9",
                    "ref_id": "FIGREF26"
                },
                {
                    "start": 374,
                    "end": 382,
                    "text": "(Table 2",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 396,
                    "end": 407,
                    "text": "(Figure 8b)",
                    "ref_id": "FIGREF25"
                },
                {
                    "start": 738,
                    "end": 747,
                    "text": "Figure 8b",
                    "ref_id": "FIGREF25"
                },
                {
                    "start": 943,
                    "end": 950,
                    "text": "Table 2",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 965,
                    "end": 974,
                    "text": "Figure 8b",
                    "ref_id": "FIGREF25"
                },
                {
                    "start": 1206,
                    "end": 1215,
                    "text": "Figure 8a",
                    "ref_id": "FIGREF25"
                },
                {
                    "start": 1221,
                    "end": 1230,
                    "text": "Figure 8b",
                    "ref_id": "FIGREF25"
                },
                {
                    "start": 1298,
                    "end": 1305,
                    "text": "Table 1",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 1391,
                    "end": 1398,
                    "text": "Table 2",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 1545,
                    "end": 1553,
                    "text": "Figure 9",
                    "ref_id": "FIGREF26"
                },
                {
                    "start": 1775,
                    "end": 1783,
                    "text": "(Table 2",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 1797,
                    "end": 1808,
                    "text": "(Figure 8b)",
                    "ref_id": "FIGREF25"
                },
                {
                    "start": 2139,
                    "end": 2148,
                    "text": "Figure 8b",
                    "ref_id": "FIGREF25"
                },
                {
                    "start": 2344,
                    "end": 2351,
                    "text": "Table 2",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 2366,
                    "end": 2375,
                    "text": "Figure 8b",
                    "ref_id": "FIGREF25"
                },
                {
                    "start": 2607,
                    "end": 2616,
                    "text": "Figure 8a",
                    "ref_id": "FIGREF25"
                },
                {
                    "start": 2622,
                    "end": 2631,
                    "text": "Figure 8b",
                    "ref_id": "FIGREF25"
                },
                {
                    "start": 2779,
                    "end": 2787,
                    "text": "(Table 2",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 2801,
                    "end": 2812,
                    "text": "(Figure 8b)",
                    "ref_id": "FIGREF25"
                },
                {
                    "start": 3143,
                    "end": 3152,
                    "text": "Figure 8b",
                    "ref_id": "FIGREF25"
                },
                {
                    "start": 3348,
                    "end": 3355,
                    "text": "Table 2",
                    "ref_id": "TABREF4"
                },
                {
                    "start": 3370,
                    "end": 3379,
                    "text": "Figure 8b",
                    "ref_id": "FIGREF25"
                },
                {
                    "start": 3611,
                    "end": 3620,
                    "text": "Figure 8a",
                    "ref_id": "FIGREF25"
                },
                {
                    "start": 3626,
                    "end": 3635,
                    "text": "Figure 8b",
                    "ref_id": "FIGREF25"
                }
            ],
            "section": "Registration Accuracy"
        },
        {
            "text": "The canthi regions are not susceptible to other factors (exertion, environment) because the blood in these regions is sufficiently supplied by the internal carotid artery and the heat loss is less than other regions such as the forehead. A recent study [25] and the IEC 80601-2-59 standard [1] indicate that the canthi regions ( Figure 10 ) have the most stable temperature with good correlation to the core body temperature and thus are the best regions for fever screening. The canthi regions can be manually selected from a thermal image to read the temperature (manual approach). However, the manual approach is time consuming and lacks consistency. With the two-step coarse-Demons registration strategy we developed, the temperature at these regions can be quickly and automatically read (automatic approach). While Section 3.1 validates the accuracy of our two-step MMIR approach, this section addresses the MMIR approach based on clinical study data. We compared the automatic approach with the manual approach for reading inner canthi temperature. We used a Discriminative Response Map Fitting (DRMF)-based model [26] for facial key point detection as a tool to detect the canthi regions in the visible image. The detected canthi regions were mirrored to the IR image based on our coarse-Demons MMIR model, and the maximum temperatures (Ta) within the canthi regions were then automatically read from the IR image. At the same time, the canthi regions were manually selected from the IR image to read the maximum temperatures (Tm). The average values of the maximum temperatures from the left canthi (LC) and right canthi (RC) regions were used to compare the manual and automatic approaches. ",
            "cite_spans": [
                {
                    "start": 253,
                    "end": 257,
                    "text": "[25]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 290,
                    "end": 293,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 1121,
                    "end": 1125,
                    "text": "[26]",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [
                {
                    "start": 329,
                    "end": 338,
                    "text": "Figure 10",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Canthi Temperature Measurement"
        },
        {
            "text": "The canthi regions are not susceptible to other factors (exertion, environment) because the blood in these regions is sufficiently supplied by the internal carotid artery and the heat loss is less than other regions such as the forehead. A recent study [25] and the IEC 80601-2-59 standard [1] indicate that the canthi regions ( Figure 10 ) have the most stable temperature with good correlation to the core body temperature and thus are the best regions for fever screening. The canthi regions can be manually selected from a thermal image to read the temperature (manual approach). However, the manual approach is time consuming and lacks consistency. With the two-step coarse-Demons registration strategy we developed, the temperature at these regions can be quickly and automatically read (automatic approach). While Section 3.1 validates the accuracy of our two-step MMIR approach, this section addresses the MMIR approach based on clinical study data. We compared the automatic approach with the manual approach for reading inner canthi temperature. We used a Discriminative Response Map Fitting (DRMF)-based model [26] for facial key point detection as a tool to detect the canthi regions in the visible image. The detected canthi regions were mirrored to the IR image based on our coarse-Demons MMIR model, and the maximum temperatures (Ta) within the canthi regions were then automatically read from the IR image. At the same time, the canthi regions were manually selected from the IR image to read the maximum temperatures (Tm). The average values of the maximum temperatures from the left canthi (LC) and right canthi (RC) regions were used to compare the manual and automatic approaches. We collected the canthi temperature data from 36 subjects through the manual and automatic approaches. We used Bland Altman plots ( Figure 11 ) for combined graphical and statistical interpretation of the two measurement techniques. The plots were used to show the absolute differences between the two measurements against their mean (i.e., (Ta \u2212 Tm) versus (Ta + Tm)/2). The mean of absolute differences (Solid line in Figure 11 ) and the 95% limits (Dashed lines in Figure 11 ) of normal distribution (\u00b11.96SD) are calculated for the estimation of inner canthi temperature from the manual and automatic approaches. We observed a difference between the automatic and manual methods of 0.10 \u00b1 0.09 \u00b0C (mean \u00b1 1.96SD). We collected the canthi temperature data from 36 subjects through the manual and automatic approaches. We used Bland Altman plots ( Figure 11 ) for combined graphical and statistical interpretation of the two measurement techniques. The plots were used to show the absolute differences between the two measurements against their mean (i.e., (Ta \u2212 Tm) versus (Ta + Tm)/2). The mean of absolute differences (Solid line in Figure 11 ) and the 95% limits (Dashed lines in Figure 11 ) of normal distribution (\u00b11.96SD) are calculated for the estimation of inner canthi temperature from the manual and automatic approaches. We observed a difference between the automatic and manual methods of 0.10 \u00b1 0.09 \u2022 C (mean \u00b1 1.96SD).",
            "cite_spans": [
                {
                    "start": 253,
                    "end": 257,
                    "text": "[25]",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 290,
                    "end": 293,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 1121,
                    "end": 1125,
                    "text": "[26]",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [
                {
                    "start": 329,
                    "end": 338,
                    "text": "Figure 10",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 1833,
                    "end": 1842,
                    "text": "Figure 11",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 2121,
                    "end": 2130,
                    "text": "Figure 11",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 2169,
                    "end": 2178,
                    "text": "Figure 11",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 2551,
                    "end": 2560,
                    "text": "Figure 11",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 2839,
                    "end": 2848,
                    "text": "Figure 11",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 2887,
                    "end": 2896,
                    "text": "Figure 11",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Canthi Temperature Measurement"
        },
        {
            "text": "interpretation of the two measurement techniques. The plots were used to show the absolute differences between the two measurements against their mean (i.e., (Ta \u2212 Tm) versus (Ta + Tm)/2). The mean of absolute differences (Solid line in Figure 11 ) and the 95% limits (Dashed lines in Figure 11 ) of normal distribution (\u00b11.96SD) are calculated for the estimation of inner canthi temperature from the manual and automatic approaches. We observed a difference between the automatic and manual methods of 0.10 \u00b1 0.09 \u00b0C (mean \u00b1 1.96SD). ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 237,
                    "end": 246,
                    "text": "Figure 11",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 285,
                    "end": 294,
                    "text": "Figure 11",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Canthi Temperature Measurement"
        },
        {
            "text": "For real-time canthi detection, the image registration speed is important. The speed for the coarse and fine registrations on a consumer laptop (Dell laptop, Intel Core i7-6600 U CPU @ 2.6 GHz, 16 GB RAM) were 5.9 s and 2.9 s, respectively. The registration speed can be affected by many factors such as the computer speed, algorithm parameters, programing language, and image contents. While the registration speed is not the focus of this paper, we believe the registration speed can be improved by using a powerful computer, further optimizing the algorithm parameters, translating the Matlab codes to a faster language such as C/C++ codes, and adjusting the image contents.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Image Registration Speed"
        },
        {
            "text": "The optical performance of a camera, and thus the image quality, might affect the registration accuracy. As mentioned in Section 2, the IR and visible images have 512 \u00d7 640 and 640 \u00d7 480 pixels, respectively, as shown in Figure 12a ,b. For canthi-based temperature measurement, we are only interested in face and blackbody region of the input images. During the process of coarse-fine registration, the input images were first cropped to the face region during the coarse registration step ( Figure 4 ). Theoretically, we should be able to get the same registration results if the region of interest around the face has the same number of pixels even though the total pixel numbers of the whole images are different. To evaluate this assumption, we cropped both the visible and IR images to 240 \u00d7 320 pixels (Figure 12c ,d)-the minimum required sizes based on the IEC standard [1] -to simulate camera with smaller number of pixels, before performing image registration. Our results showed that registration of Figure 12c ,d had the same accuracy as the registration of Figure 12a ",
            "cite_spans": [
                {
                    "start": 877,
                    "end": 880,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                }
            ],
            "ref_spans": [
                {
                    "start": 221,
                    "end": 231,
                    "text": "Figure 12a",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 492,
                    "end": 500,
                    "text": "Figure 4",
                    "ref_id": "FIGREF16"
                },
                {
                    "start": 808,
                    "end": 819,
                    "text": "(Figure 12c",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 1010,
                    "end": 1020,
                    "text": "Figure 12c",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 1069,
                    "end": 1079,
                    "text": "Figure 12a",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Efffect of Image Quality on Registraton Accuracy"
        },
        {
            "text": "For real-time canthi detection, the image registration speed is important. The speed for the coarse and fine registrations on a consumer laptop (Dell laptop, Intel Core i7-6600 U CPU @ 2.6 GHz, 16 GB RAM) were 5.9 s and 2.9 s, respectively. The registration speed can be affected by many factors such as the computer speed, algorithm parameters, programing language, and image contents. While the registration speed is not the focus of this paper, we believe the registration speed can be improved by using a powerful computer, further optimizing the algorithm parameters, translating the Matlab codes to a faster language such as C/C++ codes, and adjusting the image contents.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Image Registration Speed"
        },
        {
            "text": "The optical performance of a camera, and thus the image quality, might affect the registration accuracy. As mentioned in Section 2, the IR and visible images have 512 \u00d7 640 and 640 \u00d7 480 pixels, respectively, as shown in Figure 12a ,b. For canthi-based temperature measurement, we are only interested in face and blackbody region of the input images. During the process of coarse-fine registration, the input images were first cropped to the face region during the coarse registration step ( Figure 4 ). Theoretically, we should be able to get the same registration results if the region of interest around the face has the same number of pixels even though the total pixel numbers of the whole images are different. To evaluate this assumption, we cropped both the visible and IR images to 240 \u00d7 320 pixels (Figure 12c ,d)-the minimum required sizes based on the IEC standard [1] -to simulate camera with smaller number of pixels, before performing image registration. Our results showed that registration of Figure 12c ,d had the same accuracy as the registration of Figure 12a Theoretically, higher image resolution for the same scene will improve registration accuracy. However, a larger pixel number doesn't necessary mean a higher image resolution. The image resolution is affected by the camera's modulation transfer function [27] , which is not the focus of this paper. The qualities of two images from two cameras with the same physical parameters (e.g., pixel number, field of view, focal length) might be different, which might in turn result in different registration accuracies. Theoretically, higher image resolution for the same scene will improve registration accuracy. However, a larger pixel number doesn't necessary mean a higher image resolution. The image resolution is affected by the camera's modulation transfer function [27] , which is not the focus of this paper. The qualities of two images from two cameras with the same physical parameters (e.g., pixel number, field of view, focal length) might be different, which might in turn result in different registration accuracies.",
            "cite_spans": [
                {
                    "start": 877,
                    "end": 880,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 1333,
                    "end": 1337,
                    "text": "[27]",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 1845,
                    "end": 1849,
                    "text": "[27]",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [
                {
                    "start": 221,
                    "end": 231,
                    "text": "Figure 12a",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 492,
                    "end": 500,
                    "text": "Figure 4",
                    "ref_id": "FIGREF16"
                },
                {
                    "start": 808,
                    "end": 819,
                    "text": "(Figure 12c",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 1010,
                    "end": 1020,
                    "text": "Figure 12c",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 1069,
                    "end": 1079,
                    "text": "Figure 12a",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Efffect of Image Quality on Registraton Accuracy"
        },
        {
            "text": "While the data in this paper showed that the coarse-Demons registration was statistically more accurate for the current imaging system, the actual registration approach and parameters should be optimized and evaluated for a different imaging system to achieve optimum registration accuracy. Observed results showed that the edge detection algorithm had a significant impact on registration accuracy. The cubic B-spline registration showed degradation in performance due to edge map outliers. If the edge detection is improved through customized pre-processing, the accuracy of cubic B-spline registration might be improved for a specific IRT system.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Effects of Other Factors on Registration Accuracy"
        },
        {
            "text": "In our study, the visible camera and IRT were placed at the closest possible locations with the center-to-center distance of their optical lenses being 3 cm. If these two cameras can be closer so that they will see the subject from the same angle, the image registration should be more accurate. The intensity and uniformity of the illumination can also affect the registration. Non-uniform and too low/high illumination might deteriorate the registration accuracy.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Effects of Other Factors on Registration Accuracy"
        },
        {
            "text": "In this paper, we proposed a system that uses a two-step coarse-fine registration method for visible and IR face images for body temperature measurement using canthi regions. We evaluated two widely used FFD algorithms-the Demons algorithm and the cubic B-spline algorithm-as the second step of a coarse-fine registration method. The algorithms used edge maps to improve registration accuracy. The registration accuracy of the coarse-Demons and coarse-spline methods were qualitatively compared using MSE values and recall graphs from markers and landmarks. The results show that the coarse-Demons method outperformed the coarse-spline algorithm, likely due to overfitting of the outliers by the latter method. The quantitative measure of registration accuracy was within 2.8 \u00b1 1.2 mm, which enables accurate and automatic localization of the canthi regions in IR images for temperature measurement. We used the coarse-Demons method for registration followed by canthi detection to read the temperature at the canthi regions from IR images. The temperature readings from the proposed automatic method were compared with the readings from the manual method through Bland Altman analysis. The comparison showed a difference of 0.10 \u00b1 0.09 \u2022 C (mean \u00b1 1.96SD) for the automatic and manual temperature readings.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusions"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "International Electrotechnical Commission (IEC)/International Organization for Standardization (ISO)",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "IEC 80601-2-59: Particular Requirements for the Basic Safety and Essential Performance of Screening Thermographs for Human Febrile Temperature Screening",
            "authors": [],
            "year": 2017,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Fusion of infrared and visible images based on nonsubsampled contourlet transform and sparse K-SVD dictionary learning",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Cai",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Cheng",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Peng",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Infrared Phys. Techn",
            "volume": "82",
            "issn": "",
            "pages": "85--95",
            "other_ids": {
                "DOI": [
                    "10.1016/j.infrared.2017.01.026"
                ]
            }
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Feature guided Gaussian mixture model with semi-supervised EM and local geometric constraint for retinal image registration",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Inf. Sci",
            "volume": "417",
            "issn": "",
            "pages": "128--142",
            "other_ids": {
                "DOI": [
                    "10.1016/j.ins.2017.07.010"
                ]
            }
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "An Automatic Multi-Target Independent Analysis Framework for Non-Planar Infrared-Visible Registration",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "17",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.3390/s17081696"
                ]
            }
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Infrared and visible image fusion via gradient transfer and total variation minimization",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Inf. Fusion",
            "volume": "31",
            "issn": "",
            "pages": "100--109",
            "other_ids": {
                "DOI": [
                    "10.1016/j.inffus.2016.02.001"
                ]
            }
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Visible and infrared image registration in man-made environments employing hybrid visual features",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "J"
                    ],
                    "last": "Pauwels",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "De Zeeuw",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Pattern Recognit. Lett",
            "volume": "34",
            "issn": "",
            "pages": "42--51",
            "other_ids": {
                "DOI": [
                    "10.1016/j.patrec.2012.03.022"
                ]
            }
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Non-rigid visible and infrared face registration via regularized Gaussian fields criterion",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Tian",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Pattern Recognit",
            "volume": "48",
            "issn": "",
            "pages": "772--784",
            "other_ids": {
                "DOI": [
                    "10.1016/j.patcog.2014.09.005"
                ]
            }
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Infrared-visible image registration for augmented reality-based thermographic building diagnostics",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Seipel",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Visual. Eng",
            "volume": "3",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1186/s40327-015-0028-0"
                ]
            }
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Registration of thermal and visible light images of diseased plants using silhouette extraction in the wavelet domain",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Raza",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Sanchez",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Prince",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Clarkson",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [
                        "M"
                    ],
                    "last": "Rajpoot",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Pattern Recognit",
            "volume": "48",
            "issn": "",
            "pages": "2119--2128",
            "other_ids": {
                "DOI": [
                    "10.1016/j.patcog.2015.01.027"
                ]
            }
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "Springer Science & Business Media LLC",
            "authors": [],
            "year": 2006,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Non-Rigid Multimodality Image Registration",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Mattes",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "R"
                    ],
                    "last": "Haynor",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Vesselle",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Lewellen",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Eubank",
                    "suffix": ""
                }
            ],
            "year": 2001,
            "venue": "Med. Imag",
            "volume": "",
            "issn": "",
            "pages": "1609--1620",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Image matching as a diffusion process: An analogy with Maxwell's demons. Med. Image Anal",
            "authors": [
                {
                    "first": "J.-P",
                    "middle": [],
                    "last": "Thirion",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "",
            "volume": "2",
            "issn": "",
            "pages": "243--260",
            "other_ids": {
                "DOI": [
                    "10.1016/S1361-8415(98)80022-4"
                ]
            }
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Determining optical flow",
            "authors": [
                {
                    "first": "B",
                    "middle": [
                        "K"
                    ],
                    "last": "Horn",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "G"
                    ],
                    "last": "Schunck",
                    "suffix": ""
                }
            ],
            "year": 1981,
            "venue": "Artif. Intell",
            "volume": "17",
            "issn": "",
            "pages": "185--203",
            "other_ids": {
                "DOI": [
                    "10.1016/0004-3702(81)90024-2"
                ]
            }
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Implementation and evaluation of various demons deformable image registration algorithms on a GPU",
            "authors": [
                {
                    "first": "X",
                    "middle": [],
                    "last": "Gu",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Pan",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Liang",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Castillo",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Choi",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Castillo",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Majumdar",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Guerrero",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "B"
                    ],
                    "last": "Jiang",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Phys. Med. Biol",
            "volume": "55",
            "issn": "",
            "pages": "207--219",
            "other_ids": {
                "DOI": [
                    "10.1088/0031-9155/55/1/012"
                ]
            }
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Image registration methods: A survey",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "Zitova",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Flusser",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Image Vis. Comput",
            "volume": "21",
            "issn": "",
            "pages": "977--1000",
            "other_ids": {
                "DOI": [
                    "10.1016/S0262-8856(03)00137-9"
                ]
            }
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Mutual-information-based registration of medical images: A survey",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "P"
                    ],
                    "last": "Pluim",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "A"
                    ],
                    "last": "Maintz",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Viergever",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "22",
            "issn": "",
            "pages": "986--1004",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2003.815867"
                ]
            }
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "MRI-PET registration with automated algorithm",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "P"
                    ],
                    "last": "Woods",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "C"
                    ],
                    "last": "Mazziotta",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "R"
                    ],
                    "last": "Cherry",
                    "suffix": ""
                }
            ],
            "year": 1993,
            "venue": "J. Comput. Assist. Tomogr",
            "volume": "17",
            "issn": "",
            "pages": "536--546",
            "other_ids": {
                "DOI": [
                    "10.1097/00004728-199307000-00004"
                ]
            }
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Assessment of Intraoperative Brain Deformation Using Interventional MR Imaging",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "L"
                    ],
                    "last": "Hill",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "R"
                    ],
                    "last": "Maurer",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Jr",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "J"
                    ],
                    "last": "Martin",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sabanathan",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [
                        "A"
                    ],
                    "last": "Hall",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "J"
                    ],
                    "last": "Hawkes",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Rueckert",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "L"
                    ],
                    "last": "Truwit",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
            "volume": "",
            "issn": "",
            "pages": "910--919",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Multi-modality image registration for effective thermographic fever screening",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Dwith",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Ghassemi",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Pfefer",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Casamento",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Proceedings of the 2017 Multimodal Biomedical Imaging XII",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1117/12.2253932"
                ]
            }
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "2-D and 3-D Image Registration: For Medical, Remote Sensing, and Industrial Applications",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "Goshtasby",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "A survey of medical image registration",
            "authors": [
                {
                    "first": "J",
                    "middle": [
                        "A"
                    ],
                    "last": "Maintz",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "A"
                    ],
                    "last": "Viergever",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "Med. Image Anal",
            "volume": "2",
            "issn": "",
            "pages": "1--36",
            "other_ids": {
                "DOI": [
                    "10.1016/S1361-8415(01)80026-8"
                ]
            }
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Endoscope field of view measurement",
            "authors": [
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Khanicheh",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Leiner",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Shafer",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zobel",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Biomed. Opt. Exp",
            "volume": "8",
            "issn": "",
            "pages": "1441--1454",
            "other_ids": {
                "DOI": [
                    "10.1364/BOE.8.001441"
                ]
            }
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Rapid object detection using a boosted cascade of simple features",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Viola",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Jones",
                    "suffix": ""
                }
            ],
            "year": 2001,
            "venue": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "EM detection of common origin of multi-modal cues",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "K"
                    ],
                    "last": "Noulas",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "J"
                    ],
                    "last": "Kr\u00f6se",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Proceedings of the 8th International Conference on Multimodal interfaces",
            "volume": "",
            "issn": "",
            "pages": "201--208",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Analysis of IR thermal imager for mass blind fever screening",
            "authors": [
                {
                    "first": "E",
                    "middle": [
                        "Y"
                    ],
                    "last": "Ng",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Kawb",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Chang",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Microvasc. Res",
            "volume": "68",
            "issn": "",
            "pages": "104--109",
            "other_ids": {
                "DOI": [
                    "10.1016/j.mvr.2004.05.003"
                ]
            }
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Robust discriminative response map fitting with constrained local models",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Asthana",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Zafeiriou",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Cheng",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Pantic",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "3444--3451",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "ISO 12233: Photography-Electronic Still Picture Imaging-Resolution and Spatial Frequency Responses",
            "authors": [],
            "year": 2017,
            "venue": "International Organization for Standardization",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Joint histograms for measuring registration accuracy using the MI metric: (a) low accuracy, high entropy; (b) high accuracy, low entropy[19].",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Joint histograms for measuring registration accuracy using the MI metric: (a) low accuracy, high entropy; (b) high accuracy, low entropy[19].",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Block diagram of the two-step registration strategy.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Block diagram of image registration.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "ref I represents the intensity of reference image, and ) (n mov I represents the intensity of the moving image at the n th iteration. When n = 0, ) 0 ( mov I represents the intensity of the original moving image. Gaussian filter is used to smooth the displacement fields, which enables noise suppression and preserves geometric continuity of the deformed image. The gradient of the reference image ref I \uf0d1",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Block diagram of the two-step registration strategy. Block diagram of the two-step registration strategy.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Block diagram of image registration.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF9": {
            "text": "ref I represents the intensity of reference image, and ) (n mov I represents the intensity of the moving image at the n th iteration. When n = 0, ) 0 ( mov I represents the intensity of the original moving image. Gaussian filter is used to smooth the displacement fields, which enables noise suppression and preserves geometric continuity of the deformed image. The gradient of the reference image ref I \uf0d1",
            "latex": null,
            "type": "figure"
        },
        "FIGREF10": {
            "text": "Block diagram of image registration.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF11": {
            "text": "represents the intensity of the moving image at the n th iteration. When n = 0, I (0) mov represents the intensity of the original moving image.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF14": {
            "text": "Visible (a,c) and IR (b,d) images before (a,b) and after (c,d) coarse registration. Edge map pairs view of registered visible (green) and IR (red) images with the (a) coarse, (b) coarse-Demons, and (c) coarse-spline methods. (a) ( b) ( c) Checkered view of registered images using the (a) coarse, (b) coarse-Demons, and (c) coarse-spline methods.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF16": {
            "text": "Visible (a,c) and IR (b,d) images before (a,b) and after (c,d) coarse registration.Sensors 2018, 18, 125 7 of 13",
            "latex": null,
            "type": "figure"
        },
        "FIGREF17": {
            "text": "Visible (a,c) and IR (b,d) images before (a,b) and after (c,d) coarse registration. Edge map pairs view of registered visible (green) and IR (red) images with the (a) coarse, (b) coarse-Demons, and (c) coarse-spline methods. Checkered view of registered images using the (a) coarse, (b) coarse-Demons, and (c) coarse-spline methods.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF18": {
            "text": "Edge map pairs view of registered visible (green) and IR (red) images with the (a) coarse, (b) coarse-Demons, and (c) coarse-spline methods.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF19": {
            "text": "shows corresponding image registration results viewed through superimposed checkerboard pattern of visible and IR images in gray scale. It can be observed that the eyes and nose are not accurately aligned with the coarse registration, whereas the coarse-Demons and coarse-spline methods show better alignment. This demonstrates that applying a non-linear registration algorithm improves accurate matching of face images compared to the coarse registration alone.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF20": {
            "text": "Edge Checkered view of registered images using the (a) coarse, (b) coarse-Demons, and (c) coarse-spline methods.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF21": {
            "text": "Checkered view of registered images using the (a) coarse, (b) coarse-Demons, and (c) coarse-spline methods.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF23": {
            "text": "Aluminum Markers as control points for registration accuracy evaluation: (a) visible image; (b) IR image[19].",
            "latex": null,
            "type": "figure"
        },
        "FIGREF24": {
            "text": "Aluminum Markers as control points for registration accuracy evaluation: (a) visible image; (b) IR image[19].",
            "latex": null,
            "type": "figure"
        },
        "FIGREF25": {
            "text": "Recall graphs showing image registration accuracy of the coarse, coarse-Demons and coarse-spline models: (a) Markers in the face region as the control points based on the subjects in",
            "latex": null,
            "type": "figure"
        },
        "FIGREF26": {
            "text": "Landmarks as control points for registration accuracy evaluation: (a) visible image; (b) IR image.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF27": {
            "text": "Recall graphs showing image registration accuracy of the coarse, coarse-Demons and coarse-spline models: (a) Markers in the face region as the control points based on the subjects in",
            "latex": null,
            "type": "figure"
        },
        "FIGREF28": {
            "text": "Landmarks as control points for registration accuracy evaluation: (a) visible image; (b) IR image.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF29": {
            "text": "Landmarks as control points for registration accuracy evaluation: (a) visible image; (b) IR image.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF31": {
            "text": "Canthi regions in (a) a visible and (b) an IR images[19].",
            "latex": null,
            "type": "figure"
        },
        "FIGREF32": {
            "text": "Canthi regions in (a) a visible and (b) an IR images[19].",
            "latex": null,
            "type": "figure"
        },
        "FIGREF33": {
            "text": "Automatic versus manual canthi temperature measurement (a) and the Bland-Altman plot (b). Automatic versus manual canthi temperature measurement (a) and the Bland-Altman plot (b).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF35": {
            "text": ",b.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF36": {
            "text": "Sizes of images used for registration: (a) full size visible image, 640 \u00d7 480 pixels; (b) full size IR image, 512 \u00d7 640 pixels; (c) cropped visible image, 240 \u00d7 320 pixels; (d) cropped IR image, 240 \u00d7 320 pixels.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF37": {
            "text": "Sizes of images used for registration: (a) full size visible image, 640 \u00d7 480 pixels; (b) full size IR image, 512 \u00d7 640 pixels; (c) cropped visible image, 240 \u00d7 320 pixels; (d) cropped IR image, 240 \u00d7 320 pixels.",
            "latex": null,
            "type": "figure"
        },
        "TABREF2": {
            "text": "Registration Matching Error (Markers in the face region as control points), pixels.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Registration Matching Error (Markers in the face region as control points), pixels.",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "Registration Matching Error (Landmarks around the eye region as control points), pixels.",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": "Registration Matching Error (Landmarks around the eye region as control points), pixels.",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": "Registration Matching Error (Landmarks around the eye region as control points), pixels.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "The project was supported by U.S. Food and Drug Administration's Medical Countermeasures Initiative (MCMi) Regulatory Science Program (16ECDRH407). The authors would like to thank Rama Chellappa, Chair of the Department of Electrical and Computer Engineering, University of Maryland, for his guidance and support during the research work.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgments:"
        },
        {
            "text": "The mention of commercial products, their sources, or their use in connection with material reported herein is not to be construed as either an actual or implied endorsement of such products by the U.S. Department of Health and Human Services.Author Contributions: Yedukondala Narendra Dwith Chenna (Dwith) developed the initial codes for multi-modality image registration (MMIR) of simultaneously captured visible and IR facial images for fever screening. Pejhman Ghassemi helped to capture the visible and IR images for algorithm evaluation. T. Joshua Pfefer and Jon Casamento provided input on methods and interpretation of results, and edited the manuscript. Quanzeng Wang conceived the project, helped Dwith to debug, optimize and evaluate the codes, and oversaw the project and publication.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Disclaimer:"
        },
        {
            "text": "The authors declare no conflict of interest.Sensors 2018, 18, 125 ",
            "cite_spans": [
                {
                    "start": 58,
                    "end": 61,
                    "text": "18,",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "Conflicts of Interest:"
        }
    ]
}