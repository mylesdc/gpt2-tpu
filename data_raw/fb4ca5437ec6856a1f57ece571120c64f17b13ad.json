{
    "paper_id": "fb4ca5437ec6856a1f57ece571120c64f17b13ad",
    "metadata": {
        "title": "Online Supplementary Materials Data Extraction and Processing Limitations on using Twitter Search Application Programming Interface (API) to retrieve tweets",
        "authors": []
    },
    "abstract": [
        {
            "text": "While Twitter Search API could be used to retrieve tweets with a particular hashtag, we did not use that method directly. The reasons were as follows. Twitter Search API allows queries against the indices of recent or popular tweets and behaves similarly to, but not exactly like the Search feature available in Twitter mobile or web clients, such as Twitter.com search. Twitter Search API is based on relevance but not on completeness. Furthermore, Twitter sets restrictions on how old one can grab the data from its API. Twitter Search API searches against a sampling of recent Tweets published in the past 7 days. 1 Twitter also sets a limit on the number of requests one can make in a time period. Twitter allows the user only 180 requests per 15-minute window. 2 Thus, the process of tweet extraction is limited by these limits set by Twitter.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "Web scraping to retrieve tweets' ID. To retrieve Twitter data older than two weeks, we relied on web scraping. With Twitter Advanced Search, we can read all the tweets with a particular hashtag, person, place or between dates by scrolling through the web page. The most important thing a tweet contains is a tweet ID; if one can get a tweet ID of an old tweet we can use the search API to get all the information of that tweet. On the Twitter website using Twitter Advanced Search, users can scroll as much as they want and read the tweets even as old as five years old. Therefore, we performed Twitter scrapping to retrieve tweets older than one week. The first step was to obtain the IDs of tweets with a hashtag by scrolling automatically through the page using",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "TwitterScrapper, a Python library. 3 Given the date we can retrieve all tweet IDs with that hashtag from that date until present or any interval specified by the user.",
            "cite_spans": [
                {
                    "start": 35,
                    "end": 36,
                    "text": "3",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "Twitter Search API to retrieve meta-data. After obtaining the tweet IDs, we used Twitter Search API to retrieve all the metadata of that tweet. We made 180 requests every 15 minutes. The data retrieved was in JSON format. The data retrieval was completed and the data delivered to the analysts on November 13, 2016.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "Data processing. The Twitter data was converted from JSON format into CSV format. The data was then processed in R. The retrieved contained all original tweets and some retweets. We kept only the original tweets by removing the retweets in the corpus through identifying any tweets with \"RT\" in the text. The #CDCGrandRounds contained 7,879 tweets prior to retweet removal and 6,966 tweets after retweet removal. The #VitalSigns contained 16,021 tweets prior to retweet removal and 15,015 tweets after retweet removal. The retweet frequency used in the data analysis is based on the meta-data of the original tweet. The original tweets in the #CDCGrandRounds data set were dated from April 21, 2011 to October 25, 2016. The original tweets containing the hashtag #VitalSigns were dated from March 19, 2013 to October 31, 2016. *Only 7 of the tweets were relevant to the CDC Vital Signs report. Therefore, we decided to exclude that cycle for the analysis here.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        },
        {
            "text": "**The prevalence ratio could not be computed due to all the tweets in Cycle 42 containing a photo.",
            "cite_spans": [],
            "ref_spans": [],
            "section": ""
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Twitter. GET serach/tweets",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Twitter",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "The Search API",
            "volume": "",
            "issn": "2",
            "pages": "",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "TABREF0": {
            "text": "The tweet with the highest number of retweets for each cycle of #CDCGrandRounds, and whether it contained a visual cue (an image or a video).",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "The tweet with the highest number of retweets for each cycle of #VitalSigns and whether it contained a visual cue (an image or a video).",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Prevalence ratios of attaching a photo or video on retweet frequency for #CDCGrandRounds over different cycles.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Prevalence ratios of attaching a photo or video on retweet frequency for #Vitalsigns over different cycles.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": []
}